{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%cython` not found.\n"
     ]
    }
   ],
   "source": [
    "%%cython \n",
    "# distutils: language = c++\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "#from thinker import util\n",
    "import thinker.util as util\n",
    "\n",
    "import cython\n",
    "from libcpp cimport bool\n",
    "from libcpp.vector cimport vector\n",
    "from cpython.ref cimport PyObject, Py_INCREF, Py_DECREF\n",
    "from libc.math cimport sqrt\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "# util function\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cdef float average(vector[float]& arr):\n",
    "    cdef int n = arr.size()    \n",
    "    if n == 0: return 0.\n",
    "    cdef float sum = 0\n",
    "    cdef int i    \n",
    "    for i in range(n): sum += arr[i]\n",
    "    return sum / n    \n",
    "\n",
    "cdef float maximum(vector[float]& arr):\n",
    "    cdef int n = arr.size()    \n",
    "    if n == 0: return 0.\n",
    "    cdef float max_val = arr[0]\n",
    "    cdef int i\n",
    "    for i in range(1, n): \n",
    "        if arr[i] > max_val: \n",
    "            max_val = arr[i]\n",
    "    return max_val       \n",
    "\n",
    "# Node-related function (we use structure instead of class to minimize Python code)\n",
    "\n",
    "cdef struct Node:\n",
    "    int action # action\n",
    "    float r # reward\n",
    "    float v # value\n",
    "    int t # time step when last expanded\n",
    "    bool done # whether done or not\n",
    "    float logit # logit    \n",
    "    vector[Node*]* ppchildren # children node list\n",
    "    Node* pparent # parent node\n",
    "    float trail_r # trailing reward\n",
    "    float trail_discount # trailing discount\n",
    "    float rollout_q # trailing rollout q    \n",
    "    bool visited # visited?\n",
    "    vector[float]* prollout_qs # all rollout return\n",
    "    vector[vector[Node*]*]* ppaths # node path corresponding to the rollout return in prollout_qs\n",
    "    int rollout_n # number of rollout\n",
    "    float max_q # maximum of all v    \n",
    "    PyObject* encoded # all python object    \n",
    "    int rec_t # number of planning step\n",
    "    int num_actions # number of actions\n",
    "    float discounting # discount rate\n",
    "    bool remember_path # whethere to remember path for the rollout\n",
    "\n",
    "cdef Node* node_new(Node* pparent, int action, float logit, int num_actions, float discounting, int rec_t, bool remember_path):\n",
    "    cdef Node* pnode = <Node*> malloc(sizeof(Node))\n",
    "    cdef vector[Node*]* ppchildren =  new vector[Node*]()\n",
    "    cdef vector[float]* prollout_qs = new vector[float]()\n",
    "    cdef vector[vector[Node*]*]* ppaths\n",
    "    if remember_path:\n",
    "        ppaths = new vector[vector[Node*]*]()\n",
    "    else:\n",
    "        ppaths = NULL\n",
    "    pnode[0] = Node(action=action, r=0., v=0., t=0, done=False, logit=logit, ppchildren=ppchildren, pparent=pparent, trail_r=0., trail_discount=1., rollout_q=0,\n",
    "        visited=False, prollout_qs=prollout_qs, ppaths=ppaths, rollout_n=0, max_q=0., encoded=NULL, rec_t=rec_t, num_actions=num_actions, discounting=discounting, remember_path=remember_path)\n",
    "    return pnode\n",
    "\n",
    "cdef bool node_expanded(Node* pnode, int t):\n",
    "    \"\"\"\n",
    "    Whether the node is expanded after time step t\n",
    "    \"\"\"\n",
    "    return pnode[0].ppchildren[0].size() > 0 and t <= pnode[0].t\n",
    "\n",
    "cdef node_expand(Node* pnode, float r, float v, int t, bool done, float[:] logits, PyObject* encoded, bool override):\n",
    "    \"\"\"\n",
    "    First time arriving a node and so we expand it\n",
    "    \"\"\"\n",
    "    cdef int a    \n",
    "    cdef Node* pnode_\n",
    "    if override and not node_expanded(pnode, -1):\n",
    "        override = False # no override if not yet expanded\n",
    "\n",
    "    if not override: \n",
    "        assert not node_expanded(pnode, -1), \"node should not be expanded\"\n",
    "    else:        \n",
    "        pnode[0].prollout_qs[0][0] = r + v * pnode[0].discounting\n",
    "        for a in range(1, int(pnode[0].prollout_qs[0].size())):\n",
    "            pnode[0].prollout_qs[0][a] = pnode[0].prollout_qs[0][a] - pnode[0].r + r\n",
    "        if pnode[0].pparent != NULL and pnode[0].remember_path:\n",
    "            node_refresh(pnode[0].pparent, pnode, r - pnode[0].r, v - pnode[0].v, pnode[0].discounting, 1)\n",
    "    pnode[0].r = r\n",
    "    pnode[0].v = v\n",
    "    pnode[0].t = t\n",
    "    if pnode[0].encoded != NULL: \n",
    "        Py_DECREF(<object>pnode[0].encoded)    \n",
    "    pnode[0].encoded = encoded\n",
    "    pnode[0].done = done\n",
    "    Py_INCREF(<object>encoded)\n",
    "    for a in range(pnode[0].num_actions):\n",
    "        if not override:\n",
    "            pnode[0].ppchildren[0].push_back(node_new(pparent=pnode, action=a, logit=logits[a], \n",
    "                num_actions = pnode[0].num_actions, discounting = pnode[0].discounting, rec_t = pnode[0].rec_t,\n",
    "                remember_path = pnode[0].remember_path))\n",
    "        else:\n",
    "            pnode[0].ppchildren[0][a][0].logit = logits[a]    \n",
    "\n",
    "cdef node_refresh(Node* pnode, Node* pnode_to_refresh, float r_diff, float v_diff, float discounting, int depth):\n",
    "    \"\"\"\n",
    "    Refresh the r and v in the rollout_qs that contains pnode[0]; only available when remember_path is enabled\n",
    "    \"\"\"\n",
    "    cdef int i, j, k\n",
    "    cdef Node* pnode_check\n",
    "    for i in range(int(pnode[0].ppaths[0].size())):\n",
    "        j = int(pnode[0].ppaths[0][i][0].size())\n",
    "        k = j - 1 - depth\n",
    "        if k < 0: continue\n",
    "        pnode_check = pnode[0].ppaths[0][i][0][k]\n",
    "        if pnode_check == pnode_to_refresh:\n",
    "            pnode[0].prollout_qs[0][i] += discounting * r_diff\n",
    "            if k == 0:\n",
    "                pnode[0].prollout_qs[0][i] += discounting * pnode[0].discounting * v_diff\n",
    "    if pnode[0].pparent != NULL: node_refresh(pnode[0].pparent, pnode_to_refresh, r_diff, v_diff, discounting * pnode[0].discounting, depth+1)\n",
    "\n",
    "cdef node_visit(Node* pnode):\n",
    "    cdef vector[Node*]* ppath    \n",
    "    pnode[0].trail_r = 0.\n",
    "    pnode[0].trail_discount = 1.    \n",
    "    if not pnode[0].visited and pnode[0].remember_path:\n",
    "        ppath = new vector[Node*]()\n",
    "    else:\n",
    "        ppath = NULL\n",
    "    node_propagate(pnode=pnode, r=pnode[0].r, v=pnode[0].v, new_rollout=not pnode[0].visited, ppath=ppath)\n",
    "    pnode[0].visited = True\n",
    "\n",
    "cdef void node_propagate(Node* pnode, float r, float v, bool new_rollout, vector[Node*]* ppath):\n",
    "    cdef int i\n",
    "    cdef vector[Node*]* ppath_\n",
    "    pnode[0].trail_r = pnode[0].trail_r + pnode[0].trail_discount * r\n",
    "    pnode[0].trail_discount = pnode[0].trail_discount * pnode[0].discounting\n",
    "    pnode[0].rollout_q = pnode[0].trail_r + pnode[0].trail_discount * v    \n",
    "    if new_rollout:\n",
    "        if pnode[0].remember_path:\n",
    "            ppath_ = new vector[Node*]()\n",
    "            for i in range(int(ppath[0].size())):                \n",
    "                ppath_.push_back(ppath[0][i])\n",
    "            ppath_.push_back(pnode)\n",
    "            pnode[0].ppaths[0].push_back(ppath_)\n",
    "        else:\n",
    "            ppath_ = NULL\n",
    "        pnode[0].prollout_qs[0].push_back(pnode[0].rollout_q)        \n",
    "        pnode[0].rollout_n = pnode[0].rollout_n + 1        \n",
    "    if pnode[0].pparent != NULL: \n",
    "        node_propagate(pnode[0].pparent, r, v, new_rollout, ppath=ppath_)\n",
    "\n",
    "#@cython.cdivision(True)\n",
    "cdef float[:] node_stat(Node* pnode, bool detailed, bool reward_transform):\n",
    "    cdef float[:] result = np.zeros((pnode[0].num_actions*5+5) if detailed else (pnode[0].num_actions*5+2), dtype=np.float32) \n",
    "    cdef int i\n",
    "    result[pnode[0].action] = 1. # action\n",
    "    if not reward_transform:\n",
    "        result[pnode[0].num_actions] = pnode[0].r # reward\n",
    "        result[pnode[0].num_actions+1] = pnode[0].v # value\n",
    "        for i in range(int(pnode[0].ppchildren[0].size())):\n",
    "            child = pnode[0].ppchildren[0][i][0]\n",
    "            result[pnode[0].num_actions+2+i] = child.logit # child_logits\n",
    "            result[pnode[0].num_actions*2+2+i] = average(child.prollout_qs[0]) # child_rollout_qs_mean\n",
    "            result[pnode[0].num_actions*3+2+i] = maximum(child.prollout_qs[0]) # child_rollout_qs_max\n",
    "            result[pnode[0].num_actions*4+2+i] = child.rollout_n / <float>pnode[0].rec_t # child_rollout_ns_enc\n",
    "        if detailed:\n",
    "            pnode[0].max_q = (maximum(pnode[0].prollout_qs[0]) - pnode[0].r) / pnode[0].discounting\n",
    "            result[pnode[0].num_actions*5+2] = pnode[0].trail_r / pnode[0].discounting\n",
    "            result[pnode[0].num_actions*5+3] = pnode[0].rollout_q / pnode[0].discounting\n",
    "            result[pnode[0].num_actions*5+4] = pnode[0].max_q\n",
    "    else:\n",
    "        result[pnode[0].num_actions] = enc(pnode[0].r) # reward\n",
    "        result[pnode[0].num_actions+1] = enc(pnode[0].v) # value\n",
    "        for i in range(int(pnode[0].ppchildren[0].size())):\n",
    "            child = pnode[0].ppchildren[0][i][0]\n",
    "            result[pnode[0].num_actions+2+i] = child.logit # child_logits\n",
    "            result[pnode[0].num_actions*2+2+i] = enc(average(child.prollout_qs[0])) # child_rollout_qs_mean\n",
    "            result[pnode[0].num_actions*3+2+i] = enc(maximum(child.prollout_qs[0])) # child_rollout_qs_max\n",
    "            result[pnode[0].num_actions*4+2+i] = child.rollout_n / <float>pnode[0].rec_t # child_rollout_ns_enc\n",
    "        if detailed:\n",
    "            pnode[0].max_q = (maximum(pnode[0].prollout_qs[0]) - pnode[0].r) / pnode[0].discounting\n",
    "            result[pnode[0].num_actions*5+2] = enc(pnode[0].trail_r / pnode[0].discounting)\n",
    "            result[pnode[0].num_actions*5+3] = enc(pnode[0].rollout_q / pnode[0].discounting)\n",
    "            result[pnode[0].num_actions*5+4] = enc(pnode[0].max_q)\n",
    "    return result\n",
    "\n",
    "cdef node_del(Node* pnode, int except_idx):\n",
    "    cdef int i\n",
    "    del pnode[0].prollout_qs\n",
    "\n",
    "    if pnode[0].ppaths != NULL:\n",
    "        for i in range(int(pnode[0].ppaths[0].size())):\n",
    "            del pnode[0].ppaths[0][i]\n",
    "        del pnode[0].ppaths\n",
    "\n",
    "    for i in range(int(pnode[0].ppchildren[0].size())):\n",
    "        if i != except_idx:\n",
    "            node_del(pnode[0].ppchildren[0][i], -1)\n",
    "        else:\n",
    "            pnode[0].ppchildren[0][i][0].pparent = NULL\n",
    "    del pnode[0].ppchildren\n",
    "    if pnode[0].encoded != NULL:\n",
    "        Py_DECREF(<object>pnode[0].encoded)\n",
    "    free(pnode)\n",
    "\n",
    "cdef float enc(float x):\n",
    "    return sign(x)*(sqrt(abs(x)+1)-1)+(0.001)*x\n",
    "\n",
    "cdef float sign(float x):\n",
    "    if x > 0.: return 1.\n",
    "    if x < 0.: return -1.\n",
    "    return 0.\n",
    "\n",
    "cdef float abs(float x):\n",
    "    if x > 0.: return x\n",
    "    if x < 0.: return -x\n",
    "    return 0.\n",
    "\n",
    "\n",
    "cdef class cVecFullModelWrapper():\n",
    "    \"\"\"Wrap the gym environment with a model; output for each \n",
    "    step is (out, reward, done, info), where out is a tuple \n",
    "    of (gym_env_out, model_out, model_encodes) that corresponds to underlying \n",
    "    environment frame, output from the model wrapper, and encoding from the model\n",
    "    Assume a learned dynamic model.\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    cdef int rec_t\n",
    "    cdef float discounting\n",
    "    cdef float depth_discounting\n",
    "    cdef int max_allow_depth\n",
    "    cdef bool perfect_model\n",
    "    cdef bool tree_carry\n",
    "    cdef int reward_type\n",
    "    cdef bool reward_transform\n",
    "    cdef bool actor_see_encode\n",
    "    cdef bool actor_see_double_encode    \n",
    "    cdef int num_actions\n",
    "    cdef int obs_n    \n",
    "    cdef int env_n\n",
    "    cdef bool time \n",
    "\n",
    "    # python object\n",
    "    cdef object device\n",
    "    cdef object env\n",
    "    cdef object timings\n",
    "    cdef readonly baseline_max_q\n",
    "    cdef readonly baseline_mean_q    \n",
    "    cdef readonly object model_out_shape\n",
    "    cdef readonly object gym_env_out_shape\n",
    "\n",
    "    # tree statistic\n",
    "    cdef vector[Node*] cur_nodes\n",
    "    cdef vector[Node*] root_nodes    \n",
    "    cdef float[:] root_nodes_qmax\n",
    "    cdef float[:] root_nodes_qmax_\n",
    "    cdef int[:] rollout_depth\n",
    "    cdef int[:] max_rollout_depth\n",
    "    cdef int[:] cur_t\n",
    "\n",
    "    # internal variables only used in step function\n",
    "    cdef float[:] depth_delta\n",
    "    cdef int[:] max_rollout_depth_\n",
    "    cdef float[:] mean_q\n",
    "    cdef float[:] max_q\n",
    "    cdef int[:] status\n",
    "    cdef vector[Node*] cur_nodes_\n",
    "    cdef float[:] par_logits\n",
    "    cdef float[:, :] full_reward\n",
    "    cdef bool[:] full_done\n",
    "    cdef bool[:] full_real_done\n",
    "    cdef int[:] total_step\n",
    "\n",
    "    def __init__(self, env, env_n, flags, device=None, time=False):\n",
    "        assert not flags.perfect_model, \"this class only supports imperfect model\"\n",
    "        self.device = torch.device(\"cpu\") if device is None else device\n",
    "        self.env = env     \n",
    "        self.rec_t = flags.rec_t               \n",
    "        self.discounting = flags.discounting\n",
    "        self.depth_discounting = flags.depth_discounting\n",
    "        self.max_allow_depth = flags.max_depth\n",
    "        self.perfect_model = flags.perfect_model\n",
    "        self.tree_carry = flags.tree_carry\n",
    "        self.num_actions = env.action_space[0].n\n",
    "        self.reward_type = flags.reward_type\n",
    "        self.reward_transform = flags.reward_transform\n",
    "        self.actor_see_encode = flags.actor_see_encode  \n",
    "        self.actor_see_double_encode = flags.actor_see_double_encode\n",
    "        self.env_n = env_n\n",
    "        self.obs_n = 9 + self.num_actions * 10 + self.rec_t\n",
    "        self.model_out_shape = (self.obs_n, 1, 1)\n",
    "        self.gym_env_out_shape = env.observation_space.shape[1:]\n",
    "\n",
    "        self.baseline_max_q = torch.zeros(self.env_n, dtype=torch.float32, device=self.device)\n",
    "        self.baseline_mean_q = torch.zeros(self.env_n, dtype=torch.float32, device=self.device)        \n",
    "        self.time = time\n",
    "        self.timings = util.Timings()\n",
    "\n",
    "        # internal variable init.\n",
    "        self.depth_delta = np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.max_rollout_depth_ = np.zeros(self.env_n, dtype=np.intc)\n",
    "        self.mean_q =  np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.max_q = np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.status = np.zeros(self.env_n, dtype=np.intc)\n",
    "        self.par_logits = np.zeros(self.num_actions, dtype=np.float32)\n",
    "        self.full_reward = np.zeros((self.env_n, 2 if self.reward_type == 1 else 1), dtype=np.float32)\n",
    "        self.full_done = np.zeros(self.env_n, dtype=np.bool)\n",
    "        self.full_real_done = np.zeros(self.env_n, dtype=np.bool)\n",
    "        self.total_step = np.zeros(self.env_n, dtype=np.intc)\n",
    "        \n",
    "    def reset(self, model_net):\n",
    "        \"\"\"reset the environment; should only be called in the initial\"\"\"\n",
    "        cdef int i\n",
    "        cdef Node* root_node\n",
    "        cdef Node* cur_node\n",
    "        cdef float[:,:] model_out        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            # some init.\n",
    "            self.root_nodes_qmax = np.zeros(self.env_n, dtype=np.float32)\n",
    "            self.root_nodes_qmax_ = np.zeros(self.env_n, dtype=np.float32)\n",
    "            self.rollout_depth = np.zeros(self.env_n, dtype=np.intc)\n",
    "            self.max_rollout_depth = np.zeros(self.env_n, dtype=np.intc)\n",
    "            self.cur_t = np.zeros(self.env_n, dtype=np.intc)\n",
    "\n",
    "            # reset obs\n",
    "            obs = self.env.reset()\n",
    "\n",
    "            # obtain output from model\n",
    "            obs_py = torch.tensor(obs, dtype=torch.uint8, device=self.device)\n",
    "            pass_action = torch.zeros(self.env_n, dtype=torch.long)\n",
    "            _, _, vs, _, logits, model_encodes = model_net(obs_py, \n",
    "                                                pass_action.unsqueeze(0).to(self.device), \n",
    "                                                one_hot=False)  \n",
    "            vs = vs.cpu()\n",
    "            logits = logits.cpu()\n",
    "\n",
    "            # compute and update root node and current node\n",
    "            for i in range(self.env_n):\n",
    "                root_node = node_new(pparent=NULL, action=pass_action[i].item(), logit=0., num_actions=self.num_actions, \n",
    "                    discounting=self.discounting, rec_t=self.rec_t, remember_path=True)                \n",
    "                encoded = {\"gym_env_out\": obs_py[i], \"model_encodes\": model_encodes[-1,i]}\n",
    "                node_expand(pnode=root_node, r=0., v=vs[-1, i].item(), t=self.total_step[i], done=False,\n",
    "                    logits=logits[-1, i].numpy(), encoded=<PyObject*>encoded, override=False)\n",
    "                node_visit(pnode=root_node)\n",
    "                self.root_nodes.push_back(root_node)\n",
    "                self.cur_nodes.push_back(root_node)\n",
    "            \n",
    "            # compute model_out\n",
    "            model_out = self.compute_model_out(None, None)\n",
    "\n",
    "            gym_env_out = []\n",
    "            for i in range(self.env_n):\n",
    "                encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                if encoded[\"gym_env_out\"] is not None:\n",
    "                    gym_env_out.append(encoded[\"gym_env_out\"].unsqueeze(0))\n",
    "            if len(gym_env_out) > 0:\n",
    "                gym_env_out = torch.concat(gym_env_out)\n",
    "            else:\n",
    "                gym_env_out = None\n",
    "\n",
    "            if self.actor_see_encode:\n",
    "                model_encodes = []\n",
    "                for i in range(self.env_n):\n",
    "                    encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                    model_encodes.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "                model_encodes = torch.concat(model_encodes)\n",
    "\n",
    "                if self.actor_see_double_encode:\n",
    "                    model_encodes = torch.concat([model_encodes, model_encodes], dim=1)\n",
    "            else:\n",
    "                model_encodes = None\n",
    "\n",
    "            # record initial root_nodes_qmax \n",
    "            for i in range(self.env_n):\n",
    "                self.root_nodes_qmax[i] = self.root_nodes[i][0].max_q\n",
    "            \n",
    "            return torch.tensor(model_out, dtype=torch.float32, device=self.device), gym_env_out, model_encodes\n",
    "\n",
    "    def step(self, action, model_net):  \n",
    "        # action is tensor of shape (env_n, 3)\n",
    "        # which corresponds to real_action, im_action, reset, term\n",
    "        \n",
    "        cdef int i, j, k, l\n",
    "        cdef int[:] re_action\n",
    "        cdef int[:] im_action\n",
    "        cdef int[:] reset\n",
    "\n",
    "        cdef Node* root_node\n",
    "        cdef Node* cur_node\n",
    "        cdef Node* next_node\n",
    "        cdef vector[Node*] cur_nodes_\n",
    "        cdef vector[Node*] root_nodes_    \n",
    "        cdef float[:,:] model_out        \n",
    "\n",
    "        cdef vector[int] pass_inds_restore\n",
    "        cdef vector[int] pass_inds_step\n",
    "        cdef vector[int] pass_inds_reset\n",
    "        cdef vector[int] pass_inds_reset_\n",
    "        cdef vector[int] pass_action\n",
    "        cdef vector[int] pass_model_action\n",
    "\n",
    "        cdef float[:] vs_1\n",
    "        cdef float[:,:] logits_1\n",
    "\n",
    "        cdef float[:] rs_4\n",
    "        cdef float[:] vs_4\n",
    "        cdef float[:,:] logits_4\n",
    "\n",
    "        if self.time: self.timings.reset()\n",
    "        action = action.cpu().int().numpy()\n",
    "        re_action, im_action, reset = action[:, 0], action[:, 1], action[:, 2]\n",
    "\n",
    "        pass_model_encodes = []\n",
    "\n",
    "        for i in range(self.env_n):            \n",
    "            # compute the mask of real / imagination step                             \n",
    "            self.max_rollout_depth_[i] = self.max_rollout_depth[i]\n",
    "            self.depth_delta[i] = self.depth_discounting ** self.rollout_depth[i]\n",
    "            if self.cur_t[i] < self.rec_t - 1: # imagaination step\n",
    "                self.cur_t[i] += 1\n",
    "                self.rollout_depth[i] += 1\n",
    "                self.max_rollout_depth[i] = max(self.max_rollout_depth[i], self.rollout_depth[i])\n",
    "                next_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                if node_expanded(next_node, self.total_step[i]):\n",
    "                    self.status[i] = 2\n",
    "                else:\n",
    "                    encoded = <dict> self.cur_nodes[i][0].encoded\n",
    "                    pass_model_encodes.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "                    pass_model_action.push_back(im_action[i])\n",
    "                    self.status[i] = 4  \n",
    "            else: # real step\n",
    "                self.cur_t[i] = 0\n",
    "                self.rollout_depth[i] = 0          \n",
    "                self.max_rollout_depth[i] = 0\n",
    "                self.total_step[i] = self.total_step[i] + 1\n",
    "                # record baseline before moving on\n",
    "                self.baseline_mean_q[i] = average(self.root_nodes[i][0].prollout_qs[0]) / self.discounting\n",
    "                self.baseline_max_q[i] = maximum(self.root_nodes[i][0].prollout_qs[0]) / self.discounting\n",
    "                encoded = <dict> self.root_nodes[i][0].encoded\n",
    "                pass_inds_restore.push_back(i)\n",
    "                pass_action.push_back(re_action[i])\n",
    "                pass_inds_step.push_back(i)\n",
    "                self.status[i] = 1                              \n",
    "        if self.time: self.timings.time(\"misc_1\")\n",
    "\n",
    "        # one step of env\n",
    "        if pass_inds_step.size() > 0:\n",
    "            obs, reward, done, info = self.env.step(pass_action, inds=pass_inds_step) \n",
    "            real_done = [m[\"real_done\"] if \"real_done\" in m else done[n] for n, m in enumerate(info)]\n",
    "        if self.time: self.timings.time(\"step_state\")\n",
    "\n",
    "        # reset needed?\n",
    "        for i, j in enumerate(pass_inds_step):\n",
    "            if done[i]:\n",
    "                pass_inds_reset.push_back(j)\n",
    "                pass_inds_reset_.push_back(i) # index within pass_inds_step\n",
    "\n",
    "        # reset\n",
    "        if pass_inds_reset.size() > 0:\n",
    "            obs_reset = self.env.reset(inds=pass_inds_reset) \n",
    "            for i, j in enumerate(pass_inds_reset_):\n",
    "                obs[j] = obs_reset[i]\n",
    "                pass_action[j] = 0        \n",
    "\n",
    "        # use model for status 1 transition (real transition)\n",
    "        if pass_inds_step.size() > 0:\n",
    "            with torch.no_grad():\n",
    "                obs_py = torch.tensor(obs, dtype=torch.uint8, device=self.device)\n",
    "                _, _, vs_, _, logits_, model_encodes_1 = model_net(obs_py, \n",
    "                        torch.tensor(pass_action, dtype=long, device=self.device).unsqueeze(0), \n",
    "                        one_hot=False)  \n",
    "            vs_1 = vs_[-1].float().cpu().numpy()\n",
    "            logits_1 = logits_[-1].float().cpu().numpy()\n",
    "                \n",
    "        if self.time: self.timings.time(\"misc_2\")\n",
    "        # use model for status 4 transition (imagination transition)\n",
    "        if pass_model_action.size() > 0:\n",
    "            with torch.no_grad():\n",
    "                pass_model_encodes = torch.concat(pass_model_encodes)\n",
    "                rs_, _, vs_, _, logits_, model_encodes_4 = model_net.forward_encoded(encoded=pass_model_encodes,                        \n",
    "                        actions = torch.tensor(pass_model_action, dtype=long, device=self.device).unsqueeze(0), \n",
    "                        one_hot=False)  \n",
    "            rs_4 = rs_[-1].float().cpu().numpy()\n",
    "            vs_4 = vs_[-1].float().cpu().numpy()\n",
    "            logits_4 = logits_[-1].float().cpu().numpy()\n",
    "\n",
    "        # compute the current and root nodes\n",
    "        j = 0 # counter for status 1 transition\n",
    "        l = 0 # counter for status 4 transition\n",
    "\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                # real transition\n",
    "                new_root = (not self.tree_carry or \n",
    "                    not node_expanded(self.root_nodes[i][0].ppchildren[0][re_action[i]], -1) or done[j])\n",
    "                if new_root:\n",
    "                    root_node = node_new(pparent=NULL, action=pass_action[j], logit=0., num_actions=self.num_actions, \n",
    "                        discounting=self.discounting, rec_t=self.rec_t, remember_path=True)\n",
    "                    encoded = {\"gym_env_out\": obs_py[j], \"model_encodes\": model_encodes_1[-1,j]}\n",
    "                    node_expand(pnode=root_node, r=0., v=vs_1[j], t=self.total_step[i], done=False,\n",
    "                        logits=logits_1[j], encoded=<PyObject*>encoded, override=False)\n",
    "                    node_del(self.root_nodes[i], except_idx=-1)\n",
    "                    node_visit(root_node)\n",
    "                else:\n",
    "                    root_node = self.root_nodes[i][0].ppchildren[0][re_action[i]]\n",
    "                    encoded = {\"gym_env_out\": obs_py[j], \"model_encodes\": model_encodes_1[-1,j]}\n",
    "                    node_expand(pnode=root_node, r=0., v=vs_1[j], t=self.total_step[i], done=False,\n",
    "                        logits=logits_1[j], encoded=<PyObject*>encoded, override=True)                        \n",
    "                    node_del(self.root_nodes[i], except_idx=re_action[i])\n",
    "                    node_visit(root_node)\n",
    "                    \n",
    "                j += 1\n",
    "                root_nodes_.push_back(root_node)\n",
    "                cur_nodes_.push_back(root_node)\n",
    "\n",
    "            elif self.status[i] == 2:\n",
    "                # expanded already\n",
    "                cur_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                node_visit(cur_node)\n",
    "                root_nodes_.push_back(self.root_nodes[i])\n",
    "                cur_nodes_.push_back(cur_node)             \n",
    "            \n",
    "            elif self.status[i] == 4:\n",
    "                # need expand\n",
    "                encoded = {\"gym_env_out\": None, \"model_encodes\": model_encodes_4[-1,l]}\n",
    "                cur_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                node_expand(pnode=cur_node, r=rs_4[l], v=vs_4[l], t=self.total_step[i], done=False,\n",
    "                        logits=logits_4[l], encoded=<PyObject*>encoded, override=True)\n",
    "                node_visit(cur_node)\n",
    "                root_nodes_.push_back(self.root_nodes[i])\n",
    "                cur_nodes_.push_back(cur_node)   \n",
    "                l += 1             \n",
    "        self.root_nodes = root_nodes_\n",
    "        self.cur_nodes = cur_nodes_\n",
    "        if self.time: self.timings.time(\"compute_root_cur_nodes\")\n",
    "\n",
    "        # reset if serach depth exceeds max depth\n",
    "        if self.max_allow_depth > 0:\n",
    "            for i in range(self.env_n):\n",
    "                if self.rollout_depth[i] >= self.max_allow_depth:\n",
    "                    action[i, 2] = 1\n",
    "                    reset[i] = 1\n",
    "\n",
    "        # compute model_out        \n",
    "        model_out = self.compute_model_out(action, self.status)\n",
    "        gym_env_out = []\n",
    "        for i in range(self.env_n):\n",
    "            encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "            if encoded[\"gym_env_out\"] is not None:\n",
    "                gym_env_out.append(encoded[\"gym_env_out\"].unsqueeze(0))\n",
    "        if len(gym_env_out) > 0:\n",
    "            gym_env_out = torch.concat(gym_env_out)\n",
    "        else:\n",
    "            gym_env_out = None\n",
    "\n",
    "        if self.actor_see_encode:\n",
    "            model_encodes = []\n",
    "            for i in range(self.env_n):\n",
    "                encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                model_encodes.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "            model_encodes = torch.concat(model_encodes)\n",
    "            if self.actor_see_double_encode:\n",
    "                model_encodes_ = []\n",
    "                for i in range(self.env_n):\n",
    "                    encoded = <dict>self.root_nodes[i][0].encoded\n",
    "                    model_encodes_.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "                model_encodes_ = torch.concat(model_encodes_)\n",
    "                model_encodes = torch.concat([model_encodes, model_encodes_], dim=1)\n",
    "        else:\n",
    "            model_encodes = None\n",
    "\n",
    "        if self.time: self.timings.time(\"compute_model_out\")\n",
    "        # compute reward\n",
    "        j = 0\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                self.full_reward[i][0] = reward[j]\n",
    "            else:\n",
    "                self.full_reward[i][0] = 0.\n",
    "            if self.reward_type == 1:                        \n",
    "                self.root_nodes_qmax_[i] = self.root_nodes[i][0].max_q\n",
    "                if self.status[i] != 1:                \n",
    "                    self.full_reward[i][1] = (self.root_nodes_qmax_[i] - self.root_nodes_qmax[i])*self.depth_delta[i]\n",
    "                    if self.full_reward[i][1] < 0: self.full_reward[i][1] = 0\n",
    "                else:\n",
    "                    self.full_reward[i][1] = 0.\n",
    "                self.root_nodes_qmax[i] = self.root_nodes_qmax_[i]\n",
    "            if self.status[i] == 1:\n",
    "                j += 1\n",
    "        if self.time: self.timings.time(\"compute_reward\")\n",
    "        # compute done & full_real_done\n",
    "        j = 0\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                self.full_done[i] = done[j]\n",
    "                self.full_real_done[i] = real_done[j]\n",
    "            else:\n",
    "                self.full_done[i] = False\n",
    "                self.full_real_done[i] = False\n",
    "            if self.status[i] == 1:\n",
    "                j += 1\n",
    "        # compute reset\n",
    "        for i in range(self.env_n):\n",
    "            if reset[i]:\n",
    "                self.rollout_depth[i] = 0\n",
    "                self.cur_nodes[i] = self.root_nodes[i]\n",
    "                node_visit(self.cur_nodes[i])\n",
    "                self.status[i] = 5 \n",
    "        # some extra info\n",
    "        info = {\"cur_t\": torch.tensor(self.cur_t, dtype=torch.long, device=self.device),\n",
    "                \"max_rollout_depth\":  torch.tensor(self.max_rollout_depth_, dtype=torch.long, device=self.device),\n",
    "                \"real_done\": torch.tensor(self.full_real_done, dtype=torch.bool, device=self.device)}\n",
    "        if self.time: self.timings.time(\"end\")\n",
    "\n",
    "        return ((torch.tensor(model_out, dtype=torch.float32, device=self.device), gym_env_out, model_encodes), \n",
    "                torch.tensor(self.full_reward, dtype=torch.float32, device=self.device), \n",
    "                torch.tensor(self.full_done, dtype=torch.bool, device=self.device), \n",
    "                info)\n",
    "\n",
    "    \n",
    "    cdef float[:, :] compute_model_out(self, int[:, :]& action, int[:]& status):\n",
    "        cdef int i\n",
    "        cdef int idx1 = self.num_actions*5+5\n",
    "        cdef int idx2 = self.num_actions*10+7\n",
    "\n",
    "        result_np = np.zeros((self.env_n, self.obs_n), dtype=np.float32)\n",
    "        cdef float[:, :] result = result_np        \n",
    "        for i in range(self.env_n):\n",
    "            result[i, :idx1] = node_stat(self.root_nodes[i], detailed=True, reward_transform=self.reward_transform)\n",
    "            result[i, idx1:idx2] = node_stat(self.cur_nodes[i], detailed=False, reward_transform=self.reward_transform)    \n",
    "            # reset\n",
    "            if action is None or status[i] == 1:\n",
    "                result[i, idx2] = 1.\n",
    "            else:\n",
    "                result[i, idx2] = action[i, 2]\n",
    "            # time\n",
    "            result[i, idx2+1+self.cur_t[i]] = 1.\n",
    "            # deprec\n",
    "            result[i, idx2+self.rec_t+1] = (self.discounting ** (self.rollout_depth[i]))           \n",
    "        return result\n",
    "\n",
    "    def close(self):\n",
    "        cdef int i\n",
    "        if hasattr(self, \"root_nodes\"):\n",
    "            for i in range(self.env_n):\n",
    "                node_del(self.root_nodes[i], except_idx=-1)\n",
    "        self.env.close()\n",
    "\n",
    "    def seed(self, x):\n",
    "        self.env.seed(x)\n",
    "\n",
    "    def print_time(self):\n",
    "        print(self.timings.summary())\n",
    "\n",
    "    def clone_state(self):\n",
    "        return self.env.clone_state()\n",
    "\n",
    "    def restore_state(self, state):\n",
    "        self.env.restore_state(state)\n",
    "\n",
    "    def get_action_meanings(self):\n",
    "        return self.env.get_action_meanings()       \n",
    "\n",
    "cdef class cVecModelWrapper():\n",
    "    \"\"\"Wrap the gym environment with a model; output for each \n",
    "    step is (out, reward, done, info), where out is a tuple \n",
    "    of (gym_env_out, model_out, model_encodes) that corresponds to underlying \n",
    "    environment frame, output from the model wrapper, and encoding from the model\n",
    "    Assume a perfect dynamic model.\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    cdef int rec_t\n",
    "    cdef float discounting\n",
    "    cdef float depth_discounting\n",
    "    cdef int max_allow_depth\n",
    "    cdef bool perfect_model\n",
    "    cdef bool tree_carry\n",
    "    cdef int reward_type\n",
    "    cdef bool reward_transform\n",
    "    cdef bool actor_see_encode\n",
    "    cdef bool actor_see_double_encode\n",
    "    cdef int num_actions\n",
    "    cdef int obs_n    \n",
    "    cdef int env_n\n",
    "    cdef bool time \n",
    "\n",
    "    # python object\n",
    "    cdef object device\n",
    "    cdef object env\n",
    "    cdef object timings\n",
    "    cdef readonly baseline_max_q\n",
    "    cdef readonly baseline_mean_q    \n",
    "    cdef readonly object model_out_shape\n",
    "    cdef readonly object gym_env_out_shape\n",
    "\n",
    "    # tree statistic\n",
    "    cdef vector[Node*] cur_nodes\n",
    "    cdef vector[Node*] root_nodes    \n",
    "    cdef float[:] root_nodes_qmax\n",
    "    cdef float[:] root_nodes_qmax_\n",
    "    cdef int[:] rollout_depth\n",
    "    cdef int[:] max_rollout_depth\n",
    "    cdef int[:] cur_t\n",
    "\n",
    "    # internal variables only used in step function\n",
    "    cdef float[:] depth_delta\n",
    "    cdef int[:] max_rollout_depth_\n",
    "    cdef float[:] mean_q\n",
    "    cdef float[:] max_q\n",
    "    cdef int[:] status\n",
    "    cdef vector[Node*] cur_nodes_\n",
    "    cdef float[:] par_logits\n",
    "    cdef float[:, :] full_reward\n",
    "    cdef bool[:] full_done\n",
    "    cdef bool[:] full_real_done\n",
    "    cdef int[:] total_step\n",
    "\n",
    "    def __init__(self, env, env_n, flags, device=None, time=False):\n",
    "        assert flags.perfect_model, \"this class only supports perfect model\"\n",
    "        self.device = torch.device(\"cpu\") if device is None else device\n",
    "        self.env = env     \n",
    "        self.rec_t = flags.rec_t               \n",
    "        self.discounting = flags.discounting\n",
    "        self.depth_discounting = flags.depth_discounting\n",
    "        self.max_allow_depth = flags.max_depth\n",
    "        self.perfect_model = flags.perfect_model\n",
    "        self.tree_carry = flags.tree_carry\n",
    "        self.num_actions = env.action_space[0].n\n",
    "        self.reward_type = flags.reward_type\n",
    "        self.reward_transform = flags.reward_transform\n",
    "        self.actor_see_encode = flags.actor_see_encode      \n",
    "        self.actor_see_double_encode = flags.actor_see_double_encode  \n",
    "        self.env_n = env_n\n",
    "        self.obs_n = 9 + self.num_actions * 10 + self.rec_t\n",
    "        self.model_out_shape = (self.obs_n, 1, 1)\n",
    "        self.gym_env_out_shape = env.observation_space.shape[1:]\n",
    "\n",
    "        self.baseline_max_q = torch.zeros(self.env_n, dtype=torch.float32, device=self.device)\n",
    "        self.baseline_mean_q = torch.zeros(self.env_n, dtype=torch.float32, device=self.device)        \n",
    "        self.time = time\n",
    "        self.timings = util.Timings()\n",
    "\n",
    "        # internal variable init.\n",
    "        self.depth_delta = np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.max_rollout_depth_ = np.zeros(self.env_n, dtype=np.intc)\n",
    "        self.mean_q =  np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.max_q = np.zeros(self.env_n, dtype=np.float32)\n",
    "        self.status = np.zeros(self.env_n, dtype=np.intc)\n",
    "        self.par_logits = np.zeros(self.num_actions, dtype=np.float32)\n",
    "        self.full_reward = np.zeros((self.env_n, 2 if self.reward_type == 1 else 1), dtype=np.float32)\n",
    "        self.full_done = np.zeros(self.env_n, dtype=np.bool)\n",
    "        self.full_real_done = np.zeros(self.env_n, dtype=np.bool)\n",
    "        self.total_step = np.zeros(self.env_n, dtype=np.intc)\n",
    "        \n",
    "    def reset(self, model_net):\n",
    "        \"\"\"reset the environment; should only be called in the initial\"\"\"\n",
    "        cdef int i\n",
    "        cdef Node* root_node\n",
    "        cdef Node* cur_node\n",
    "        cdef float[:,:] model_out        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            # some init.\n",
    "            self.root_nodes_qmax = np.zeros(self.env_n, dtype=np.float32)\n",
    "            self.root_nodes_qmax_ = np.zeros(self.env_n, dtype=np.float32)\n",
    "            self.rollout_depth = np.zeros(self.env_n, dtype=np.intc)\n",
    "            self.max_rollout_depth = np.zeros(self.env_n, dtype=np.intc)\n",
    "            self.cur_t = np.zeros(self.env_n, dtype=np.intc)\n",
    "\n",
    "            # reset obs\n",
    "            obs = self.env.reset()\n",
    "\n",
    "            # obtain output from model\n",
    "            obs_py = torch.tensor(obs, dtype=torch.uint8, device=self.device)\n",
    "            pass_action = torch.zeros(self.env_n, dtype=torch.long)\n",
    "            _, _, vs, _, logits, model_encodes = model_net(obs_py, \n",
    "                                                pass_action.unsqueeze(0).to(self.device), \n",
    "                                                one_hot=False)  \n",
    "            vs = vs.cpu()\n",
    "            logits = logits.cpu()\n",
    "            env_state = self.env.clone_state(inds=np.arange(self.env_n))\n",
    "\n",
    "            # compute and update root node and current node\n",
    "            for i in range(self.env_n):\n",
    "                root_node = node_new(pparent=NULL, action=pass_action[i].item(), logit=0., num_actions=self.num_actions, \n",
    "                    discounting=self.discounting, rec_t=self.rec_t, remember_path=False)                \n",
    "                if not self.actor_see_encode:\n",
    "                    encoded = {\"env_state\": env_state[i], \"gym_env_out\": obs_py[i]}\n",
    "                else:\n",
    "                    encoded = {\"env_state\": env_state[i], \"gym_env_out\": obs_py[i], \"model_encodes\": model_encodes[0,i]}\n",
    "                node_expand(pnode=root_node, r=0., v=vs[-1, i].item(), t=self.total_step[i], done=False,\n",
    "                    logits=logits[-1, i].numpy(), encoded=<PyObject*>encoded, override=False)\n",
    "                node_visit(pnode=root_node)\n",
    "                self.root_nodes.push_back(root_node)\n",
    "                self.cur_nodes.push_back(root_node)\n",
    "            \n",
    "            # compute model_out\n",
    "            model_out = self.compute_model_out(None, None)\n",
    "\n",
    "            gym_env_out = []\n",
    "            for i in range(self.env_n):\n",
    "                encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                gym_env_out.append(encoded[\"gym_env_out\"].unsqueeze(0))\n",
    "            gym_env_out = torch.concat(gym_env_out)\n",
    "\n",
    "            if self.actor_see_encode:\n",
    "                model_encodes = []\n",
    "                for i in range(self.env_n):\n",
    "                    encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                    model_encodes.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "                model_encodes = torch.concat(model_encodes)\n",
    "\n",
    "                if self.actor_see_double_encode:\n",
    "                    model_encodes = torch.concat([model_encodes, model_encodes], dim=1)\n",
    "                \n",
    "            else:\n",
    "                model_encodes = None\n",
    "\n",
    "            # record initial root_nodes_qmax \n",
    "            for i in range(self.env_n):\n",
    "                self.root_nodes_qmax[i] = self.root_nodes[i][0].max_q\n",
    "            \n",
    "            return torch.tensor(model_out, dtype=torch.float32, device=self.device), gym_env_out, model_encodes\n",
    "\n",
    "    def step(self, action, model_net):  \n",
    "        # action is tensor of shape (env_n, 3)\n",
    "        # which corresponds to real_action, im_action, reset, term\n",
    "\n",
    "        cdef int i, j, k\n",
    "        cdef int[:] re_action\n",
    "        cdef int[:] im_action\n",
    "        cdef int[:] reset\n",
    "\n",
    "        cdef Node* root_node\n",
    "        cdef Node* cur_node\n",
    "        cdef Node* next_node\n",
    "        cdef vector[Node*] cur_nodes_\n",
    "        cdef vector[Node*] root_nodes_    \n",
    "        cdef float[:,:] model_out        \n",
    "\n",
    "        cdef vector[int] pass_inds_restore\n",
    "        cdef vector[int] pass_inds_step\n",
    "        cdef vector[int] pass_inds_reset\n",
    "        cdef vector[int] pass_inds_reset_\n",
    "        cdef vector[int] pass_action\n",
    "\n",
    "        cdef float[:] vs\n",
    "        cdef float[:,:] logits\n",
    "\n",
    "        if self.time: self.timings.reset()\n",
    "        action = action.cpu().int().numpy()\n",
    "        re_action, im_action, reset = action[:, 0], action[:, 1], action[:, 2]\n",
    "\n",
    "        pass_env_states = []\n",
    "\n",
    "        for i in range(self.env_n):            \n",
    "            # compute the mask of real / imagination step                             \n",
    "            self.max_rollout_depth_[i] = self.max_rollout_depth[i]\n",
    "            self.depth_delta[i] = self.depth_discounting ** self.rollout_depth[i]\n",
    "            if self.cur_t[i] < self.rec_t - 1: # imagaination step\n",
    "                self.cur_t[i] += 1\n",
    "                self.rollout_depth[i] += 1\n",
    "                self.max_rollout_depth[i] = max(self.max_rollout_depth[i], self.rollout_depth[i])\n",
    "                next_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                if node_expanded(next_node, -1):\n",
    "                    self.status[i] = 2\n",
    "                elif self.cur_nodes[i][0].done:\n",
    "                    self.status[i] = 3\n",
    "                else:\n",
    "                    if self.status[i] != 0 or self.status[i] != 4: # no need restore if last step is real or just expanded\n",
    "                        encoded = <dict> self.cur_nodes[i][0].encoded\n",
    "                        pass_env_states.append(encoded[\"env_state\"])\n",
    "                        pass_inds_restore.push_back(i)\n",
    "                        pass_action.push_back(im_action[i])\n",
    "                        pass_inds_step.push_back(i)\n",
    "                    self.status[i] = 4  \n",
    "            else: # real step\n",
    "                self.cur_t[i] = 0\n",
    "                self.rollout_depth[i] = 0          \n",
    "                self.max_rollout_depth[i] = 0\n",
    "                self.total_step[i] = self.total_step[i] + 1\n",
    "                # record baseline before moving on\n",
    "                self.baseline_mean_q[i] = average(self.root_nodes[i][0].prollout_qs[0]) / self.discounting\n",
    "                self.baseline_max_q[i] = maximum(self.root_nodes[i][0].prollout_qs[0]) / self.discounting\n",
    "                encoded = <dict> self.root_nodes[i][0].encoded\n",
    "                pass_env_states.append(encoded[\"env_state\"])\n",
    "                pass_inds_restore.push_back(i)\n",
    "                pass_action.push_back(re_action[i])\n",
    "                pass_inds_step.push_back(i)\n",
    "                self.status[i] = 1                              \n",
    "        if self.time: self.timings.time(\"misc_1\")\n",
    "\n",
    "        # restore env      \n",
    "        if pass_inds_restore.size() > 0:\n",
    "            self.env.restore_state(pass_env_states, inds=pass_inds_restore)\n",
    "\n",
    "        # one step of env\n",
    "        if pass_inds_step.size() > 0:\n",
    "            obs, reward, done, info = self.env.step(pass_action, inds=pass_inds_step) \n",
    "            real_done = [m[\"real_done\"] if \"real_done\" in m else done[n] for n, m in enumerate(info)]\n",
    "        if self.time: self.timings.time(\"step_state\")\n",
    "\n",
    "        # reset needed?\n",
    "        for i, j in enumerate(pass_inds_step):\n",
    "            if self.status[j] == 1 and done[i]:\n",
    "                pass_inds_reset.push_back(j)\n",
    "                pass_inds_reset_.push_back(i) # index within pass_inds_step\n",
    "        # reset\n",
    "        if pass_inds_reset.size() > 0:\n",
    "            obs_reset = self.env.reset(inds=pass_inds_reset) \n",
    "            for i, j in enumerate(pass_inds_reset_):\n",
    "                obs[j] = obs_reset[i]\n",
    "                pass_action[j] = 0            \n",
    "        if self.time: self.timings.time(\"misc_2\")\n",
    "\n",
    "        # use model\n",
    "        if pass_inds_step.size() > 0:\n",
    "            with torch.no_grad():\n",
    "                obs_py = torch.tensor(obs, dtype=torch.uint8, device=self.device)\n",
    "                _, _, vs_, _, logits_, model_encodes = model_net(obs_py, \n",
    "                        torch.tensor(pass_action, dtype=long, device=self.device).unsqueeze(0), \n",
    "                        one_hot=False)  \n",
    "            vs = vs_[-1].float().cpu().numpy()\n",
    "            logits = logits_[-1].float().cpu().numpy()\n",
    "            if self.time: self.timings.time(\"model\")\n",
    "            env_state = self.env.clone_state(inds=pass_inds_step)   \n",
    "            if self.time: self.timings.time(\"clone_state\")\n",
    "\n",
    "        # compute the current and root nodes\n",
    "        j = 0\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                # real transition\n",
    "                new_root = (not self.tree_carry or \n",
    "                    not node_expanded(self.root_nodes[i][0].ppchildren[0][re_action[i]], -1) or done[j])\n",
    "                if new_root:\n",
    "                    root_node = node_new(pparent=NULL, action=pass_action[j], logit=0., num_actions=self.num_actions, \n",
    "                        discounting=self.discounting, rec_t=self.rec_t, remember_path=False)\n",
    "                    if not self.actor_see_encode:\n",
    "                        encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j]}\n",
    "                    else:\n",
    "                        encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j], \"model_encodes\": model_encodes[0,j]}\n",
    "                    node_expand(pnode=root_node, r=0., v=vs[j], t=self.total_step[i], done=False,\n",
    "                        logits=logits[j], encoded=<PyObject*>encoded, override=False)\n",
    "                    node_del(self.root_nodes[i], except_idx=-1)\n",
    "                    node_visit(root_node)\n",
    "                else:\n",
    "                    root_node = self.root_nodes[i][0].ppchildren[0][re_action[i]]\n",
    "                    if not self.actor_see_encode:\n",
    "                        encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j]}\n",
    "                    else:\n",
    "                        encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j], \"model_encodes\": model_encodes[0,j]}\n",
    "                    node_expand(pnode=root_node, r=0., v=vs[j], t=self.total_step[i], done=False,\n",
    "                        logits=logits[j], encoded=<PyObject*>encoded, override=True)                        \n",
    "                    node_del(self.root_nodes[i], except_idx=re_action[i])\n",
    "                    node_visit(root_node)\n",
    "                    \n",
    "                j += 1\n",
    "                root_nodes_.push_back(root_node)\n",
    "                cur_nodes_.push_back(root_node)\n",
    "\n",
    "            elif self.status[i] == 2:\n",
    "                # expanded already\n",
    "                cur_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                node_visit(cur_node)\n",
    "                root_nodes_.push_back(self.root_nodes[i])\n",
    "                cur_nodes_.push_back(cur_node)    \n",
    "\n",
    "            elif self.status[i] == 3:\n",
    "                # done already\n",
    "                for k in range(self.num_actions):\n",
    "                    self.par_logits[k] = self.cur_nodes[i].ppchildren[0][k][0].logit\n",
    "                cur_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                node_expand(pnode=cur_node, r=0., v=0., t=self.total_step[i], done=True,\n",
    "                        logits=self.par_logits, encoded=self.cur_nodes[i][0].encoded, override=False)\n",
    "                node_visit(cur_node)\n",
    "                root_nodes_.push_back(self.root_nodes[i])\n",
    "                cur_nodes_.push_back(cur_node)              \n",
    "            \n",
    "            elif self.status[i] == 4:\n",
    "                # need expand\n",
    "                if not self.actor_see_encode:\n",
    "                    encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j]}\n",
    "                else:\n",
    "                    encoded = {\"env_state\": env_state[j], \"gym_env_out\": obs_py[j], \"model_encodes\": model_encodes[0,j]}\n",
    "                cur_node = self.cur_nodes[i][0].ppchildren[0][im_action[i]]\n",
    "                node_expand(pnode=cur_node, r=reward[j], v=vs[j] if not done[j] else 0., t=self.total_step[i], done=done[j],\n",
    "                        logits=logits[j], encoded=<PyObject*>encoded, override=False)\n",
    "                node_visit(cur_node)\n",
    "                root_nodes_.push_back(self.root_nodes[i])\n",
    "                cur_nodes_.push_back(cur_node)   \n",
    "                j += 1                            \n",
    "\n",
    "        self.root_nodes = root_nodes_\n",
    "        self.cur_nodes = cur_nodes_\n",
    "        if self.time: self.timings.time(\"compute_root_cur_nodes\")\n",
    "\n",
    "        # reset if serach depth exceeds max depth\n",
    "        if self.max_allow_depth > 0:\n",
    "            for i in range(self.env_n):\n",
    "                if self.rollout_depth[i] >= self.max_allow_depth:\n",
    "                    action[i, 2] = 1\n",
    "                    reset[i] = 1\n",
    "\n",
    "        # compute model_out        \n",
    "        model_out = self.compute_model_out(action, self.status)\n",
    "\n",
    "        gym_env_out = []\n",
    "        for i in range(self.env_n):\n",
    "            encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "            gym_env_out.append(encoded[\"gym_env_out\"].unsqueeze(0))\n",
    "        gym_env_out = torch.concat(gym_env_out)\n",
    "\n",
    "        if self.actor_see_encode:\n",
    "            model_encodes = []\n",
    "            for i in range(self.env_n):\n",
    "                encoded = <dict>self.cur_nodes[i][0].encoded\n",
    "                model_encodes.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "            model_encodes = torch.concat(model_encodes)\n",
    "\n",
    "            if self.actor_see_double_encode:\n",
    "                model_encodes_ = []\n",
    "                for i in range(self.env_n):\n",
    "                    encoded = <dict>self.root_nodes[i][0].encoded\n",
    "                    model_encodes_.append(encoded[\"model_encodes\"].unsqueeze(0))\n",
    "                model_encodes_ = torch.concat(model_encodes_)\n",
    "                model_encodes = torch.concat([model_encodes, model_encodes_], dim=1)\n",
    "        else:\n",
    "            model_encodes = None\n",
    "\n",
    "        if self.time: self.timings.time(\"compute_model_out\")\n",
    "\n",
    "        # compute reward\n",
    "        j = 0\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                self.full_reward[i][0] = reward[j]\n",
    "            else:\n",
    "                self.full_reward[i][0] = 0.\n",
    "            if self.reward_type == 1:                        \n",
    "                self.root_nodes_qmax_[i] = self.root_nodes[i][0].max_q\n",
    "                if self.status[i] != 1:                \n",
    "                    self.full_reward[i][1] = (self.root_nodes_qmax_[i] - self.root_nodes_qmax[i])*self.depth_delta[i]\n",
    "                else:\n",
    "                    self.full_reward[i][1] = 0.\n",
    "                self.root_nodes_qmax[i] = self.root_nodes_qmax_[i]\n",
    "            if self.status[i] == 1 or self.status[i] == 4:\n",
    "                j += 1\n",
    "        if self.time: self.timings.time(\"compute_reward\")\n",
    "\n",
    "        # compute done & full_real_done\n",
    "        j = 0\n",
    "        for i in range(self.env_n):\n",
    "            if self.status[i] == 1:\n",
    "                self.full_done[i] = done[j]\n",
    "                self.full_real_done[i] = real_done[j]\n",
    "            else:\n",
    "                self.full_done[i] = False\n",
    "                self.full_real_done[i] = False\n",
    "            if self.status[i] == 1 or self.status[i] == 4:\n",
    "                j += 1\n",
    "\n",
    "        # compute reset\n",
    "        for i in range(self.env_n):\n",
    "            if reset[i]:\n",
    "                self.rollout_depth[i] = 0\n",
    "                self.cur_nodes[i] = self.root_nodes[i]\n",
    "                node_visit(self.cur_nodes[i])\n",
    "                self.status[i] = 5 # need to restore state on the next transition, so we need to alter the status from 4\n",
    "        \n",
    "        # some extra info\n",
    "        info = {\"cur_t\": torch.tensor(self.cur_t, dtype=torch.long, device=self.device),\n",
    "                \"max_rollout_depth\":  torch.tensor(self.max_rollout_depth_, dtype=torch.long, device=self.device),\n",
    "                \"real_done\": torch.tensor(self.full_real_done, dtype=torch.bool, device=self.device)}\n",
    "        if self.time: self.timings.time(\"end\")\n",
    "\n",
    "        return ((torch.tensor(model_out, dtype=torch.float32, device=self.device), gym_env_out, model_encodes), \n",
    "                torch.tensor(self.full_reward, dtype=torch.float32, device=self.device), \n",
    "                torch.tensor(self.full_done, dtype=torch.bool, device=self.device), \n",
    "                info)\n",
    "\n",
    "    \n",
    "    cdef float[:, :] compute_model_out(self, int[:, :]& action, int[:]& status):\n",
    "        cdef int i\n",
    "        cdef int idx1 = self.num_actions*5+5\n",
    "        cdef int idx2 = self.num_actions*10+7\n",
    "\n",
    "        result_np = np.zeros((self.env_n, self.obs_n), dtype=np.float32)\n",
    "        cdef float[:, :] result = result_np        \n",
    "        for i in range(self.env_n):\n",
    "            result[i, :idx1] = node_stat(self.root_nodes[i], detailed=True, reward_transform=self.reward_transform)\n",
    "            result[i, idx1:idx2] = node_stat(self.cur_nodes[i], detailed=False, reward_transform=self.reward_transform)    \n",
    "            # reset\n",
    "            if action is None or status[i] == 1:\n",
    "                result[i, idx2] = 1.\n",
    "            else:\n",
    "                result[i, idx2] = action[i, 2]\n",
    "            # time\n",
    "            result[i, idx2+1+self.cur_t[i]] = 1.\n",
    "            # deprec\n",
    "            result[i, idx2+self.rec_t+1] = (self.discounting ** (self.rollout_depth[i]))           \n",
    "        return result\n",
    "\n",
    "    def close(self):\n",
    "        cdef int i\n",
    "        if hasattr(self, \"root_nodes\"):\n",
    "            for i in range(self.env_n):\n",
    "                node_del(self.root_nodes[i], except_idx=-1)\n",
    "        self.env.close()\n",
    "\n",
    "    def seed(self, x):\n",
    "        self.env.seed(x)\n",
    "\n",
    "    def print_time(self):\n",
    "        print(self.timings.summary())\n",
    "\n",
    "    def clone_state(self):\n",
    "        return self.env.clone_state()\n",
    "\n",
    "    def restore_state(self, state):\n",
    "        self.env.restore_state(state)\n",
    "\n",
    "    def get_action_meanings(self):\n",
    "        return self.env.get_action_meanings()       \n",
    "\n",
    "\n",
    "from thinker.gym_add.asyn_vector_env import AsyncVectorEnv\n",
    "import thinker.util as util\n",
    "from thinker.net import ModelNet\n",
    "from thinker.util import Timings\n",
    "import thinker.env\n",
    "import gym\n",
    "import gym_csokoban\n",
    "import os \n",
    "\n",
    "flags = util.parse([])\n",
    "flags.rec_t = 20\n",
    "flags.flex_t = False\n",
    "flags.env = \"BreakoutNoFrameskip-v4\"\n",
    "flags.tree_carry = True\n",
    "flags.see_encode = True\n",
    "flags.max_depth = 3\n",
    "flags.perfect_model = True\n",
    "\n",
    "env_n = 2\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "#env = Environment(flags, env_n=env_n, model_wrap=True, device=device)\n",
    "env = AsyncVectorEnv([lambda: thinker.env.PreWrap(gym.make(flags.env), flags.env) for _ in range(env_n)])\n",
    "num_actions = env.action_space[0].n\n",
    "c = cVecModelWrapper if flags.perfect_model else cVecFullModelWrapper\n",
    "env = c(env, env_n, flags, device=device, time=True)\n",
    "env.seed(np.arange(env_n))\n",
    "\n",
    "model_net = ModelNet(env.gym_env_out_shape, num_actions, flags)\n",
    "_ = model_net.train(False)\n",
    "model_net.to(device)\n",
    "\n",
    "model_out, gym_env_out, model_encodes = env.reset(model_net)\n",
    "timings = Timings()\n",
    "timings.reset()\n",
    "\n",
    "im_actions =    [1, 2, 3]\n",
    "im_actions_tensor = torch.tensor([[im_actions[n] for _ in range(env_n)] for n in range(len(im_actions))])\n",
    "#_, _, _, _, encodes_ = model_net.forward_encoded(model_encodes, im_actions_tensor.to(device))\n",
    "\n",
    "real_actions =  [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "im_actions =    [1, 2, 3, 0, 2, 3, 1, 2]\n",
    "reset_actions = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for n in range(len(real_actions)):\n",
    "    action = torch.tensor([[real_actions[n],\n",
    "                            im_actions[n],\n",
    "                            reset_actions[n],\n",
    "                        ] for _ in range(env_n)], dtype=torch.long)\n",
    "    (model_out, gym_env_out, model_encodes), reward, done, info = env.step(action.to(device), model_net)    \n",
    "    print(n, util.decode_model_out(model_out.unsqueeze(0), num_actions, flags.reward_transform)['reset'])\n",
    "    \n",
    "\n",
    "env.close()\n",
    "#print(torch.sum(torch.abs(encodes_[-1] - model_encodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('thinker/thinker')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from collections import deque\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from thinker.env import Environment, EnvOut\n",
    "from thinker.net import ActorNet, ModelNet\n",
    "from thinker.buffer import ModelBuffer\n",
    "from torch import nn\n",
    "import thinker.util as util\n",
    "import gym\n",
    "import gym_csokoban\n",
    "\n",
    "def gplot(x, ax=None, title=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    if type(x) == torch.Tensor: x = x.cpu()\n",
    "    if type(x) == np.ndarray: x = torch.tensor(x)       \n",
    "    ax.imshow(torch.swapaxes(torch.swapaxes(x,0,2),0,1), interpolation='nearest', aspect=\"auto\")\n",
    "    if title is not None: ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc/.cache/ipython/cython/_cython_magic_ebd584b4aea78c44f6db178c00dc29dc.cpp: In function void __pyx_f_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_node_propagate(__pyx_t_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_Node*, float, float, bool, std::vector<__pyx_t_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_Node*>*):\n",
      "/home/sc/.cache/ipython/cython/_cython_magic_ebd584b4aea78c44f6db178c00dc29dc.cpp:3601:37: warning: comparison of integer expressions of different signedness: int and std::vector<__pyx_t_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_Node*>::size_type {aka long unsigned int} [-Wsign-compare]\n",
      " 3601 |       for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {\n",
      "      |                           ~~~~~~~~~~^~~~~~~~~~~\n",
      "/home/sc/.cache/ipython/cython/_cython_magic_ebd584b4aea78c44f6db178c00dc29dc.cpp: At global scope:\n",
      "/home/sc/.cache/ipython/cython/_cython_magic_ebd584b4aea78c44f6db178c00dc29dc.cpp:3753:27: warning: __Pyx_memviewslice __pyx_f_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_node_stat(__pyx_t_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_Node*, bool, bool) defined but not used [-Wunused-function]\n",
      " 3753 | static __Pyx_memviewslice __pyx_f_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_node_stat(struct __pyx_t_46_cython_magic_ebd584b4aea78c44f6db178c00dc29dc_Node *__pyx_v_pnode, bool __pyx_v_detailed, bool __pyx_v_reward_transform) {\n",
      "      |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root paths\n",
      "0 0 2.0\n",
      "root rollout_qs\n",
      "0 7.0\n",
      "1 14.0\n",
      "new root rollout_qs\n",
      "0 7.0\n",
      "1 18.0\n",
      "root paths\n",
      "0 0 4.0\n",
      "1 0 8.0\n",
      "1 1 4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pydict = {\"A\": 1 }\n",
    "cdef Node* proot_node = node_new(pparent=NULL, action=0, logit=0.25, num_actions=4, discounting=1, rec_t=5, remember_path=True)    \n",
    "cdef Node* pcur_node = proot_node\n",
    "cdef Node* ptest_node\n",
    "node_expand(pnode=proot_node, r=1, v=2, t=0, done=False, logits=np.array([3,4,5,1], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=proot_node)\n",
    "print(\"root paths\")\n",
    "for n in range(proot_node.ppaths[0].size()):\n",
    "    for m in range(proot_node.ppaths[0][n][0].size()):\n",
    "        print(n, m, proot_node.ppaths[0][n][0][m][0].v)\n",
    "\n",
    "pcur_node = pcur_node[0].ppchildren[0][3]\n",
    "node_expand(pnode=pcur_node, r=3, v=4, t=0, done=False, logits=np.array([3,4,6,1], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "pcur_node = pcur_node[0].ppchildren[0][3]\n",
    "node_expand(pnode=pcur_node, r=5, v=6, t=0, done=False, logits=np.array([3,4,6,1], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "ptest_node = proot_node[0].ppchildren[0][3]\n",
    "print(\"root rollout_qs\")\n",
    "for n, i in enumerate(ptest_node.prollout_qs[0]): print(n, i)\n",
    "\n",
    "node_expand(pnode=pcur_node, r=7, v=8, t=1, done=False, logits=np.array([3,4,6,1], dtype=np.float32), encoded=<PyObject*>pydict, override=True)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "print(\"new root rollout_qs\")\n",
    "for n, i in enumerate(ptest_node.prollout_qs[0]): print(n, i)\n",
    "\n",
    "print(\"root paths\")\n",
    "for n in range(ptest_node.ppaths[0].size()):\n",
    "    for m in range(ptest_node.ppaths[0][n][0].size()):\n",
    "        print(n, m, ptest_node.ppaths[0][n][0][m][0].v)\n",
    "\n",
    "node_del(proot_node, -1)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = Environment(flags, env_n=env_n, device=device)\n",
    "env = AsyncVectorEnv([lambda: thinker.env.PreWrap(gym.make(flags.env), flags.env) for _ in range(env_n)])\n",
    "num_actions = env.action_space[0].n\n",
    "env = cVecModelWrapper(env, env_n, flags, device=device, time=True)\n",
    "env.seed(np.arange(env_n))\n",
    "\n",
    "model_net = ModelNet(env.gym_env_out_shape, num_actions, flags)\n",
    "_ = model_net.train(False)\n",
    "model_net.to(device)\n",
    "model_out, gym_env_out, model_encodes = env.reset(model_net)\n",
    "\n",
    "\n",
    "flags.perfect_model = False\n",
    "env_ = AsyncVectorEnv([lambda: thinker.env.PreWrap(gym.make(flags.env), flags.env) for _ in range(env_n)])\n",
    "env_ = cVecModelWrapper(env_, env_n, flags, device=device, time=True)\n",
    "env_.seed(np.arange(env_n))\n",
    "model_out_, gym_env_out_, model_encodes_ = env_.reset(model_net)\n",
    "print(\"diff: \", torch.sum(torch.abs(model_out - model_out_)))\n",
    "\n",
    "\n",
    "action = torch.tensor([[np.random.randint(num_actions),\n",
    "                        np.random.randint(num_actions),\n",
    "                        np.random.randint(1),\n",
    "                        ] for _ in range(env_n)], dtype=torch.long)\n",
    "\n",
    "timings = Timings()\n",
    "timings.reset()\n",
    "\n",
    "\n",
    "for n in range(100):\n",
    "    timings.time(\"s0\")\n",
    "    (model_out, gym_env_out, model_encodes), reward, done, info = env.step(action.to(device), model_net)\n",
    "    \n",
    "    timings.time(\"s1\")\n",
    "    (model_out_, gym_env_out_, model_encodes_), reward_, done_, info_ = env_.step(action.to(device), model_net)\n",
    "    timings.time(\"s2\")\n",
    "\n",
    "    model_out_diff = torch.sum(torch.abs(model_out - model_out_))\n",
    "    gym_env_out_diff = torch.sum(torch.abs(gym_env_out - gym_env_out_))\n",
    "    reward_diff = torch.sum(torch.abs(reward - reward_))\n",
    "    done_diff = torch.sum(torch.abs(done.float() - done_.float()))\n",
    "    \n",
    "    if model_out_diff > 1e-5: \n",
    "        err_ind = torch.argmax(torch.max(torch.abs(model_out - model_out_), dim=1)[0])     \n",
    "        print(model_out[err_ind], model_out_[err_ind])\n",
    "        raise Exception(\"model_out_diff %f\" % model_out_diff)\n",
    "    if gym_env_out_diff > 1e-5: raise Exception(\"gym_env_out_diff %f\" % gym_env_out_diff)\n",
    "    if reward_diff > 1e-5: raise Exception(\"gym_env_out_diff %f\" % reward_diff)\n",
    "    if done_diff > 1e-5: raise Exception(\"gym_env_out_diff %f\" % done_diff)\n",
    "\n",
    "    if n % 50 == 0: print(\"Finish %d step\" % n)\n",
    "env.close()\n",
    "env_.close()\n",
    "print(timings.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for Node\n",
    "%%cython \n",
    "\n",
    "pydict = {\"A\": 1 }\n",
    "cdef Node* proot_node = node_new(pparent=NULL, action=0, logit=0.25, num_actions=4, discounting=0.97, rec_t=5)    \n",
    "node_expand(pnode=proot_node, r=0.5, v=1.2, logits=np.array([1.2,3.4,1.2,-3.4], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=proot_node)\n",
    "cdef Node* pcur_node = proot_node[0].ppchildren[0][3]\n",
    "node_expand(pnode=pcur_node, r=0.4, v=1.9, logits=np.array([1.4,3.5,5.2,-3.4], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "pcur_node = pcur_node[0].ppchildren[0][3]\n",
    "node_expand(pnode=pcur_node, r=1.4, v=1.9, logits=np.array([1.4,3.5,5.2,-3.4], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "node_visit(pnode=proot_node)\n",
    "pcur_node = proot_node[0].ppchildren[0][2]\n",
    "node_expand(pnode=pcur_node, r=4.4, v=-1.9, logits=np.array([5.4,1.5,5.2,-3.4], dtype=np.float32), encoded=<PyObject*>pydict, override=False)\n",
    "node_visit(pnode=pcur_node)\n",
    "\n",
    "for i in range(proot_node[0].prollout_qs[0].size()):\n",
    "    print(proot_node[0].prollout_qs[0][i])\n",
    "print(np.array(node_stat(proot_node, True)))\n",
    "\n",
    "node_del(proot_node, 2)\n",
    "print(np.array(node_stat(pcur_node, True)), pcur_node[0].pparent == NULL)\n",
    "\n",
    "\n",
    "import thinker.env\n",
    "import torch\n",
    "import numpy as np\n",
    "pydict = None\n",
    "node = thinker.env.Node(None, action=0, logit=0.25, num_actions=4, discounting=0.97, rec_t=5)   \n",
    "node.expand(r=torch.tensor([0.5]), v=torch.tensor([1.2]), logits=torch.tensor([1.2,3.4,1.2,-3.4], dtype=float), encoded=pydict)\n",
    "node.visit()\n",
    "cur_node = node.children[3]\n",
    "cur_node.expand(r=torch.tensor([0.4]), v=torch.tensor([1.9]), logits=torch.tensor([1.4,3.5,5.2,-3.4], dtype=float), encoded=pydict, override=False)\n",
    "cur_node.visit()\n",
    "cur_node = cur_node.children[3]\n",
    "cur_node.expand(r=torch.tensor([1.4]), v=torch.tensor([1.9]), logits=torch.tensor([1.4,3.5,5.2,-3.4], dtype=float), encoded=pydict, override=False)\n",
    "cur_node.visit()\n",
    "\n",
    "node.visit()\n",
    "cur_node = node.children[2]\n",
    "cur_node.expand(r=torch.tensor([4.4]), v=torch.tensor([-1.9]), logits=torch.tensor([5.4,1.5,5.2,-3.4], dtype=float), encoded=pydict, override=False)\n",
    "cur_node.visit()\n",
    "\n",
    "\n",
    "print(node.stat(True))\n",
    "print(node.rollout_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<!-- Generated by Cython 0.29.32 -->\n",
       "<html>\n",
       "<head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
       "    <title>Cython: _cython_magic_44fec6d40ce544bf2012d868c8450c04.pyx</title>\n",
       "    <style type=\"text/css\">\n",
       "    \n",
       "body.cython { font-family: courier; font-size: 12; }\n",
       "\n",
       ".cython.tag  {  }\n",
       ".cython.line { margin: 0em }\n",
       ".cython.code { font-size: 9; color: #444444; display: none; margin: 0px 0px 0px 8px; border-left: 8px none; }\n",
       "\n",
       ".cython.line .run { background-color: #B0FFB0; }\n",
       ".cython.line .mis { background-color: #FFB0B0; }\n",
       ".cython.code.run  { border-left: 8px solid #B0FFB0; }\n",
       ".cython.code.mis  { border-left: 8px solid #FFB0B0; }\n",
       "\n",
       ".cython.code .py_c_api  { color: red; }\n",
       ".cython.code .py_macro_api  { color: #FF7000; }\n",
       ".cython.code .pyx_c_api  { color: #FF3000; }\n",
       ".cython.code .pyx_macro_api  { color: #FF7000; }\n",
       ".cython.code .refnanny  { color: #FFA000; }\n",
       ".cython.code .trace  { color: #FFA000; }\n",
       ".cython.code .error_goto  { color: #FFA000; }\n",
       "\n",
       ".cython.code .coerce  { color: #008000; border: 1px dotted #008000 }\n",
       ".cython.code .py_attr { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_attr  { color: #0000FF; }\n",
       ".cython.code .py_call { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_call  { color: #0000FF; }\n",
       "\n",
       ".cython.score-0 {background-color: #FFFFff;}\n",
       ".cython.score-1 {background-color: #FFFFe7;}\n",
       ".cython.score-2 {background-color: #FFFFd4;}\n",
       ".cython.score-3 {background-color: #FFFFc4;}\n",
       ".cython.score-4 {background-color: #FFFFb6;}\n",
       ".cython.score-5 {background-color: #FFFFaa;}\n",
       ".cython.score-6 {background-color: #FFFF9f;}\n",
       ".cython.score-7 {background-color: #FFFF96;}\n",
       ".cython.score-8 {background-color: #FFFF8d;}\n",
       ".cython.score-9 {background-color: #FFFF86;}\n",
       ".cython.score-10 {background-color: #FFFF7f;}\n",
       ".cython.score-11 {background-color: #FFFF79;}\n",
       ".cython.score-12 {background-color: #FFFF73;}\n",
       ".cython.score-13 {background-color: #FFFF6e;}\n",
       ".cython.score-14 {background-color: #FFFF6a;}\n",
       ".cython.score-15 {background-color: #FFFF66;}\n",
       ".cython.score-16 {background-color: #FFFF62;}\n",
       ".cython.score-17 {background-color: #FFFF5e;}\n",
       ".cython.score-18 {background-color: #FFFF5b;}\n",
       ".cython.score-19 {background-color: #FFFF57;}\n",
       ".cython.score-20 {background-color: #FFFF55;}\n",
       ".cython.score-21 {background-color: #FFFF52;}\n",
       ".cython.score-22 {background-color: #FFFF4f;}\n",
       ".cython.score-23 {background-color: #FFFF4d;}\n",
       ".cython.score-24 {background-color: #FFFF4b;}\n",
       ".cython.score-25 {background-color: #FFFF48;}\n",
       ".cython.score-26 {background-color: #FFFF46;}\n",
       ".cython.score-27 {background-color: #FFFF44;}\n",
       ".cython.score-28 {background-color: #FFFF43;}\n",
       ".cython.score-29 {background-color: #FFFF41;}\n",
       ".cython.score-30 {background-color: #FFFF3f;}\n",
       ".cython.score-31 {background-color: #FFFF3e;}\n",
       ".cython.score-32 {background-color: #FFFF3c;}\n",
       ".cython.score-33 {background-color: #FFFF3b;}\n",
       ".cython.score-34 {background-color: #FFFF39;}\n",
       ".cython.score-35 {background-color: #FFFF38;}\n",
       ".cython.score-36 {background-color: #FFFF37;}\n",
       ".cython.score-37 {background-color: #FFFF36;}\n",
       ".cython.score-38 {background-color: #FFFF35;}\n",
       ".cython.score-39 {background-color: #FFFF34;}\n",
       ".cython.score-40 {background-color: #FFFF33;}\n",
       ".cython.score-41 {background-color: #FFFF32;}\n",
       ".cython.score-42 {background-color: #FFFF31;}\n",
       ".cython.score-43 {background-color: #FFFF30;}\n",
       ".cython.score-44 {background-color: #FFFF2f;}\n",
       ".cython.score-45 {background-color: #FFFF2e;}\n",
       ".cython.score-46 {background-color: #FFFF2d;}\n",
       ".cython.score-47 {background-color: #FFFF2c;}\n",
       ".cython.score-48 {background-color: #FFFF2b;}\n",
       ".cython.score-49 {background-color: #FFFF2b;}\n",
       ".cython.score-50 {background-color: #FFFF2a;}\n",
       ".cython.score-51 {background-color: #FFFF29;}\n",
       ".cython.score-52 {background-color: #FFFF29;}\n",
       ".cython.score-53 {background-color: #FFFF28;}\n",
       ".cython.score-54 {background-color: #FFFF27;}\n",
       ".cython.score-55 {background-color: #FFFF27;}\n",
       ".cython.score-56 {background-color: #FFFF26;}\n",
       ".cython.score-57 {background-color: #FFFF26;}\n",
       ".cython.score-58 {background-color: #FFFF25;}\n",
       ".cython.score-59 {background-color: #FFFF24;}\n",
       ".cython.score-60 {background-color: #FFFF24;}\n",
       ".cython.score-61 {background-color: #FFFF23;}\n",
       ".cython.score-62 {background-color: #FFFF23;}\n",
       ".cython.score-63 {background-color: #FFFF22;}\n",
       ".cython.score-64 {background-color: #FFFF22;}\n",
       ".cython.score-65 {background-color: #FFFF22;}\n",
       ".cython.score-66 {background-color: #FFFF21;}\n",
       ".cython.score-67 {background-color: #FFFF21;}\n",
       ".cython.score-68 {background-color: #FFFF20;}\n",
       ".cython.score-69 {background-color: #FFFF20;}\n",
       ".cython.score-70 {background-color: #FFFF1f;}\n",
       ".cython.score-71 {background-color: #FFFF1f;}\n",
       ".cython.score-72 {background-color: #FFFF1f;}\n",
       ".cython.score-73 {background-color: #FFFF1e;}\n",
       ".cython.score-74 {background-color: #FFFF1e;}\n",
       ".cython.score-75 {background-color: #FFFF1e;}\n",
       ".cython.score-76 {background-color: #FFFF1d;}\n",
       ".cython.score-77 {background-color: #FFFF1d;}\n",
       ".cython.score-78 {background-color: #FFFF1c;}\n",
       ".cython.score-79 {background-color: #FFFF1c;}\n",
       ".cython.score-80 {background-color: #FFFF1c;}\n",
       ".cython.score-81 {background-color: #FFFF1c;}\n",
       ".cython.score-82 {background-color: #FFFF1b;}\n",
       ".cython.score-83 {background-color: #FFFF1b;}\n",
       ".cython.score-84 {background-color: #FFFF1b;}\n",
       ".cython.score-85 {background-color: #FFFF1a;}\n",
       ".cython.score-86 {background-color: #FFFF1a;}\n",
       ".cython.score-87 {background-color: #FFFF1a;}\n",
       ".cython.score-88 {background-color: #FFFF1a;}\n",
       ".cython.score-89 {background-color: #FFFF19;}\n",
       ".cython.score-90 {background-color: #FFFF19;}\n",
       ".cython.score-91 {background-color: #FFFF19;}\n",
       ".cython.score-92 {background-color: #FFFF19;}\n",
       ".cython.score-93 {background-color: #FFFF18;}\n",
       ".cython.score-94 {background-color: #FFFF18;}\n",
       ".cython.score-95 {background-color: #FFFF18;}\n",
       ".cython.score-96 {background-color: #FFFF18;}\n",
       ".cython.score-97 {background-color: #FFFF17;}\n",
       ".cython.score-98 {background-color: #FFFF17;}\n",
       ".cython.score-99 {background-color: #FFFF17;}\n",
       ".cython.score-100 {background-color: #FFFF17;}\n",
       ".cython.score-101 {background-color: #FFFF16;}\n",
       ".cython.score-102 {background-color: #FFFF16;}\n",
       ".cython.score-103 {background-color: #FFFF16;}\n",
       ".cython.score-104 {background-color: #FFFF16;}\n",
       ".cython.score-105 {background-color: #FFFF16;}\n",
       ".cython.score-106 {background-color: #FFFF15;}\n",
       ".cython.score-107 {background-color: #FFFF15;}\n",
       ".cython.score-108 {background-color: #FFFF15;}\n",
       ".cython.score-109 {background-color: #FFFF15;}\n",
       ".cython.score-110 {background-color: #FFFF15;}\n",
       ".cython.score-111 {background-color: #FFFF15;}\n",
       ".cython.score-112 {background-color: #FFFF14;}\n",
       ".cython.score-113 {background-color: #FFFF14;}\n",
       ".cython.score-114 {background-color: #FFFF14;}\n",
       ".cython.score-115 {background-color: #FFFF14;}\n",
       ".cython.score-116 {background-color: #FFFF14;}\n",
       ".cython.score-117 {background-color: #FFFF14;}\n",
       ".cython.score-118 {background-color: #FFFF13;}\n",
       ".cython.score-119 {background-color: #FFFF13;}\n",
       ".cython.score-120 {background-color: #FFFF13;}\n",
       ".cython.score-121 {background-color: #FFFF13;}\n",
       ".cython.score-122 {background-color: #FFFF13;}\n",
       ".cython.score-123 {background-color: #FFFF13;}\n",
       ".cython.score-124 {background-color: #FFFF13;}\n",
       ".cython.score-125 {background-color: #FFFF12;}\n",
       ".cython.score-126 {background-color: #FFFF12;}\n",
       ".cython.score-127 {background-color: #FFFF12;}\n",
       ".cython.score-128 {background-color: #FFFF12;}\n",
       ".cython.score-129 {background-color: #FFFF12;}\n",
       ".cython.score-130 {background-color: #FFFF12;}\n",
       ".cython.score-131 {background-color: #FFFF12;}\n",
       ".cython.score-132 {background-color: #FFFF11;}\n",
       ".cython.score-133 {background-color: #FFFF11;}\n",
       ".cython.score-134 {background-color: #FFFF11;}\n",
       ".cython.score-135 {background-color: #FFFF11;}\n",
       ".cython.score-136 {background-color: #FFFF11;}\n",
       ".cython.score-137 {background-color: #FFFF11;}\n",
       ".cython.score-138 {background-color: #FFFF11;}\n",
       ".cython.score-139 {background-color: #FFFF11;}\n",
       ".cython.score-140 {background-color: #FFFF11;}\n",
       ".cython.score-141 {background-color: #FFFF10;}\n",
       ".cython.score-142 {background-color: #FFFF10;}\n",
       ".cython.score-143 {background-color: #FFFF10;}\n",
       ".cython.score-144 {background-color: #FFFF10;}\n",
       ".cython.score-145 {background-color: #FFFF10;}\n",
       ".cython.score-146 {background-color: #FFFF10;}\n",
       ".cython.score-147 {background-color: #FFFF10;}\n",
       ".cython.score-148 {background-color: #FFFF10;}\n",
       ".cython.score-149 {background-color: #FFFF10;}\n",
       ".cython.score-150 {background-color: #FFFF0f;}\n",
       ".cython.score-151 {background-color: #FFFF0f;}\n",
       ".cython.score-152 {background-color: #FFFF0f;}\n",
       ".cython.score-153 {background-color: #FFFF0f;}\n",
       ".cython.score-154 {background-color: #FFFF0f;}\n",
       ".cython.score-155 {background-color: #FFFF0f;}\n",
       ".cython.score-156 {background-color: #FFFF0f;}\n",
       ".cython.score-157 {background-color: #FFFF0f;}\n",
       ".cython.score-158 {background-color: #FFFF0f;}\n",
       ".cython.score-159 {background-color: #FFFF0f;}\n",
       ".cython.score-160 {background-color: #FFFF0f;}\n",
       ".cython.score-161 {background-color: #FFFF0e;}\n",
       ".cython.score-162 {background-color: #FFFF0e;}\n",
       ".cython.score-163 {background-color: #FFFF0e;}\n",
       ".cython.score-164 {background-color: #FFFF0e;}\n",
       ".cython.score-165 {background-color: #FFFF0e;}\n",
       ".cython.score-166 {background-color: #FFFF0e;}\n",
       ".cython.score-167 {background-color: #FFFF0e;}\n",
       ".cython.score-168 {background-color: #FFFF0e;}\n",
       ".cython.score-169 {background-color: #FFFF0e;}\n",
       ".cython.score-170 {background-color: #FFFF0e;}\n",
       ".cython.score-171 {background-color: #FFFF0e;}\n",
       ".cython.score-172 {background-color: #FFFF0e;}\n",
       ".cython.score-173 {background-color: #FFFF0d;}\n",
       ".cython.score-174 {background-color: #FFFF0d;}\n",
       ".cython.score-175 {background-color: #FFFF0d;}\n",
       ".cython.score-176 {background-color: #FFFF0d;}\n",
       ".cython.score-177 {background-color: #FFFF0d;}\n",
       ".cython.score-178 {background-color: #FFFF0d;}\n",
       ".cython.score-179 {background-color: #FFFF0d;}\n",
       ".cython.score-180 {background-color: #FFFF0d;}\n",
       ".cython.score-181 {background-color: #FFFF0d;}\n",
       ".cython.score-182 {background-color: #FFFF0d;}\n",
       ".cython.score-183 {background-color: #FFFF0d;}\n",
       ".cython.score-184 {background-color: #FFFF0d;}\n",
       ".cython.score-185 {background-color: #FFFF0d;}\n",
       ".cython.score-186 {background-color: #FFFF0d;}\n",
       ".cython.score-187 {background-color: #FFFF0c;}\n",
       ".cython.score-188 {background-color: #FFFF0c;}\n",
       ".cython.score-189 {background-color: #FFFF0c;}\n",
       ".cython.score-190 {background-color: #FFFF0c;}\n",
       ".cython.score-191 {background-color: #FFFF0c;}\n",
       ".cython.score-192 {background-color: #FFFF0c;}\n",
       ".cython.score-193 {background-color: #FFFF0c;}\n",
       ".cython.score-194 {background-color: #FFFF0c;}\n",
       ".cython.score-195 {background-color: #FFFF0c;}\n",
       ".cython.score-196 {background-color: #FFFF0c;}\n",
       ".cython.score-197 {background-color: #FFFF0c;}\n",
       ".cython.score-198 {background-color: #FFFF0c;}\n",
       ".cython.score-199 {background-color: #FFFF0c;}\n",
       ".cython.score-200 {background-color: #FFFF0c;}\n",
       ".cython.score-201 {background-color: #FFFF0c;}\n",
       ".cython.score-202 {background-color: #FFFF0c;}\n",
       ".cython.score-203 {background-color: #FFFF0b;}\n",
       ".cython.score-204 {background-color: #FFFF0b;}\n",
       ".cython.score-205 {background-color: #FFFF0b;}\n",
       ".cython.score-206 {background-color: #FFFF0b;}\n",
       ".cython.score-207 {background-color: #FFFF0b;}\n",
       ".cython.score-208 {background-color: #FFFF0b;}\n",
       ".cython.score-209 {background-color: #FFFF0b;}\n",
       ".cython.score-210 {background-color: #FFFF0b;}\n",
       ".cython.score-211 {background-color: #FFFF0b;}\n",
       ".cython.score-212 {background-color: #FFFF0b;}\n",
       ".cython.score-213 {background-color: #FFFF0b;}\n",
       ".cython.score-214 {background-color: #FFFF0b;}\n",
       ".cython.score-215 {background-color: #FFFF0b;}\n",
       ".cython.score-216 {background-color: #FFFF0b;}\n",
       ".cython.score-217 {background-color: #FFFF0b;}\n",
       ".cython.score-218 {background-color: #FFFF0b;}\n",
       ".cython.score-219 {background-color: #FFFF0b;}\n",
       ".cython.score-220 {background-color: #FFFF0b;}\n",
       ".cython.score-221 {background-color: #FFFF0b;}\n",
       ".cython.score-222 {background-color: #FFFF0a;}\n",
       ".cython.score-223 {background-color: #FFFF0a;}\n",
       ".cython.score-224 {background-color: #FFFF0a;}\n",
       ".cython.score-225 {background-color: #FFFF0a;}\n",
       ".cython.score-226 {background-color: #FFFF0a;}\n",
       ".cython.score-227 {background-color: #FFFF0a;}\n",
       ".cython.score-228 {background-color: #FFFF0a;}\n",
       ".cython.score-229 {background-color: #FFFF0a;}\n",
       ".cython.score-230 {background-color: #FFFF0a;}\n",
       ".cython.score-231 {background-color: #FFFF0a;}\n",
       ".cython.score-232 {background-color: #FFFF0a;}\n",
       ".cython.score-233 {background-color: #FFFF0a;}\n",
       ".cython.score-234 {background-color: #FFFF0a;}\n",
       ".cython.score-235 {background-color: #FFFF0a;}\n",
       ".cython.score-236 {background-color: #FFFF0a;}\n",
       ".cython.score-237 {background-color: #FFFF0a;}\n",
       ".cython.score-238 {background-color: #FFFF0a;}\n",
       ".cython.score-239 {background-color: #FFFF0a;}\n",
       ".cython.score-240 {background-color: #FFFF0a;}\n",
       ".cython.score-241 {background-color: #FFFF0a;}\n",
       ".cython.score-242 {background-color: #FFFF0a;}\n",
       ".cython.score-243 {background-color: #FFFF0a;}\n",
       ".cython.score-244 {background-color: #FFFF0a;}\n",
       ".cython.score-245 {background-color: #FFFF0a;}\n",
       ".cython.score-246 {background-color: #FFFF09;}\n",
       ".cython.score-247 {background-color: #FFFF09;}\n",
       ".cython.score-248 {background-color: #FFFF09;}\n",
       ".cython.score-249 {background-color: #FFFF09;}\n",
       ".cython.score-250 {background-color: #FFFF09;}\n",
       ".cython.score-251 {background-color: #FFFF09;}\n",
       ".cython.score-252 {background-color: #FFFF09;}\n",
       ".cython.score-253 {background-color: #FFFF09;}\n",
       ".cython.score-254 {background-color: #FFFF09;}\n",
       "pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".cython .hll { background-color: #ffffcc }\n",
       ".cython { background: #f8f8f8; }\n",
       ".cython .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".cython .err { border: 1px solid #FF0000 } /* Error */\n",
       ".cython .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".cython .o { color: #666666 } /* Operator */\n",
       ".cython .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".cython .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".cython .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".cython .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".cython .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".cython .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".cython .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".cython .ge { font-style: italic } /* Generic.Emph */\n",
       ".cython .gr { color: #E40000 } /* Generic.Error */\n",
       ".cython .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".cython .gi { color: #008400 } /* Generic.Inserted */\n",
       ".cython .go { color: #717171 } /* Generic.Output */\n",
       ".cython .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".cython .gs { font-weight: bold } /* Generic.Strong */\n",
       ".cython .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".cython .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".cython .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".cython .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".cython .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".cython .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".cython .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".cython .kt { color: #B00040 } /* Keyword.Type */\n",
       ".cython .m { color: #666666 } /* Literal.Number */\n",
       ".cython .s { color: #BA2121 } /* Literal.String */\n",
       ".cython .na { color: #687822 } /* Name.Attribute */\n",
       ".cython .nb { color: #008000 } /* Name.Builtin */\n",
       ".cython .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".cython .no { color: #880000 } /* Name.Constant */\n",
       ".cython .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".cython .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".cython .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".cython .nf { color: #0000FF } /* Name.Function */\n",
       ".cython .nl { color: #767600 } /* Name.Label */\n",
       ".cython .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".cython .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".cython .nv { color: #19177C } /* Name.Variable */\n",
       ".cython .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".cython .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".cython .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".cython .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".cython .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".cython .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".cython .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".cython .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".cython .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".cython .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".cython .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".cython .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".cython .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".cython .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".cython .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".cython .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".cython .sx { color: #008000 } /* Literal.String.Other */\n",
       ".cython .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".cython .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".cython .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".cython .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".cython .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".cython .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".cython .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".cython .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".cython .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".cython .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "    </style>\n",
       "</head>\n",
       "<body class=\"cython\">\n",
       "<p><span style=\"border-bottom: solid 1px grey;\">Generated by Cython 0.29.32</span></p>\n",
       "<p>\n",
       "    <span style=\"background-color: #FFFF00\">Yellow lines</span> hint at Python interaction.<br />\n",
       "    Click on a line that starts with a \"<code>+</code>\" to see the C code that Cython generated for it.\n",
       "</p>\n",
       "<div class=\"cython\"><pre class=\"cython line score-0\">&#xA0;<span class=\"\">01</span>: <span class=\"k\">from</span> <span class=\"nn\">__future__</span> <span class=\"k\">import</span> <span class=\"n\">print_function</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">02</span>: <span class=\"k\">cdef</span> <span class=\"k\">class</span> <span class=\"nf\">Shrubbery</span><span class=\"p\">:</span></pre>\n",
       "<pre class='cython code score-0 '>struct __pyx_obj_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery {\n",
       "  PyObject_HEAD\n",
       "  struct __pyx_vtabstruct_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *__pyx_vtab;\n",
       "  int width;\n",
       "  int height;\n",
       "};\n",
       "\n",
       "\n",
       "\n",
       "struct __pyx_vtabstruct_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery {\n",
       "  PyObject *(*describe)(struct __pyx_obj_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *);\n",
       "};\n",
       "static struct __pyx_vtabstruct_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *__pyx_vtabptr_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">03</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">width</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">04</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">height</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">05</span>: </pre>\n",
       "<pre class=\"cython line score-38\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">06</span>:     <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"nb\">int</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"nb\">int</span> <span class=\"n\">h</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-38 '>/* Python wrapper */\n",
       "static int __pyx_pw_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_9Shrubbery_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/\n",
       "static int __pyx_pw_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_9Shrubbery_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {\n",
       "  int __pyx_v_w;\n",
       "  int __pyx_v_h;\n",
       "  int __pyx_r;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__init__ (wrapper)\", 0);\n",
       "  {\n",
       "    static PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_w,&amp;__pyx_n_s_h,0};\n",
       "    PyObject* values[2] = {0,0};\n",
       "    if (unlikely(__pyx_kwds)) {\n",
       "      Py_ssize_t kw_args;\n",
       "      const Py_ssize_t pos_args = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "      switch (pos_args) {\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='py_c_api'>PyDict_Size</span>(__pyx_kwds);\n",
       "      switch (pos_args) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_w)) != 0)) kw_args--;\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (likely((values[1] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"__init__\", 1, 2, 2, 1); <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L3_error)</span>\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, \"__init__\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else if (<span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args) != 2) {\n",
       "      goto __pyx_L5_argtuple_error;\n",
       "    } else {\n",
       "      values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "      values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "    }\n",
       "    __pyx_v_w = <span class='pyx_c_api'>__Pyx_PyInt_As_int</span>(values[0]); if (unlikely((__pyx_v_w == (int)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L3_error)</span>\n",
       "    __pyx_v_h = <span class='pyx_c_api'>__Pyx_PyInt_As_int</span>(values[1]); if (unlikely((__pyx_v_h == (int)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L3_error)</span>\n",
       "  }\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"__init__\", 1, 2, 2, <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)); <span class='error_goto'>__PYX_ERR(0, 6, __pyx_L3_error)</span>\n",
       "  __pyx_L3_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_44fec6d40ce544bf2012d868c8450c04.Shrubbery.__init__\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return -1;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_9Shrubbery___init__(((struct __pyx_obj_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *)__pyx_v_self), __pyx_v_w, __pyx_v_h);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static int __pyx_pf_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_9Shrubbery___init__(struct __pyx_obj_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *__pyx_v_self, int __pyx_v_w, int __pyx_v_h) {\n",
       "  int __pyx_r;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__init__\", 0);\n",
       "/*  */\n",
       "  /* function exit code */\n",
       "  __pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">07</span>:         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">width</span> <span class=\"o\">=</span> <span class=\"n\">w</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_self-&gt;width = __pyx_v_w;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">08</span>:         <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">height</span> <span class=\"o\">=</span> <span class=\"n\">h</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_self-&gt;height = __pyx_v_h;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">09</span>: </pre>\n",
       "<pre class=\"cython line score-6\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">10</span>:     <span class=\"k\">cdef</span> <span class=\"nf\">describe</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-6 '>static PyObject *__pyx_f_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_9Shrubbery_describe(struct __pyx_obj_46_cython_magic_44fec6d40ce544bf2012d868c8450c04_Shrubbery *__pyx_v_self) {\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"describe\", 0);\n",
       "/*  */\n",
       "  /* function exit code */\n",
       "  __pyx_r = Py_None; <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "  goto __pyx_L0;\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_44fec6d40ce544bf2012d868c8450c04.Shrubbery.describe\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = 0;\n",
       "  __pyx_L0:;\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "</pre><pre class=\"cython line score-19\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">11</span>:         <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">&quot;This shrubbery is&quot;</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">width</span><span class=\"p\">,</span></pre>\n",
       "<pre class='cython code score-19 '>  __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyInt_From_int</span>(__pyx_v_self-&gt;width);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 11, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "/*  */\n",
       "  __pyx_t_3 = <span class='py_c_api'>PyTuple_New</span>(5);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 11, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_kp_u_This_shrubbery_is);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_kp_u_This_shrubbery_is);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 0, __pyx_kp_u_This_shrubbery_is);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_1);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 1, __pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_n_u_by);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_n_u_by);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 2, __pyx_n_u_by);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 3, __pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_kp_u_cubits);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_kp_u_cubits);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 4, __pyx_kp_u_cubits);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_builtin_print, __pyx_t_3, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 11, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_2); __pyx_t_2 = 0;\n",
       "</pre><pre class=\"cython line score-2\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">12</span>:               <span class=\"s\">&quot;by&quot;</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">height</span><span class=\"p\">,</span> <span class=\"s\">&quot;cubits.&quot;</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-2 '>  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyInt_From_int</span>(__pyx_v_self-&gt;height);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "</pre></div></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cython --annotate\n",
    "from __future__ import print_function\n",
    "cdef class Shrubbery:\n",
    "    cdef int width\n",
    "    cdef int height\n",
    "\n",
    "    def __init__(self, int w, int h):\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "\n",
    "    cdef describe(self):\n",
    "        print(\"This shrubbery is\", self.width,\n",
    "              \"by\", self.height, \"cubits.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f50a7fa60ad8550b89b217983de73aa91b7ad4da24a2c984b86370b087d0b88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
