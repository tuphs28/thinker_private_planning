{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(\"RS/thinker/thinker\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from collections import deque\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from thinker.env import Environment\n",
    "from thinker.net import ActorNet, ModelNet\n",
    "from thinker.buffer import ModelBuffer\n",
    "import thinker.util as util\n",
    "\n",
    "\n",
    "def plot_gym_env_out(x, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.imshow(\n",
    "        torch.swapaxes(torch.swapaxes(x[0].cpu(), 0, 2), 0, 1),\n",
    "        interpolation=\"nearest\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = util.parse([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chung\\Personal\\RS\\thinker\\thinker\\debug.ipynb Cell 3\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chung/Personal/RS/thinker/thinker/debug.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthinker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutil\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chung/Personal/RS/thinker/thinker/debug.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m flags \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mparse([])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chung/Personal/RS/thinker/thinker/debug.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m FileWriter(xpid\u001b[39m=\u001b[39mflags\u001b[39m.\u001b[39mxpid, xp_args\u001b[39m=\u001b[39mflags\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chung/Personal/RS/thinker/thinker/debug.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                   rootdir\u001b[39m=\u001b[39mflags\u001b[39m.\u001b[39msavedir, overwrite\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mload_checkpoint)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "from thinker.core.file_writer import FileWriter\n",
    "import thinker.util as util\n",
    "\n",
    "flags = util.parse([])\n",
    "FileWriter(\n",
    "    xpid=flags.xpid,\n",
    "    xp_args=flags.__dict__,\n",
    "    rootdir=flags.savedir,\n",
    "    overwrite=not self.flags.load_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os, cv2\n",
    "\n",
    "# font_path = os.path.join(cv2.__path__[0],'qt','fonts','DejaVuSans.ttf')\n",
    "font_path = os.path.join(\"C:\\\\\", \"Windows\", \"Fonts\", \"calibri.ttf\")\n",
    "font = ImageFont.truetype(font_path, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2216261"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from thinker.net import *\n",
    "\n",
    "\n",
    "class DRCNet(BaseNet):\n",
    "    def __init__(self, obs_shape, gym_obs_shape, num_actions, flags):\n",
    "        super(DRCNet, self).__init__()\n",
    "        # assert flags.disable_model\n",
    "        # assert flags.critic_enc_type == 0\n",
    "\n",
    "        self.obs_shape = obs_shape\n",
    "        self.gym_obs_shape = gym_obs_shape\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, out_channels=32, kernel_size=8, stride=4, padding=2\n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "        )\n",
    "        output_shape = lambda h, w, kernel, stride, padding: (\n",
    "            ((h + 2 * padding - kernel) // stride + 1),\n",
    "            ((w + 2 * padding - kernel) // stride + 1),\n",
    "        )\n",
    "\n",
    "        h, w = output_shape(gym_obs_shape[1], gym_obs_shape[2], 8, 4, 2)\n",
    "        h, w = output_shape(h, w, 4, 2, 1)\n",
    "\n",
    "        self.drc_depth = 3\n",
    "        self.drc_n = 3\n",
    "        self.core = ConvAttnLSTM(\n",
    "            h=h,\n",
    "            w=w,\n",
    "            input_dim=32,\n",
    "            hidden_dim=32,\n",
    "            kernel_size=3,\n",
    "            num_layers=3,\n",
    "            num_heads=8,\n",
    "            mem_n=None,\n",
    "            attn=False,\n",
    "            attn_mask_b=None,\n",
    "            pool_inject=True,\n",
    "        )\n",
    "        last_out_size = 32 * h * w * 2\n",
    "        self.final_layer = nn.Sequential(nn.Linear(last_out_size, 256), nn.ReLU())\n",
    "        self.policy = nn.Linear(256, self.num_actions)\n",
    "        self.baseline = nn.Linear(256, 1)\n",
    "\n",
    "    def initial_state(self, batch_size, device=None):\n",
    "        return self.core.init_state(batch_size, device=device)\n",
    "\n",
    "    def forward(self, obs, core_state=(), greedy=False):\n",
    "        done = obs.done\n",
    "        assert (\n",
    "            len(done.shape) == 2\n",
    "        ), f\"done shape should be (T, B) instead of {done.shape}\"\n",
    "        T, B = done.shape\n",
    "        model_enc = obs.gym_env_out.float() / 255.0\n",
    "        model_enc = torch.flatten(model_enc, 0, 1)\n",
    "        model_enc = self.encoder(model_enc)\n",
    "        core_input = model_enc.view(*((T, B) + model_enc.shape[1:]))\n",
    "        core_output_list = []\n",
    "        notdone = ~(done.bool())\n",
    "        for n, (input, nd) in enumerate(zip(core_input.unbind(), notdone.unbind())):\n",
    "            for t in range(self.drc_n):\n",
    "                if t > 0:\n",
    "                    nd = torch.ones_like(nd)\n",
    "                nd = nd.view(-1)\n",
    "                output, core_state = self.core(input, core_state, nd, nd)\n",
    "            core_output_list.append(output)\n",
    "        core_output = torch.cat(core_output_list)\n",
    "        core_output = torch.flatten(core_output, 0, 1)\n",
    "        core_output = torch.cat([model_enc, core_output], dim=1)\n",
    "        core_output = torch.flatten(core_output, 1)\n",
    "        final_out = self.final_layer(core_output)\n",
    "        policy_logits = self.policy(final_out)\n",
    "        if not greedy:\n",
    "            action = torch.multinomial(F.softmax(policy_logits, dim=1), num_samples=1)\n",
    "        else:\n",
    "            action = torch.argmax(policy_logits, dim=1)\n",
    "        policy_logits = policy_logits.view(T, B, self.num_actions)\n",
    "        action = action.view(T, B)\n",
    "        baseline = self.baseline(final_out).view(T, B, 1)\n",
    "        reg_loss = (\n",
    "            1e-3 * torch.sum(policy_logits**2, dim=-1) / 2\n",
    "            + 1e-5 * torch.sum(final_out**2, dim=-1).view(T, B) / 2\n",
    "        )\n",
    "        actor_out = ActorOut(\n",
    "            policy_logits=policy_logits,\n",
    "            im_policy_logits=None,\n",
    "            reset_policy_logits=None,\n",
    "            action=action,\n",
    "            im_action=None,\n",
    "            reset_action=None,\n",
    "            baseline_enc=None,\n",
    "            baseline=baseline,\n",
    "            reg_loss=reg_loss,\n",
    "        )\n",
    "        return actor_out, core_state\n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "drc_net = DRCNet(obs_shape=None, gym_obs_shape=(3, 80, 80), num_actions=4, flags=None)\n",
    "obs = Namespace(gym_env_out=torch.zeros(5, 8, 3, 80, 80), done=torch.zeros(5, 8))\n",
    "core_state = drc_net.initial_state(batch_size=8)\n",
    "drc_net.forward(obs, core_state)\n",
    "sum(p.numel() for p in drc_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 32, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_state[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initalizing log worker\n"
     ]
    }
   ],
   "source": [
    "import time, timeit\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import traceback\n",
    "import ray\n",
    "import thinker.util as util\n",
    "from thinker.net import ActorNet, ModelNet\n",
    "from thinker.env import Environment\n",
    "\n",
    "\n",
    "def gen_video_wandb(video_stats, grayscale):\n",
    "    import cv2\n",
    "\n",
    "    # Generate video\n",
    "    imgs = []\n",
    "    hw = video_stats[\"real_imgs\"][0].shape[1]\n",
    "    copy_n = 1 if grayscale else 3\n",
    "\n",
    "    for i in range(len(video_stats[\"real_imgs\"])):\n",
    "        img = np.zeros(shape=(copy_n, hw, hw * 2), dtype=np.uint8)\n",
    "        real_img = np.copy(video_stats[\"real_imgs\"][i])\n",
    "        im_img = np.copy(video_stats[\"im_imgs\"][i])\n",
    "\n",
    "        if video_stats[\"status\"][i] == 1:\n",
    "            if grayscale:\n",
    "                im_img[0, :, :] = im_img[0, :, :] * 0.7\n",
    "            else:\n",
    "                im_img[0, :, :] = 255 * 0.3 + im_img[0, :, :] * 0.7\n",
    "                im_img[1, :, :] = 255 * 0.3 + im_img[1, :, :] * 0.7\n",
    "        elif video_stats[\"status\"][i] == 0:\n",
    "            if grayscale:\n",
    "                im_img[0, :, :] = 255 * 0.7 + im_img[0, :, :] * 0.3\n",
    "            else:\n",
    "                im_img[2, :, :] = 255 * 0.3 + im_img[2, :, :] * 0.7\n",
    "\n",
    "        img[:, :, :hw] = real_img\n",
    "        img[:, :, hw:] = im_img\n",
    "        imgs.append(img)\n",
    "\n",
    "    enlarge_fcator = 3\n",
    "    new_imgs = []\n",
    "    for img in imgs:\n",
    "        _, height, width = img.shape\n",
    "        new_height, new_width = height * enlarge_fcator, width * enlarge_fcator\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        resized_img = cv2.resize(\n",
    "            img, (new_width, new_height), interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "        if not grayscale:\n",
    "            resized_img = np.transpose(resized_img, (2, 0, 1))\n",
    "        new_imgs.append(resized_img)\n",
    "\n",
    "    return np.array(new_imgs)\n",
    "\n",
    "\n",
    "class SLogWorker:\n",
    "    def __init__(self, flags):\n",
    "        self.flags = flags\n",
    "        if flags.load_checkpoint:\n",
    "            self.check_point_path = flags.load_checkpoint\n",
    "        else:\n",
    "            self.check_point_path = \"%s/%s\" % (flags.savedir, flags.xpid)\n",
    "        self.actor_log_path = os.path.join(self.check_point_path, \"logs.csv\")\n",
    "        self.model_log_path = os.path.join(self.check_point_path, \"logs_model.csv\")\n",
    "        self.actor_net_path = os.path.join(self.check_point_path, \"ckp_actor.tar\")\n",
    "        self.model_net_path = os.path.join(self.check_point_path, \"ckp_model.tar\")\n",
    "        self.actor_fields = None\n",
    "        self.model_fields = None\n",
    "        self.last_actor_tick = -1\n",
    "        self.last_model_tick = -1\n",
    "        self.real_step = -1\n",
    "        self.last_real_step_v = -1\n",
    "        self.last_real_step_c = -1\n",
    "        self.vis_policy = self.flags.policy_vis_freq > 0\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self._logger = util.logger()\n",
    "        self._logger.info(\"Initalizing log worker\")\n",
    "        self.log_model = flags.train_model and not self.flags.disable_model\n",
    "        self.log_freq = 10  # log frequency (in second)\n",
    "        # self.wlogger = util.Wandb(flags)\n",
    "        self.timer = timeit.default_timer\n",
    "        self.video = None\n",
    "        self.grayscale = flags.grayscale\n",
    "\n",
    "        if self.vis_policy:\n",
    "            self.env = Environment(\n",
    "                flags, model_wrap=True, debug=True, device=self.device\n",
    "            )\n",
    "            self.env.seed(np.random.randint(10000))\n",
    "\n",
    "            self.actor_net = ActorNet(\n",
    "                obs_shape=self.env.model_out_shape,\n",
    "                gym_obs_shape=self.env.gym_env_out_shape,\n",
    "                num_actions=self.env.num_actions,\n",
    "                flags=flags,\n",
    "            )\n",
    "            self.actor_net.to(self.device)\n",
    "            self.actor_net.train(False)\n",
    "            self.model_net = ModelNet(\n",
    "                obs_shape=self.env.gym_env_out_shape,\n",
    "                num_actions=self.env.num_actions,\n",
    "                flags=flags,\n",
    "                debug=True,\n",
    "            )\n",
    "            self.model_net.train(False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def start(self):\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(self.log_freq)\n",
    "\n",
    "                # log stat\n",
    "                self.log_stat()\n",
    "\n",
    "                # visualize policy\n",
    "                if (\n",
    "                    self.real_step - self.last_real_step_v >= self.flags.policy_vis_freq\n",
    "                    and self.flags.policy_vis_freq > 0\n",
    "                ):\n",
    "                    self._logger.info(\n",
    "                        f\"Steps {self.real_step}: Uploading video to wandb...\"\n",
    "                    )\n",
    "                    self.last_real_step_v = self.real_step\n",
    "                    self.visualize_wandb()\n",
    "                    self._logger.info(\n",
    "                        f\"Steps {self.real_step}: Finish uploading video to wandb...\"\n",
    "                    )\n",
    "\n",
    "                # upload files\n",
    "                if (\n",
    "                    self.real_step - self.last_real_step_c >= self.flags.wandb_ckp_freq\n",
    "                    and self.flags.wandb_ckp_freq > 0\n",
    "                ):\n",
    "                    self._logger.info(\n",
    "                        f\"Steps {self.real_step}: Uploading files to wandb...\"\n",
    "                    )\n",
    "                    self.last_real_step_c = self.real_step\n",
    "                    # self.wlogger.wandb.save(os.path.join(self.check_point_path, \"*\"),\n",
    "                    #                        self.check_point_path)\n",
    "                    self._logger.info(\n",
    "                        f\"Steps {self.real_step}: Finish uploading files to wandb...\"\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            self._logger.error(\n",
    "                f\"Steps {self.real_step}: Exception detected in log_worker: {e}\"\n",
    "            )\n",
    "            self._logger.error(traceback.format_exc())\n",
    "        finally:\n",
    "            self.close(0)\n",
    "            return True\n",
    "\n",
    "    def read_stat(self, log, fields, tick, name):\n",
    "        # read the last line in log file and parse it as dict\n",
    "        # if log file not yet exists or last line has not been\n",
    "        # updated or fields / last line cannot be read, return None\n",
    "        if fields is None:\n",
    "            if os.path.exists(log):\n",
    "                with open(log, \"r\") as f:\n",
    "                    fields_ = f.readline()\n",
    "                if fields_.endswith(\"\\n\"):\n",
    "                    fields = fields_.strip().split(\",\")\n",
    "                    self._logger.info(f\"Steps {self.real_step}: Read fields for {name}\")\n",
    "                    self._logger.info(fields)\n",
    "                else:\n",
    "                    pass\n",
    "                    # self._logger.info(\"Cannot read fields from %s\" % log)\n",
    "            else:\n",
    "                self._logger.error(f\"Steps {self.real_step}: File {log} does not exist\")\n",
    "\n",
    "        if fields is not None:\n",
    "            stat = self.parse_line(fields, self.last_non_empty_line(log))\n",
    "            if stat is not None and tick != stat[\"_tick\"]:\n",
    "                tick = stat[\"_tick\"]\n",
    "                return stat, fields, tick\n",
    "        return None, fields, tick\n",
    "\n",
    "    def log_stat(self):\n",
    "        try:\n",
    "            actor_stat, self.actor_fields, self.last_actor_tick = self.read_stat(\n",
    "                self.actor_log_path, self.actor_fields, self.last_actor_tick, \"actor\"\n",
    "            )\n",
    "            if self.log_model:\n",
    "                model_stat, self.model_fields, self.last_model_tick = self.read_stat(\n",
    "                    self.model_log_path,\n",
    "                    self.model_fields,\n",
    "                    self.last_model_tick,\n",
    "                    \"model\",\n",
    "                )\n",
    "            stat = {}\n",
    "            if self.log_model and model_stat is not None:\n",
    "                stat.update(model_stat)\n",
    "\n",
    "            if actor_stat is not None:\n",
    "                self.real_step = actor_stat[\"real_step\"]\n",
    "                stat.update(actor_stat)\n",
    "\n",
    "            if self.video is not None:\n",
    "                stat.update(self.video)\n",
    "                self.video = None\n",
    "\n",
    "            excludes = [\"_tick\", \"# _tick\", \"_time\"]\n",
    "            for y in excludes:\n",
    "                stat.pop(y, None)\n",
    "            if stat:\n",
    "                stat[\"real_step\"] = self.real_step\n",
    "                # self.wlogger.wandb.log(stat, step=self.real_step)\n",
    "        except Exception as e:\n",
    "            self._logger.error(\n",
    "                f\"Steps {self.real_step}: Error loading stat from log: {e}\"\n",
    "            )\n",
    "            self._logger.error(traceback.format_exc())\n",
    "            return None\n",
    "        return\n",
    "\n",
    "    def visualize_wandb(self):\n",
    "        if not os.path.exists(self.actor_net_path):\n",
    "            self._logger.info(\n",
    "                f\"Steps {self.real_step}: Actor net checkpoint {self.actor_net_path} does not exist\"\n",
    "            )\n",
    "            return None\n",
    "        if not os.path.exists(self.model_net_path):\n",
    "            self._logger.info(\n",
    "                f\"Steps {self.real_step}: Model net checkpoint {self.model_net_path} does not exist\"\n",
    "            )\n",
    "            return None\n",
    "        try:\n",
    "            checkpoint = torch.load(self.actor_net_path, torch.device(\"cpu\"))\n",
    "            self.actor_net.set_weights(checkpoint[\"actor_net_state_dict\"])\n",
    "            checkpoint = torch.load(self.model_net_path, torch.device(\"cpu\"))\n",
    "            self.model_net.set_weights(checkpoint[\"model_net_state_dict\"])\n",
    "        except Exception as e:\n",
    "            self._logger.error(f\"Steps {self.real_step}: Error loading checkpoint: {e}\")\n",
    "            return None\n",
    "\n",
    "        env_out = self.env.initial(self.model_net)\n",
    "        actor_state = self.actor_net.initial_state(batch_size=1, device=self.device)\n",
    "\n",
    "        step = 0\n",
    "        record_steps = self.flags.policy_vis_length * self.flags.rec_t\n",
    "        max_steps = (\n",
    "            record_steps + np.random.randint(100) * self.flags.rec_t\n",
    "        )  # randomly skip the first 100 real steps\n",
    "        start_time = self.timer()\n",
    "\n",
    "        video_stats = {\"real_imgs\": [], \"im_imgs\": [], \"status\": []}\n",
    "        start_record = False\n",
    "\n",
    "        copy_n = 1 if self.grayscale else 3\n",
    "\n",
    "        while step < max_steps:\n",
    "            step += 1\n",
    "            actor_out, actor_state = self.actor_net(env_out, actor_state)\n",
    "            action = [actor_out.action, actor_out.im_action, actor_out.reset_action]\n",
    "            action = torch.cat(action, dim=-1).unsqueeze(0)\n",
    "            env_out = self.env.step(action, self.model_net)\n",
    "\n",
    "            if start_record:\n",
    "                if self.flags.perfect_model:\n",
    "                    gym_env_out = env_out.gym_env_out\n",
    "                else:\n",
    "                    gym_env_out = (torch.clamp(self.env.env.xs, 0, 1) * 255).to(\n",
    "                        torch.uint8\n",
    "                    )\n",
    "                # record data for generating video\n",
    "                if action[0, 0, 2] == 1:\n",
    "                    video_stats[\"real_imgs\"].append(video_stats[\"real_imgs\"][-1])\n",
    "                    video_stats[\"im_imgs\"].append(video_stats[\"real_imgs\"][-1])\n",
    "                    video_stats[\"status\"].append(1)\n",
    "                if env_out.cur_t[0, 0] == 0:\n",
    "                    video_stats[\"real_imgs\"].append(\n",
    "                        gym_env_out[0, 0, -copy_n:].cpu().numpy()\n",
    "                    )\n",
    "                    video_stats[\"status\"].append(0)\n",
    "                else:\n",
    "                    video_stats[\"real_imgs\"].append(video_stats[\"real_imgs\"][-1])\n",
    "                    video_stats[\"status\"].append(2)\n",
    "                video_stats[\"im_imgs\"].append(gym_env_out[0, 0, -copy_n:].cpu().numpy())\n",
    "\n",
    "            if (\n",
    "                step >= max_steps - record_steps\n",
    "                and env_out.cur_t.item() == 0\n",
    "                and not start_record\n",
    "            ):\n",
    "                video_stats[\"real_imgs\"].append(\n",
    "                    env_out.gym_env_out[0, 0, -copy_n:].cpu().numpy()\n",
    "                )\n",
    "                video_stats[\"im_imgs\"].append(video_stats[\"real_imgs\"][-1])\n",
    "                video_stats[\"status\"].append(\n",
    "                    0\n",
    "                )  # 0 for real step, 1 for reset, 2 for normal\n",
    "                start_record = True\n",
    "\n",
    "            # if self.timer() - start_time > self.log_freq:\n",
    "            #    start_time = self.timer()\n",
    "            #    self.log_stat()\n",
    "\n",
    "        self.video = gen_video_wandb(video_stats, self.grayscale)\n",
    "        # self.video = {f\"policy\": self.wlogger.wandb.Video(video, fps=5, format=\"gif\")}\n",
    "\n",
    "    def last_non_empty_line(self, file_path, delimiter=\"\\n\"):\n",
    "        # A safe version of reading last line\n",
    "        if os.path.getsize(file_path) <= 0:\n",
    "            self._logger.error(f\"Steps {self.real_step}: {file_path} is empty\")\n",
    "            return None\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            f.seek(-1, os.SEEK_END)  # Move to the last character in the file\n",
    "            last_char = f.read(1)\n",
    "            # If the line does not end with '\\n', it is incomplete\n",
    "            if last_char != delimiter.encode():\n",
    "                self._logger.error(\n",
    "                    f\"Steps {self.real_step}: Last line does not end with delimiter\"\n",
    "                )\n",
    "                return None\n",
    "            while f.tell() > 0:\n",
    "                char = f.read(1)\n",
    "                if char == delimiter.encode():\n",
    "                    line = f.readline().decode().strip()\n",
    "                    if line:\n",
    "                        return line\n",
    "                f.seek(-2, os.SEEK_CUR)\n",
    "        return None\n",
    "\n",
    "    def parse_line(self, header, line):\n",
    "        if header is None or line is None:\n",
    "            return None\n",
    "        data = re.split(r\",(?![^\\(]*\\))\", line.strip())\n",
    "        data_dict = {}\n",
    "        if len(header) != len(data):\n",
    "            self._logger.error(\n",
    "                f\"Steps {self.real_step}: Header size and data size mismatch\"\n",
    "            )\n",
    "            return None\n",
    "        for n, (key, value) in enumerate(zip(header, data)):\n",
    "            try:\n",
    "                if not value:\n",
    "                    value = None\n",
    "                else:\n",
    "                    value = eval(value)\n",
    "                if type(value) == str:\n",
    "                    value = eval(value)\n",
    "            except (SyntaxError, NameError, TypeError) as e:\n",
    "                self._logger.error(\n",
    "                    f\"Steps {self.real_step}: Cannot read value {value} for key {key}: {e}\"\n",
    "                )\n",
    "                return None\n",
    "            data_dict[key] = value\n",
    "            if n == 0:\n",
    "                data_dict[\"_tick\"] = value  # assume first column is the tick\n",
    "        return data_dict\n",
    "\n",
    "    def close(self, exit_code):\n",
    "        pass\n",
    "        # self.wlogger.wandb.finish(exit_code=exit_code)\n",
    "\n",
    "\n",
    "flags = util.parse(args=[\"--load_checkpoint\", \"D:/data/thinker/logs/tmp/latest\"])\n",
    "log_worker = SLogWorker(flags)\n",
    "log_worker.visualize_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_worker.visualize_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 3, 288, 576)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_shape = np.array(log_worker.video).shape\n",
    "print(video_shape)\n",
    "file_path = \"\"\n",
    "width = video_shape[3]\n",
    "height = video_shape[2]\n",
    "\n",
    "fps = 5\n",
    "path = os.path.join(file_path, \"video2.avi\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"FFV1\")\n",
    "video = cv2.VideoWriter(path, fourcc, float(fps), (width, height))\n",
    "video.set(cv2.CAP_PROP_BITRATE, 10000)  # set the video bitrate to 10000 kb/s\n",
    "for img in log_worker.video:\n",
    "    video.write(np.transpose(img, (1, 2, 0)))\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e1c3f15baeac42b350955c7791eba0d4b3a4c7ef635edb2d91a98439423f015"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
