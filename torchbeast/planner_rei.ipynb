{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d1c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import pprint\n",
    "import threading\n",
    "import time\n",
    "import timeit\n",
    "import traceback\n",
    "import typing\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Necessary for multithreading.\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing as mp\n",
    "from torch.multiprocessing import Process, Manager\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchbeast.core import file_writer\n",
    "from torchbeast.core import prof\n",
    "from torchbeast.core import vtrace\n",
    "from torchbeast.atari_wrappers import *\n",
    "from torchbeast.transformer_rnn import *\n",
    "from torchbeast.train import *\n",
    "from torchbeast.model import Model\n",
    "\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from collections import deque\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# util functions\n",
    "\n",
    "def get_git_revision_hash():\n",
    "    return subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()\n",
    "\n",
    "def exp_scale(x, start, end, n, m):\n",
    "    a = (end - start) / (np.exp(m * n) - 1)\n",
    "    c = start - a\n",
    "    x = np.clip(x, 0, n)    \n",
    "    return a * np.exp(m * x) + c\n",
    "\n",
    "class DataParallelWrapper(object):\n",
    "    def __init__(self, module):\n",
    "        self.module = module\n",
    "              \n",
    "    def __getattr__(self, name):        \n",
    "        if name in self.module.__dict__.keys(): \n",
    "            return getattr(self.module, name)\n",
    "        else:\n",
    "            return getattr(self.module.module, name)\n",
    "    \n",
    "# Update to original core funct\n",
    "\n",
    "def create_buffers(flags, obs_shape, num_actions, num_rewards) -> Buffers:\n",
    "    T = flags.unroll_length\n",
    "    specs = dict(\n",
    "        frame=dict(size=(T + 1, *obs_shape), dtype=torch.float32),\n",
    "        reward=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        done=dict(size=(T + 1,), dtype=torch.bool),\n",
    "        truncated_done=dict(size=(T + 1,), dtype=torch.bool),\n",
    "        episode_return=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        episode_step=dict(size=(T + 1,), dtype=torch.int32),\n",
    "        policy_logits=dict(size=(T + 1, num_actions), dtype=torch.float32),\n",
    "        im_policy_logits=dict(size=(T + 1, num_actions), dtype=torch.float32),        \n",
    "        reset_policy_logits=dict(size=(T + 1, 2), dtype=torch.float32),\n",
    "        baseline=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        last_action=dict(size=(T + 1, 3 if not flags.flex_t else 4), dtype=torch.int64),\n",
    "        action=dict(size=(T + 1,), dtype=torch.int64),\n",
    "        im_action=dict(size=(T + 1,), dtype=torch.int64),        \n",
    "        reset_action=dict(size=(T + 1,), dtype=torch.int64), \n",
    "        reg_loss=dict(size=(T + 1,), dtype=torch.float32),  \n",
    "        cur_t=dict(size=(T + 1,), dtype=torch.int64),             \n",
    "        max_rollout_depth=dict(size=(T + 1,), dtype=torch.float32),  \n",
    "    )\n",
    "    if flags.flex_t:\n",
    "        specs.update(dict(\n",
    "            term_policy_logits=dict(size=(T + 1, 2), dtype=torch.float32),\n",
    "            term_action=dict(size=(T + 1,), dtype=torch.int64),)\n",
    "                     )\n",
    "    \n",
    "    buffers: Buffers = {key: [] for key in specs}\n",
    "    for _ in range(flags.num_buffers):\n",
    "        for key in buffers:\n",
    "            buffers[key].append(torch.empty(**specs[key]).share_memory_())\n",
    "    return buffers  \n",
    "\n",
    "def act(\n",
    "    flags,\n",
    "    actor_index: int,\n",
    "    free_queue: mp.SimpleQueue,\n",
    "    full_queue: mp.SimpleQueue,\n",
    "    actor_net: torch.nn.Module,\n",
    "    model: torch.nn.Module,\n",
    "    buffers: Buffers,\n",
    "    initial_agent_state_buffers,\n",
    "):\n",
    "    try:\n",
    "        logging.info(\"Actor %i started.\", actor_index)\n",
    "        timings = prof.Timings()  # Keep track of how fast things are.\n",
    "\n",
    "        gym_env = ModelWrapper(SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop), \n",
    "                               model=model, flags=flags)\n",
    "        seed = actor_index ^ int.from_bytes(os.urandom(4), byteorder=\"little\")\n",
    "        gym_env.seed(seed)\n",
    "        env = Environment(gym_env)\n",
    "        env_output = env.initial()\n",
    "        agent_state = actor_net.initial_state(batch_size=1)\n",
    "        agent_output, unused_state = actor_net(env_output, agent_state)\n",
    "        while True:\n",
    "            index = free_queue.get()\n",
    "            if index is None:\n",
    "                break\n",
    "\n",
    "            # Write old rollout end.\n",
    "            for key in env_output:           \n",
    "                if key in buffers: buffers[key][index][0, ...] = env_output[key]\n",
    "            for key in agent_output:\n",
    "                if key in buffers: buffers[key][index][0, ...] = agent_output[key]                    \n",
    "            for i, tensor in enumerate(agent_state):\n",
    "                initial_agent_state_buffers[index][i][...] = tensor\n",
    "\n",
    "            # Do new rollout.\n",
    "            for t in range(flags.unroll_length):\n",
    "                timings.reset()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    agent_output, agent_state = actor_net(env_output, agent_state)                    \n",
    "\n",
    "                timings.time(\"actor_net\")\n",
    "                \n",
    "                action = [agent_output['action'], agent_output['im_action'], agent_output['reset_action']]\n",
    "                if 'term_action' in agent_output: action.append(agent_output['term_action'])\n",
    "                action = torch.cat(action, dim=-1)\n",
    "                env_output = env.step(action.unsqueeze(0))\n",
    "\n",
    "                if flags.trun_bs:\n",
    "                    if env_output['truncated_done']: \n",
    "                        env_output['reward'] = env_output['reward'] + flags.im_discounting * agent_output['baseline']\n",
    "\n",
    "                timings.time(\"step\")\n",
    "\n",
    "                for key in env_output:\n",
    "                    if key in buffers:\n",
    "                        buffers[key][index][t + 1, ...] = env_output[key]\n",
    "                for key in agent_output:\n",
    "                    if key in buffers:\n",
    "                        buffers[key][index][t + 1, ...] = agent_output[key]\n",
    "\n",
    "                timings.time(\"write\")\n",
    "            full_queue.put(index)\n",
    "\n",
    "        if actor_index == 0:\n",
    "            logging.info(\"Actor %i: %s\", actor_index, timings.summary())\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass  # Return silently.\n",
    "    except Exception as e:\n",
    "        logging.error(\"Exception in worker process %i\", actor_index)\n",
    "        traceback.print_exc()\n",
    "        print()\n",
    "        raise e\n",
    "\n",
    "def compute_baseline_loss(advantages, masks_ls, c_ls):\n",
    "    assert len(masks_ls) == len(c_ls)\n",
    "    loss = 0.  \n",
    "    for mask, c in zip(masks_ls, c_ls):\n",
    "        loss = loss + 0.5 * torch.sum((advantages * (1 - mask)) ** 2) * c        \n",
    "    return loss\n",
    "    \n",
    "def compute_policy_gradient_loss(logits_ls, actions_ls, masks_ls, c_ls, advantages):\n",
    "    assert len(logits_ls) == len(actions_ls) == len(masks_ls) == len(c_ls)\n",
    "    loss = 0.    \n",
    "    for logits, actions, masks, c in zip(logits_ls, actions_ls, masks_ls, c_ls):\n",
    "        cross_entropy = F.nll_loss(\n",
    "            F.log_softmax(torch.flatten(logits, 0, 1), dim=-1),\n",
    "            target=torch.flatten(actions, 0, 1),\n",
    "            reduction=\"none\",)\n",
    "        cross_entropy = cross_entropy.view_as(advantages)\n",
    "        adv_cross_entropy = cross_entropy * advantages.detach()\n",
    "        loss = loss + torch.sum(adv_cross_entropy * (1-masks)) * c\n",
    "    return loss  \n",
    "\n",
    "def compute_entropy_loss(logits_ls, masks_ls, c_ls):\n",
    "    \"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"\n",
    "    loss = 0.\n",
    "    assert(len(logits_ls) == len(masks_ls) == len(c_ls))\n",
    "    for logits, masks, c in zip(logits_ls, masks_ls, c_ls):\n",
    "        policy = F.softmax(logits, dim=-1)\n",
    "        log_policy = F.log_softmax(logits, dim=-1)\n",
    "        ent = torch.sum(policy * log_policy, dim=-1) #* (1-masks)\n",
    "        loss = loss + torch.sum(ent) * c \n",
    "    return loss\n",
    "\n",
    "def action_log_probs(policy_logits, actions):\n",
    "    return -F.nll_loss(\n",
    "        F.log_softmax(torch.flatten(policy_logits, 0, -2), dim=-1),\n",
    "        torch.flatten(actions),\n",
    "        reduction=\"none\",\n",
    "    ).view_as(actions) \n",
    "  \n",
    "def from_logits(\n",
    "    behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "    discounts, rewards, values, bootstrap_value, clip_rho_threshold=1.0,\n",
    "    clip_pg_rho_threshold=1.0, lamb=1.0,):\n",
    "    \"\"\"V-trace for softmax policies.\"\"\"\n",
    "    assert(len(behavior_logits_ls) == len(target_logits_ls) == len(actions_ls) == len(masks_ls))\n",
    "    log_rhos = 0.       \n",
    "    for behavior_logits, target_logits, actions, masks in zip(behavior_logits_ls, \n",
    "             target_logits_ls, actions_ls, masks_ls):\n",
    "        behavior_log_probs = action_log_probs(behavior_logits, actions)        \n",
    "        target_log_probs = action_log_probs(target_logits, actions)\n",
    "        log_rho = target_log_probs - behavior_log_probs\n",
    "        log_rhos = log_rhos + log_rho * (1-masks)\n",
    "    \n",
    "    vtrace_returns = vtrace.from_importance_weights(\n",
    "        log_rhos=log_rhos,\n",
    "        discounts=discounts,\n",
    "        rewards=rewards,\n",
    "        values=values,\n",
    "        bootstrap_value=bootstrap_value,\n",
    "        clip_rho_threshold=clip_rho_threshold,\n",
    "        clip_pg_rho_threshold=clip_pg_rho_threshold,\n",
    "        lamb=lamb\n",
    "    )\n",
    "    return vtrace.VTraceFromLogitsReturns(\n",
    "        log_rhos=log_rhos,\n",
    "        behavior_action_log_probs=None,\n",
    "        target_action_log_probs=None,\n",
    "        **vtrace_returns._asdict(),\n",
    "    )  \n",
    "\n",
    "def learn(\n",
    "    flags,\n",
    "    actor_model,\n",
    "    model,\n",
    "    batch,\n",
    "    initial_agent_state,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    real_step,\n",
    "    lock=threading.Lock(),  # noqa: B008\n",
    "):\n",
    "    \"\"\"Performs a learning (optimization) step.\"\"\"\n",
    "    learn_(flags, actor_model, model, batch, initial_agent_state, optimizer, scheduler, lock=threading.Lock()),  # noqa: B008)\n",
    "    \n",
    "    with lock:                \n",
    "        learner_outputs, unused_state = model(batch, initial_agent_state)\n",
    "        #learner_outputs[\"im_policy_logits\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        #learner_outputs[\"reset_policy_logits\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        #learner_outputs[\"baseline\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        \n",
    "        # Take final value function slice for bootstrapping.\n",
    "        bootstrap_value = learner_outputs[\"baseline\"][-1]        \n",
    "\n",
    "        # Move from obs[t] -> action[t] to action[t] -> obs[t].\n",
    "        batch = {key: tensor[1:] for key, tensor in batch.items()}\n",
    "        learner_outputs = {key: tensor[:-1] for key, tensor in learner_outputs.items()}\n",
    "        \n",
    "        T, B = batch[\"done\"].shape\n",
    "\n",
    "        rewards = batch[\"reward\"]\n",
    "        if flags.reward_clipping > 0:\n",
    "            clipped_rewards = torch.clamp(rewards, -flags.reward_clipping, flags.reward_clipping)\n",
    "        else:\n",
    "            clipped_rewards = rewards\n",
    "        \n",
    "        # compute advantage w.r.t real rewards\n",
    "        \n",
    "        discounts = (~batch[\"done\"]).float() * flags.im_discounting        \n",
    "        #discounts = (~batch[\"done\"]).float()\n",
    "        #discounts[batch[\"cur_t\"] == 0] = flags.discounting\n",
    "        \n",
    "        behavior_logits_ls = [batch[\"policy_logits\"], batch[\"im_policy_logits\"], batch[\"reset_policy_logits\"]]\n",
    "        target_logits_ls = [learner_outputs[\"policy_logits\"], learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "        actions_ls = [batch[\"action\"], batch[\"im_action\"], batch[\"reset_action\"]]        \n",
    "        im_mask = (batch[\"cur_t\"] == 0).float()\n",
    "        real_mask = 1 - im_mask\n",
    "        zero_mask = torch.zeros_like(im_mask)\n",
    "        masks_ls = [real_mask, im_mask, im_mask]                \n",
    "        c_ls = [flags.real_cost, flags.real_im_cost, flags.real_im_cost]\n",
    "           \n",
    "        if flags.flex_t:\n",
    "            behavior_logits_ls.append(batch[\"term_policy_logits\"])\n",
    "            target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "            actions_ls.append(batch[\"term_action\"])\n",
    "            masks_ls.append(zero_mask)\n",
    "            c_ls.append(flags.real_im_cost)\n",
    "\n",
    "        vtrace_returns = from_logits(\n",
    "            behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "            discounts=discounts,\n",
    "            rewards=clipped_rewards[:, :, 0],\n",
    "            values=learner_outputs[\"baseline\"][:, :, 0],\n",
    "            bootstrap_value=bootstrap_value[:, 0],\n",
    "            lamb=flags.lamb\n",
    "        )        \n",
    "        \n",
    "        pg_loss = compute_policy_gradient_loss(target_logits_ls, actions_ls, masks_ls, c_ls, vtrace_returns.pg_advantages, )  \n",
    "        \n",
    "        baseline_loss = flags.baseline_cost * compute_baseline_loss(\n",
    "            vtrace_returns.vs - learner_outputs[\"baseline\"][:, :, 0], \n",
    "            masks_ls = [real_mask, im_mask], c_ls = [flags.real_cost, flags.real_im_cost])\n",
    "       \n",
    "        # compute advantage w.r.t imagainary rewards\n",
    "\n",
    "        if flags.reward_type == 1:\n",
    "            if flags.reward_carry:                \n",
    "                discounts = (~batch[\"done\"]).float() * flags.im_discounting \n",
    "            else:\n",
    "                discounts = (~(batch[\"cur_t\"] == 0)).float() * flags.im_discounting        \n",
    "            behavior_logits_ls = [batch[\"im_policy_logits\"], batch[\"reset_policy_logits\"]]\n",
    "            target_logits_ls = [learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "            actions_ls = [batch[\"im_action\"], batch[\"reset_action\"]] \n",
    "            masks_ls = [im_mask, im_mask]  \n",
    "            c_ls = [flags.im_cost, flags.im_cost]\n",
    "            \n",
    "            if flags.flex_t:\n",
    "                behavior_logits_ls.append(batch[\"term_policy_logits\"])\n",
    "                target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "                actions_ls.append(batch[\"term_action\"])\n",
    "                masks_ls.append(zero_mask)\n",
    "                c_ls.append(flags.im_cost)\n",
    "            \n",
    "            vtrace_returns = from_logits(\n",
    "                behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "                discounts=discounts,\n",
    "                rewards=clipped_rewards[:, :, 1],\n",
    "                values=learner_outputs[\"baseline\"][:, :, 1],\n",
    "                bootstrap_value=bootstrap_value[:, 1],\n",
    "                lamb=flags.lamb\n",
    "            )\n",
    "            im_pg_loss = compute_policy_gradient_loss(target_logits_ls, actions_ls, masks_ls, c_ls, vtrace_returns.pg_advantages, )   \n",
    "            im_baseline_loss = flags.baseline_cost * compute_baseline_loss(\n",
    "                vtrace_returns.vs - learner_outputs[\"baseline\"][:, :, 1], masks_ls = [zero_mask], c_ls = [flags.im_cost])     \n",
    "            \n",
    "        target_logits_ls = [learner_outputs[\"policy_logits\"], learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "        masks_ls = [real_mask, im_mask, im_mask]    \n",
    "        im_ent_c = flags.im_entropy_cost * (flags.real_im_cost + (flags.im_cost if flags.reward_type == 1 else 0))\n",
    "        c_ls = [flags.entropy_cost * flags.real_cost, im_ent_c, im_ent_c]\n",
    "        if flags.flex_t:\n",
    "            target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "            masks_ls.append(zero_mask)\n",
    "            c_ls.append(im_ent_c)        \n",
    "        entropy_loss = compute_entropy_loss(target_logits_ls, masks_ls, c_ls)       \n",
    "            \n",
    "\n",
    "        reg_loss = flags.reg_cost * torch.sum(learner_outputs[\"reg_loss\"])\n",
    "        total_loss = pg_loss + baseline_loss + entropy_loss + reg_loss\n",
    "        \n",
    "        print(\"1 pg_loss:%f im_pg_loss %f baseline_loss %f im_baseline_loss %f entropy_loss %f\" % (pg_loss, im_pg_loss, baseline_loss, im_baseline_loss, entropy_loss))              \n",
    "              \n",
    "        if flags.reward_type == 1:\n",
    "            total_loss = total_loss + im_pg_loss + im_baseline_loss\n",
    "        \n",
    "        episode_returns = batch[\"episode_return\"][batch[\"done\"]][:, 0]  \n",
    "        max_rollout_depth = (batch[\"max_rollout_depth\"][batch[\"cur_t\"] == 0]).detach().cpu().numpy()\n",
    "        max_rollout_depth = np.average(max_rollout_depth) if len (max_rollout_depth) > 0 else 0.        \n",
    "        real_step = torch.sum(batch[\"cur_t\"]==0).item()\n",
    "        stats = {\n",
    "            \"episode_returns\": tuple(episode_returns.detach().cpu().numpy()),\n",
    "            \"mean_episode_return\": torch.mean(episode_returns).item(),\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"pg_loss\": pg_loss.item(),\n",
    "            \"baseline_loss\": baseline_loss.item(),\n",
    "            \"entropy_loss\": entropy_loss.item(),\n",
    "            \"reg_loss\": reg_loss.item(),\n",
    "            \"max_rollout_depth\": max_rollout_depth,\n",
    "            \"real_step\": real_step,\n",
    "            \"mean_plan_step\": T * B / max(real_step, 1),\n",
    "        }\n",
    "        \n",
    "        if flags.reward_type == 1:            \n",
    "            im_episode_returns = batch[\"episode_return\"][batch[\"cur_t\"] == 0][:, 1]\n",
    "            stats[\"im_episode_returns\"] = tuple(im_episode_returns.detach().cpu().numpy())\n",
    "            stats[\"im_pg_loss\"] = im_pg_loss.item()\n",
    "            stats[\"im_baseline_loss\"] = im_baseline_loss.item()   \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimize_params = optimizer.param_groups[0]['params']\n",
    "        if flags.grad_norm_clipping > 0:\n",
    "            total_norm = nn.utils.clip_grad_norm_(optimize_params, flags.grad_norm_clipping)\n",
    "        else:\n",
    "            total_norm = 0.\n",
    "            parameters = [p for p in optimize_params if p.grad is not None and p.requires_grad]\n",
    "            for p in parameters:\n",
    "                param_norm = p.grad.detach().data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** 0.5\n",
    "        stats[\"total_norm\"] = total_norm\n",
    "        \n",
    "        optimizer.step()\n",
    "        if not flags.flex_t:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.last_epoch = real_step - 1  # scheduler does not support setting epoch directly\n",
    "            scheduler.step() \n",
    "\n",
    "        actor_model.load_state_dict(model.state_dict())\n",
    "        return stats  \n",
    "\n",
    "# Wrap the environment with a model\n",
    "\n",
    "def _format_frame(frame, bsz=None):\n",
    "    if type(frame) == np.ndarray:\n",
    "        frame = torch.from_numpy(frame).float()\n",
    "    if bsz is not None:\n",
    "        return frame.view((1,) + frame.shape)\n",
    "    else:\n",
    "        return frame.view((1, 1) + frame.shape)\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, gym_env):\n",
    "        self.gym_env = gym_env\n",
    "        self.episode_return = None\n",
    "        self.episode_step = None\n",
    "\n",
    "    def initial(self):\n",
    "        initial_reward = torch.zeros(1, 1)\n",
    "        # This supports only single-tensor actions ATM.\n",
    "        initial_last_action = torch.zeros(1, 1, dtype=torch.int64)\n",
    "        self.episode_return = torch.zeros(1, 1, 1)\n",
    "        self.episode_step = torch.zeros(1, 1, dtype=torch.int32)\n",
    "        initial_done = torch.ones(1, 1, dtype=torch.bool)\n",
    "        initial_frame = _format_frame(self.gym_env.reset())\n",
    "        return dict(\n",
    "            frame=initial_frame,\n",
    "            reward=initial_reward,\n",
    "            done=initial_done,\n",
    "            truncated_done=torch.tensor(0).view(1, 1).bool(),\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=torch.tensor(0).view(1, 1),\n",
    "            last_action=initial_last_action,\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        frame, reward, done, unused_info = self.gym_env.step(action[0,0].cpu().detach().numpy())     \n",
    "        self.episode_step += 1\n",
    "        self.episode_return = self.episode_return + torch.tensor(reward).unsqueeze(0).unsqueeze(0)\n",
    "        episode_step = self.episode_step\n",
    "        episode_return = self.episode_return.clone()\n",
    "        if done:\n",
    "            frame = self.gym_env.reset()\n",
    "            self.episode_return = torch.zeros(1, 1, 1)\n",
    "            self.episode_step = torch.zeros(1, 1, dtype=torch.int32)        \n",
    "        frame = _format_frame(frame)\n",
    "        reward = torch.tensor(reward).view(1, 1, -1)\n",
    "        done = torch.tensor(done).view(1, 1)\n",
    "        truncated_done = 'TimeLimit.truncated' in unused_info and unused_info['TimeLimit.truncated']\n",
    "        truncated_done = torch.tensor(truncated_done).view(1, 1)\n",
    "        cur_t = torch.tensor(unused_info[\"cur_t\"]).view(1, 1)\n",
    "        if cur_t == 0 and self.episode_return.shape[2] > 1:\n",
    "            self.episode_return[:, :, 1] = 0.\n",
    "        if 'max_rollout_depth' in unused_info:\n",
    "            max_rollout_depth = torch.tensor(unused_info[\"max_rollout_depth\"]).view(1, 1)\n",
    "        else:\n",
    "            max_rollout_depth = torch.tensor(0.).view(1, 1)\n",
    "        \n",
    "        return dict(\n",
    "            frame=frame,\n",
    "            reward=reward,\n",
    "            done=done,\n",
    "            truncated_done=truncated_done,          \n",
    "            episode_return=episode_return,\n",
    "            episode_step=episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=action,\n",
    "            max_rollout_depth=max_rollout_depth\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        self.gym_env.close()\n",
    "\n",
    "    def clone_state(self):\n",
    "        state = self.gym_env.clone_state()\n",
    "        state[\"env_episode_return\"] = self.episode_return.clone()\n",
    "        state[\"env_episode_step\"] = self.episode_step.clone()\n",
    "        return state\n",
    "        \n",
    "    def restore_state(self, state):\n",
    "        self.episode_return = state[\"env_episode_return\"].clone()\n",
    "        self.episode_step = state[\"env_episode_step\"].clone()\n",
    "        self.gym_env.restore_state(state)\n",
    "        \n",
    "class Vec_Environment:\n",
    "    # deprecated\n",
    "    def __init__(self, gym_env, bsz):\n",
    "        self.gym_env = gym_env\n",
    "        self.bsz = bsz\n",
    "        self.episode_return = torch.zeros(1, self.bsz)\n",
    "        self.episode_step = torch.zeros(1, self.bsz)        \n",
    "\n",
    "    def initial(self):\n",
    "        initial_reward = torch.zeros(1, self.bsz, 1)\n",
    "        # This supports only single-tensor actions ATM.\n",
    "        initial_last_action = torch.zeros(1, self.bsz, dtype=torch.int64)\n",
    "        self.episode_return = torch.zeros(1, self.bsz)\n",
    "        self.episode_step = torch.zeros(1, self.bsz, dtype=torch.int32)\n",
    "        initial_done = torch.ones(1, self.bsz, dtype=torch.uint8)\n",
    "        initial_frame = _format_frame(self.gym_env.reset(), self.bsz)\n",
    "        cur_t = torch.zeros(1, self.bsz)\n",
    "        \n",
    "        return dict(\n",
    "            frame=initial_frame,\n",
    "            reward=initial_reward,\n",
    "            done=initial_done,\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=initial_last_action,\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        frame, reward, done, unused_info = self.gym_env.step(action.detach().cpu().numpy())   \n",
    "        \n",
    "        self.episode_step += 1\n",
    "        self.episode_return += torch.Tensor(reward).unsqueeze(0)\n",
    "        \n",
    "        done = torch.tensor(done).view(1, self.bsz)\n",
    "        truncated_done = ['TimeLimit.truncated' in x and x['TimeLimit.truncated'] for x in unused_info]\n",
    "        truncated_done = torch.tensor(truncated_done).view(1, self.bsz)\n",
    "        \n",
    "        self.episode_return = (~done).float().unsqueeze(-1) * self.episode_return\n",
    "        self.episode_step = (~done).float() * self.episode_step\n",
    "        \n",
    "        frame = _format_frame(frame, self.bsz)\n",
    "        reward = torch.tensor(reward).view(1, self.bsz).float()\n",
    "        \n",
    "        cur_t = [x[\"cur_t\"] for x in unused_info]  \n",
    "        cur_t = torch.tensor(cur_t).view(1, self.bsz)\n",
    "        \n",
    "        return dict(\n",
    "            frame=frame,\n",
    "            reward=reward,\n",
    "            done=done,\n",
    "            truncated_done=truncated_done,\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=action.unsqueeze(0),\n",
    "        )\n",
    "    \n",
    "    def clone_state(self):        \n",
    "        state = {}\n",
    "        state[\"env_episode_return\"] = self.episode_return.clone()\n",
    "        state[\"env_episode_step\"] = self.episode_step.clone()\n",
    "        for n, k in enumerate(self.gym_env.envs): \n",
    "            state[\"env_%d\"%n] = k.clone_state()\n",
    "        return state\n",
    "        \n",
    "    def restore_state(self, state):\n",
    "        self.episode_return = state[\"env_episode_return\"].clone()\n",
    "        self.episode_step = state[\"env_episode_step\"].clone()\n",
    "        for n, k in enumerate(self.gym_env.envs): \n",
    "            k.restore_state(state[\"env_%d\"%n])\n",
    "\n",
    "    def close(self):\n",
    "        self.gym_env.close()  \n",
    "\n",
    "class Actor_net(nn.Module):    \n",
    "    def __init__(self, obs_shape, num_actions, flags):\n",
    "\n",
    "        super(Actor_net, self).__init__()\n",
    "        self.obs_shape = obs_shape\n",
    "        self.num_actions = num_actions  \n",
    "        \n",
    "        self.tran_t = flags.tran_t                   # number of recurrence of RNN        \n",
    "        self.tran_mem_n = flags.tran_mem_n           # size of memory for the attn modules\n",
    "        self.tran_layer_n = flags.tran_layer_n       # number of layers\n",
    "        self.tran_lstm = flags.tran_lstm             # to use lstm or not\n",
    "        self.tran_lstm_no_attn = flags.tran_lstm_no_attn  # to use attention in lstm or not\n",
    "        self.tran_lstm_new = flags.tran_lstm_new\n",
    "        self.attn_mask_b = flags.tran_attn_b         # atention bias for current position\n",
    "        self.tran_norm_first = flags.tran_norm_first # to use norm first in transformer (not on LSTM)\n",
    "        self.tran_ff_n = flags.tran_ff_n             # number of dim of ff in transformer (not on LSTM)        \n",
    "        self.tran_skip = flags.tran_skip             # whether to add skip connection\n",
    "        self.conv_out = flags.tran_dim               # size of transformer / LSTM embedding dim        \n",
    "        self.no_mem = flags.no_mem                   # whether to earse real memory at the end of planning stage\n",
    "        self.num_rewards = flags.num_rewards         # dim of rewards (1 for vanilla; 2 for planning rewards)\n",
    "        self.flex_t = flags.flex_t                   # whether to output the terminate action\n",
    "        self.flex_t_term_b = flags.flex_t_term_b     # bias added to the logit of terminating\n",
    "        \n",
    "        self.conv_out_hw = 1   \n",
    "        self.d_model = self.conv_out\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=self.obs_shape[0], out_channels=self.conv_out//2, kernel_size=1, stride=1)        \n",
    "        self.conv2 = nn.Conv2d(in_channels=self.conv_out//2, out_channels=self.conv_out, kernel_size=1, stride=1)        \n",
    "        self.frame_conv = torch.nn.Sequential(self.conv1, nn.ReLU(), self.conv2, nn.ReLU())\n",
    "        self.env_input_size = self.conv_out\n",
    "        d_in = self.env_input_size + self.d_model \n",
    "        \n",
    "        if self.tran_lstm:\n",
    "            self.core = ConvAttnLSTM(h=self.conv_out_hw, w=self.conv_out_hw,\n",
    "                                 input_dim=d_in-self.d_model, hidden_dim=self.d_model,\n",
    "                                 kernel_size=1, num_layers=self.tran_layer_n,\n",
    "                                 num_heads=8, mem_n=self.tran_mem_n, attn=not self.tran_lstm_no_attn,\n",
    "                                 attn_mask_b=self.attn_mask_b, legacy= not self.tran_lstm_new)\n",
    "        else:            \n",
    "            self.core = ConvTransformerRNN(d_in=d_in,\n",
    "                                       h=self.conv_out_hw, w=self.conv_out_hw, d_model=self.d_model, \n",
    "                                       num_heads=8, dim_feedforward=self.tran_ff_n, \n",
    "                                       mem_n=self.tran_mem_n, norm_first=self.tran_norm_first,\n",
    "                                       num_layers=self.tran_layer_n, rpos=True, conv=False)   \n",
    "                         \n",
    "        \n",
    "        if self.tran_skip:\n",
    "            rnn_out_size = self.conv_out_hw * self.conv_out_hw * (self.d_model + self.env_input_size)\n",
    "        else:\n",
    "            rnn_out_size = self.conv_out_hw * self.conv_out_hw * self.d_model\n",
    "                \n",
    "        self.fc = nn.Linear(rnn_out_size, 256)        \n",
    "        \n",
    "        self.im_policy = nn.Linear(256, self.num_actions)        \n",
    "        self.policy = nn.Linear(256, self.num_actions)        \n",
    "        self.baseline = nn.Linear(256, self.num_rewards)        \n",
    "        self.reset = nn.Linear(256, 2)        \n",
    "        \n",
    "        if self.flex_t: self.term = nn.Linear(256, 2)        \n",
    "        \n",
    "        print(\"actor size: \", sum(p.numel() for p in self.parameters()))\n",
    "        #for k, v in self.named_parameters(): print(k, v.numel())   \n",
    "\n",
    "    def initial_state(self, batch_size):\n",
    "        state = self.core.init_state(batch_size) + (torch.zeros(1, batch_size, \n",
    "               self.env_input_size, self.conv_out_hw, self.conv_out_hw),)\n",
    "        return state\n",
    "\n",
    "    def forward(self, obs, core_state=(), debug=False):\n",
    "        # one-step forward for the actor\n",
    "        # input / done shape x: T x B x C x 1 x 1 / B x C x 1 x 1\n",
    "        # only supports T = 1 at the moment; all output does not have T dim.        \n",
    "        \n",
    "        x = obs[\"frame\"]\n",
    "        done = obs[\"done\"]\n",
    "        \n",
    "        if len(x.shape) == 4: x = x.unsqueeze(0)\n",
    "        if len(done.shape) == 1: done = done.unsqueeze(0)  \n",
    "            \n",
    "        T, B, *_ = x.shape\n",
    "        x = torch.flatten(x, 0, 1)  # Merge time and batch.  \n",
    "        env_input = self.frame_conv(x)                \n",
    "        core_input = env_input.view(T, B, -1, self.conv_out_hw, self.conv_out_hw)\n",
    "        core_output_list = []\n",
    "        notdone = ~(done.bool())\n",
    "        \n",
    "        for n, (input, nd) in enumerate(zip(core_input.unbind(), notdone.unbind())):       \n",
    "            if self.no_mem and obs[\"cur_t\"][n, 0] == 0:\n",
    "                core_state = self.initial_state(B)\n",
    "                core_state = tuple(v.to(x.device) for v in core_state)\n",
    "                \n",
    "            # Input shape: B, self.conv_out + self.num_actions + 1, H, W\n",
    "            for t in range(self.tran_t):                \n",
    "                if t > 0: nd = torch.ones(B).to(x.device).bool()                    \n",
    "                nd = nd.view(-1)      \n",
    "                output, core_state = self.core(input, core_state, nd, nd) # output shape: 1, B, core_output_size \n",
    "                \n",
    "            last_input = input   \n",
    "            core_output_list.append(output)\n",
    "                                   \n",
    "        core_output = torch.cat(core_output_list)  \n",
    "        if self.tran_skip: core_output = torch.concat([core_output, core_input], dim=-3)\n",
    "        core_output = torch.flatten(core_output, 0, 1)        \n",
    "        core_output = F.relu(self.fc(torch.flatten(core_output, start_dim=1)))   \n",
    "        \n",
    "        policy_logits = self.policy(core_output)\n",
    "        im_policy_logits = self.im_policy(core_output)\n",
    "        reset_policy_logits = self.reset(core_output)\n",
    "        \n",
    "        if self.flex_t: \n",
    "            term_policy_logits = self.term(core_output)            \n",
    "            term_policy_logits[:, 1] += self.flex_t_term_b\n",
    "        \n",
    "        action = torch.multinomial(F.softmax(policy_logits, dim=1), num_samples=1)\n",
    "        im_action = torch.multinomial(F.softmax(im_policy_logits, dim=1), num_samples=1)\n",
    "        reset_action = torch.multinomial(F.softmax(reset_policy_logits, dim=1), num_samples=1)\n",
    "        if self.flex_t: term_action = torch.multinomial(F.softmax(term_policy_logits, dim=1), num_samples=1)\n",
    "                \n",
    "        baseline = self.baseline(core_output)\n",
    "                   \n",
    "        reg_loss = (1e-3 * torch.sum(policy_logits**2, dim=-1) / 2 + \n",
    "                    1e-5 * torch.sum(core_output**2, dim=-1) / 2)\n",
    "        reg_loss = reg_loss.view(T, B)\n",
    "        \n",
    "        policy_logits = policy_logits.view(T, B, self.num_actions)\n",
    "        im_policy_logits = im_policy_logits.view(T, B, self.num_actions)\n",
    "        reset_policy_logits = reset_policy_logits.view(T, B, 2)\n",
    "        if self.flex_t: term_policy_logits = term_policy_logits.view(T, B, 2)\n",
    "            \n",
    "        \n",
    "        action = action.view(T, B)      \n",
    "        im_action = im_action.view(T, B)      \n",
    "        reset_action = reset_action.view(T, B)             \n",
    "        if self.flex_t: term_action = term_action.view(T, B)\n",
    "        baseline = baseline.view(T, B, self.num_rewards)\n",
    "        \n",
    "        ret_dict = dict(policy_logits=policy_logits,                         \n",
    "                        im_policy_logits=im_policy_logits,                         \n",
    "                        reset_policy_logits=reset_policy_logits,     \n",
    "                        action=action,     \n",
    "                        im_action=im_action,\n",
    "                        reset_action=reset_action,\n",
    "                        baseline=baseline, \n",
    "                        reg_loss=reg_loss, )\n",
    "        \n",
    "        if self.flex_t: ret_dict.update(dict(term_policy_logits=term_policy_logits,    \n",
    "                                             term_action=term_action))\n",
    "        return (ret_dict, core_state) \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2) * (-math.log(10000.0) / dim))\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, step) :\n",
    "        # step: int Tensor, shape [batch_size]\n",
    "        step = torch.clamp(step, 0, self.max_len-1)\n",
    "        return self.pe[step, :]    \n",
    "        \n",
    "class ModelWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, model, flags):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        \n",
    "        self.env = env\n",
    "        self.model = model                \n",
    "        self.rec_t = flags.rec_t        \n",
    "        self.flex_t = flags.flex_t \n",
    "        self.flex_t_cost = flags.flex_t_cost         \n",
    "        self.flex_t_cost_m = flags.flex_t_cost_m\n",
    "        self.flex_t_cost_type = flags.flex_t_cost_type\n",
    "        self.discounting = flags.discounting\n",
    "        self.stat_pos_encode = flags.stat_pos_encode\n",
    "        self.stat_pos_encode_dim = flags.stat_pos_encode_dim\n",
    "        self.reward_type = flags.reward_type    \n",
    "        self.no_mem = flags.no_mem\n",
    "        self.perfect_model = flags.perfect_model\n",
    "        self.reset_m = flags.reset_m\n",
    "        self.tree_carry = flags.tree_carry\n",
    "        self.tree_vb = flags.tree_vb\n",
    "        self.thres_carry = flags.thres_carry        \n",
    "        self.thres_discounting = flags.thres_discounting\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.root_node = None\n",
    "            \n",
    "        if not self.flex_t:\n",
    "            obs_n = 9 + num_actions * 10 + (self.rec_t if not self.stat_pos_encode else (2 * self.stat_pos_encode_dim))\n",
    "        else:\n",
    "            obs_n = 10 + num_actions * 10  + (1 if not self.stat_pos_encode else (2 * self.stat_pos_encode_dim))          \n",
    "        if self.stat_pos_encode:\n",
    "            obs_n = obs_n - num_actions * 2 + self.stat_pos_encode_dim * num_actions * 2\n",
    "        \n",
    "        self.observation_space = gym.spaces.Box(\n",
    "          low=-np.inf, high=np.inf, shape=(obs_n, 1, 1), dtype=float)\n",
    "        self.model.train(False)        \n",
    "        \n",
    "        self.max_rollout_depth = 0.\n",
    "        self.thres = None\n",
    "        self.root_max_q = None\n",
    "        \n",
    "        if self.stat_pos_encode:\n",
    "            self.pos = PositionalEncoding(dim=self.stat_pos_encode_dim, max_len=self.rec_t)\n",
    "        else:\n",
    "            self.pos = None\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        x = self.env.reset()\n",
    "        self.cur_t = 0        \n",
    "        out = self.use_model(x, 0., 0, self.cur_t, reset=1., term=0., done=False)\n",
    "        if self.reward_type == 1:\n",
    "            self.last_root_max_q = self.root_max_q\n",
    "        return out.unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    def step(self, action):  \n",
    "        if not self.flex_t:\n",
    "            re_action, im_action, reset = action\n",
    "            term = None\n",
    "        else:\n",
    "            re_action, im_action, reset, term = action\n",
    "        info = {}\n",
    "        info[\"max_rollout_depth\"] = self.max_rollout_depth\n",
    "        if (not self.flex_t and self.cur_t < self.rec_t - 1) or (\n",
    "            self.flex_t and self.cur_t < self.rec_t - 1 and not term):\n",
    "          self.cur_t += 1\n",
    "          out = self.use_model(None, None, im_action, self.cur_t, reset=reset, term=term, done=False)          \n",
    "          if self.reward_type == 0:\n",
    "            r = np.array([0.])\n",
    "          else:\n",
    "            if self.flex_t:\n",
    "                if self.flex_t_cost_type == 0:\n",
    "                    flex_t_cost = self.flex_t_cost\n",
    "                elif self.flex_t_cost_type == 1:\n",
    "                    flex_t_cost = exp_scale(self.cur_t, 1e-7, self.flex_t_cost, self.rec_t, self.flex_t_cost_m)\n",
    "            else:                \n",
    "                flex_t_cost = 0.\n",
    "            r = np.array([0., (self.root_max_q - self.last_root_max_q - flex_t_cost).item()], dtype=np.float32)\n",
    "          done = False\n",
    "          info['cur_t'] = self.cur_t   \n",
    "        else:\n",
    "          self.cur_t = 0\n",
    "          if self.perfect_model: self.env.restore_state(self.root_node.encoded)\n",
    "          x, r, done, info_ = self.env.step(re_action)                    \n",
    "          out = self.use_model(x, r, re_action, self.cur_t, reset=1., term=term, done=done) \n",
    "          info.update(info_)\n",
    "          info['cur_t'] = self.cur_t\n",
    "          if self.reward_type == 0:\n",
    "            r = np.array([r])\n",
    "          else:\n",
    "            r = np.array([r, 0.], dtype=np.float32)   \n",
    "        if self.reward_type == 1:\n",
    "            self.last_root_max_q = self.root_max_q   \n",
    "        \n",
    "        return out.unsqueeze(-1).unsqueeze(-1), r, done, info        \n",
    "        \n",
    "    def use_model(self, x, r, a, cur_t, reset, term, done=False):\n",
    "        with torch.no_grad():\n",
    "            if cur_t == 0:\n",
    "                self.rollout_depth = 0.\n",
    "                self.unexpand_rollout_depth = 0.\n",
    "                self.pass_unexpand = False\n",
    "                self.max_rollout_depth = 0.\n",
    "                \n",
    "                if self.root_max_q is not None:\n",
    "                    self.thres = (self.root_max_q - r) / self.discounting\n",
    "                if done:\n",
    "                    self.thres = None\n",
    "                \n",
    "                if self.no_mem:\n",
    "                    re_action = 0\n",
    "                    re_reward = torch.tensor([0.], dtype=torch.float32)                \n",
    "                else:\n",
    "                    re_action = a                \n",
    "                    re_reward = torch.tensor([r], dtype=torch.float32)                \n",
    "                \n",
    "                x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "                self.x = self.x_ = x_tensor\n",
    "                a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions)                \n",
    "                _, vs, logits, encodeds = self.model(x_tensor, a_tensor.unsqueeze(0), one_hot=True) \n",
    "                \n",
    "                if self.perfect_model: \n",
    "                    encoded = self.clone_state()\n",
    "                else:\n",
    "                    encoded=encodeds[-1]\n",
    "                \n",
    "                if (not self.tree_carry or self.root_node is None or \n",
    "                    not self.root_node.children[a].expanded() or done):\n",
    "                \n",
    "                    self.root_node = Node(parent=None, action=re_action, logit=None, \n",
    "                                          num_actions=self.num_actions,\n",
    "                                          discounting=self.discounting,\n",
    "                                          rec_t=self.rec_t)\n",
    "                    self.root_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                          v=vs[-1, 0].unsqueeze(-1), logits=logits[-1, 0],\n",
    "                                          encoded=encoded)\n",
    "                else:\n",
    "                    self.root_node = self.root_node.children[a]\n",
    "                    self.root_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                          v=vs[-1, 0].unsqueeze(-1), logits=logits[-1, 0],\n",
    "                                          encoded=encoded, override=True)\n",
    "                    self.parent = None\n",
    "                \n",
    "                if self.thres is not None:\n",
    "                    self.thres = self.thres_discounting * self.thres + (1 - self.thres_discounting) * vs[-1, 0].item()\n",
    "                \n",
    "                self.root_node.visit()\n",
    "                self.cur_node = self.root_node\n",
    "                \n",
    "            else:\n",
    "                self.rollout_depth += 1                    \n",
    "                self.max_rollout_depth = max(self.max_rollout_depth, self.rollout_depth)\n",
    "                next_node = self.cur_node.children[a]\n",
    "                \n",
    "                if not next_node.expanded():\n",
    "                    self.pass_unexpand = True\n",
    "                    a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions) \n",
    "                    if not self.perfect_model:\n",
    "                        rs, vs, logits, encodeds = self.model.forward_encoded(self.cur_node.encoded, \n",
    "                            a_tensor.unsqueeze(0), one_hot=True)\n",
    "                        next_node.expand(r=rs[-1, 0].unsqueeze(-1), v=vs[-1, 0].unsqueeze(-1), \n",
    "                                     logits=logits[-1, 0], encoded=encodeds[-1])\n",
    "                    else:                        \n",
    "                        if \"done\" not in self.cur_node.encoded:                            \n",
    "                            self.env.restore_state(self.cur_node.encoded)                        \n",
    "                            x, r, done, info = self.env.step(a)                        \n",
    "                            encoded = self.env.clone_state()\n",
    "                            if done: encoded[\"done\"] = True                        \n",
    "                            x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "                            self.x_ = x_tensor\n",
    "                            a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions) \n",
    "                            _, vs, logits, _ = self.model(x_tensor, a_tensor.unsqueeze(0), one_hot=True)                        \n",
    "\n",
    "                            if done:\n",
    "                                v = torch.tensor([0.], dtype=torch.float32)\n",
    "                            else:\n",
    "                                v = vs[-1, 0].unsqueeze(-1)\n",
    "\n",
    "                            next_node.expand(r=torch.tensor([r], dtype=torch.float32), \n",
    "                                             v=v, \n",
    "                                             logits=logits[-1, 0], \n",
    "                                             encoded=encoded)\n",
    "                        else:\n",
    "                            logits = torch.concat([x.logit for x in self.cur_node.children])  \n",
    "                            next_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                             v=torch.tensor([0.], dtype=torch.float32),\n",
    "                                             logits=logits, \n",
    "                                             encoded=self.cur_node.encoded)                            \n",
    "                            \n",
    "                next_node.visit()\n",
    "                self.cur_node = next_node\n",
    "            \n",
    "            if self.pass_unexpand:                 \n",
    "                self.unexpand_rollout_depth += 1    \n",
    "                if self.reset_m >= 0 and self.unexpand_rollout_depth > self.reset_m:\n",
    "                    reset = True\n",
    "            \n",
    "            root_node_stat = self.root_node.stat(pos=self.pos)\n",
    "            cur_node_stat = self.cur_node.stat(pos=self.pos)                        \n",
    "            reset = torch.tensor([reset], dtype=torch.float32)            \n",
    "            depc = torch.tensor([self.discounting ** (self.rollout_depth-1)])\n",
    "            \n",
    "            root_trail_r = self.root_node.trail_r / self.discounting\n",
    "            root_rollout_q = self.root_node.rollout_q / self.discounting\n",
    "            if self.tree_vb != 0:\n",
    "                rollout_qs = [x + (self.tree_vb if n == 0 else 0.) for n, x in enumerate(self.root_node.rollout_qs)]\n",
    "            else:\n",
    "                rollout_qs = self.root_node.rollout_qs\n",
    "            root_max_q = torch.max(torch.concat(rollout_qs)).unsqueeze(-1) / self.discounting\n",
    "            if self.thres_carry and self.thres is not None:\n",
    "                root_max_q = torch.max(root_max_q, self.thres)\n",
    "                \n",
    "            if self.stat_pos_encode:\n",
    "                time = torch.concat([self.pos(torch.tensor([cur_t]).long()), self.pos(torch.tensor([self.rollout_depth]).long())], dim=-1)\n",
    "                time = time[0]\n",
    "            else:\n",
    "                if not self.flex_t:\n",
    "                    time = F.one_hot(torch.tensor(cur_t).long(), self.rec_t)\n",
    "                else:\n",
    "                    time = torch.tensor([self.discounting ** (self.cur_t)])                    \n",
    "                \n",
    "            if not self.flex_t:\n",
    "                ret_list = [root_node_stat, cur_node_stat, reset, time, depc, root_trail_r, root_rollout_q, root_max_q]\n",
    "            else:\n",
    "                term = torch.tensor([term], dtype=torch.float32)                            \n",
    "                ret_list = [root_node_stat, cur_node_stat, root_trail_r, root_rollout_q, root_max_q, reset, depc, term, time]\n",
    "                \n",
    "            out = torch.concat(ret_list, dim=-1)  \n",
    "            self.last_node = self.cur_node     \n",
    "            \n",
    "            self.root_max_q = root_max_q\n",
    "            self.ret_dict = {\"v0\": self.root_node.ret_dict[\"v\"].unsqueeze(0),\n",
    "                             \"q_s_a\": self.root_node.ret_dict[\"child_rollout_qs_mean\"].unsqueeze(0),\n",
    "                             \"max_q_s_a\": self.root_node.ret_dict[\"child_rollout_qs_max\"].unsqueeze(0),\n",
    "                             \"n_s_a\": self.root_node.child_rollout_ns.unsqueeze(0),\n",
    "                             \"logit0\": self.root_node.ret_dict[\"child_logits\"].unsqueeze(0),\n",
    "                             \"logit\": self.cur_node.ret_dict[\"child_logits\"].unsqueeze(0),\n",
    "                             \"reset\": reset,\n",
    "                             \"term\": term}\n",
    "            \n",
    "            if self.thres is not None:\n",
    "                self.ret_dict[\"thres\"] = self.thres\n",
    "            \n",
    "            if reset:\n",
    "                self.rollout_depth = 0\n",
    "                self.unexpand_rollout_depth = 0.\n",
    "                self.cur_node = self.root_node\n",
    "                self.cur_node.visit()\n",
    "                self.pass_unexpand = False\n",
    "                \n",
    "            return out\n",
    "                \n",
    "class Node:\n",
    "    def __init__(self, parent, action, logit, num_actions, discounting, rec_t):        \n",
    "        \n",
    "        self.action = F.one_hot(torch.tensor(action).long(), num_actions) # shape (1, num_actions)        \n",
    "        self.r = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.v = torch.tensor([0.], dtype=torch.float32)            \n",
    "        self.logit = logit # shape (1,)        \n",
    "        \n",
    "        self.rollout_qs = []  # list of tensors of shape (1,)\n",
    "        self.rollout_n = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.encoded = None \n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.discounting = discounting\n",
    "        self.rec_t = rec_t        \n",
    "        \n",
    "        self.visited = False\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def expand(self, r, v, logits, encoded, override=False):\n",
    "        \"\"\"\n",
    "        First time arriving a node and so we expand it\n",
    "        r, v: tensor of shape (1,)\n",
    "        logits: tensor of shape (num_actions,)\n",
    "        \"\"\"\n",
    "        if not override: assert not self.expanded()\n",
    "        if override:\n",
    "            self.rollout_qs = [x - self.r + r for x in self.rollout_qs]\n",
    "            self.rollout_qs[0] = v * self.discounting\n",
    "        self.r = r\n",
    "        self.v = v\n",
    "        self.encoded = encoded\n",
    "        for a in range(self.num_actions):\n",
    "            if not override:\n",
    "                child = self.children.append(Node(self, a, logits[[a]], \n",
    "                   self.num_actions, self.discounting, self.rec_t))\n",
    "            else:\n",
    "                self.children[a].logit = logits[[a]]        \n",
    "            \n",
    "    def visit(self):\n",
    "        self.trail_r = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.trail_discount = 1.\n",
    "        self.propagate(self.r, self.v, not self.visited)        \n",
    "        self.visited = True\n",
    "        \n",
    "    def propagate(self, r, v, new_rollout):\n",
    "        self.trail_r = self.trail_r + self.trail_discount * r\n",
    "        self.trail_discount = self.trail_discount * self.discounting\n",
    "        self.rollout_q = self.trail_r + self.trail_discount * v\n",
    "        if new_rollout:\n",
    "            self.rollout_qs.append(self.rollout_q)\n",
    "            self.rollout_n = self.rollout_n + 1\n",
    "        if self.parent is not None: self.parent.propagate(r, v, new_rollout)\n",
    "            \n",
    "    def stat(self, pos=None):\n",
    "        assert self.expanded()\n",
    "        self.child_logits = torch.concat([x.logit for x in self.children])        \n",
    "        child_rollout_qs_mean = []\n",
    "        child_rollout_qs_max = []\n",
    "        for x in self.children:\n",
    "            if len(x.rollout_qs) > 0:                \n",
    "                q_mean = torch.mean(torch.cat(x.rollout_qs), dim=-1, keepdim=True)\n",
    "                q_max = torch.max(torch.cat(x.rollout_qs), dim=-1, keepdim=True)[0]\n",
    "            else:\n",
    "                q_mean = torch.tensor([0.], dtype=torch.float32)    \n",
    "                q_max = torch.tensor([0.], dtype=torch.float32)    \n",
    "            child_rollout_qs_mean.append(q_mean)\n",
    "            child_rollout_qs_max.append(q_max)\n",
    "        self.child_rollout_qs_mean = torch.concat(child_rollout_qs_mean)\n",
    "        self.child_rollout_qs_max = torch.concat(child_rollout_qs_max)\n",
    "        \n",
    "        self.child_rollout_ns = torch.tensor([x.rollout_n for x in self.children]).long()\n",
    "        if pos is None:\n",
    "            self.child_rollout_ns_enc = self.child_rollout_ns / self.rec_t       \n",
    "        else:\n",
    "            self.child_rollout_ns_enc = torch.flatten(pos(self.child_rollout_ns))\n",
    "            \n",
    "        ret_list = [\"action\", \"r\", \"v\", \"child_logits\", \"child_rollout_qs_mean\",\n",
    "                    \"child_rollout_qs_max\", \"child_rollout_ns_enc\"]\n",
    "        self.ret_dict = {x: getattr(self, x) for x in ret_list}\n",
    "        out = torch.concat(list(self.ret_dict.values()))        \n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5f1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parser():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch Scalable Agent\")\n",
    "\n",
    "    parser.add_argument(\"--env\", type=str, default=\"Sokoban-v0\",\n",
    "                        help=\"Gym environment.\")\n",
    "    parser.add_argument(\"--env_disable_noop\", action=\"store_true\",\n",
    "                        help=\"Disable noop in environment or not. (sokoban only)\")\n",
    "\n",
    "    parser.add_argument(\"--xpid\", default=None,\n",
    "                        help=\"Experiment id (default: None).\")\n",
    "\n",
    "    parser.add_argument(\"--disable_checkpoint\", action=\"store_true\",\n",
    "                        help=\"Disable saving checkpoint.\")\n",
    "    parser.add_argument(\"--load_checkpoint\", default=\"\",\n",
    "                        help=\"Load checkpoint directory.\")    \n",
    "    parser.add_argument(\"--savedir\", default=\"~/RS/thinker/logs/torchbeast\",\n",
    "                        help=\"Root dir where experiment data will be saved.\")\n",
    "\n",
    "    # Training settings.        \n",
    "    parser.add_argument(\"--num_actors\", default=48, type=int, metavar=\"N\",\n",
    "                        help=\"Number of actors (default: 48).\")\n",
    "    parser.add_argument(\"--total_steps\", default=500000000, type=int, metavar=\"T\",\n",
    "                        help=\"Total environment steps to train for.\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, metavar=\"B\",\n",
    "                        help=\"Learner batch size.\")\n",
    "    parser.add_argument(\"--unroll_length\", default=100, type=int, metavar=\"T\",\n",
    "                        help=\"The unroll length (time dimension).\")\n",
    "    parser.add_argument(\"--num_buffers\", default=None, type=int,\n",
    "                        metavar=\"N\", help=\"Number of shared-memory buffers.\")\n",
    "    parser.add_argument(\"--num_learner_threads\", \"--num_threads\", default=1, type=int,\n",
    "                        metavar=\"N\", help=\"Number learner threads.\")\n",
    "    parser.add_argument(\"--disable_cuda\", action=\"store_true\",\n",
    "                        help=\"Disable CUDA.\")\n",
    "\n",
    "    # Architecture settings\n",
    "    parser.add_argument(\"--tran_dim\", default=64, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer hidden dim.\")\n",
    "    parser.add_argument(\"--tran_mem_n\", default=5, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer memory.\")\n",
    "    parser.add_argument(\"--tran_layer_n\", default=3, type=int, metavar=\"N\",\n",
    "                        help=\"Number of transformer layer.\")\n",
    "    parser.add_argument(\"--tran_t\", default=1, type=int, metavar=\"T\",\n",
    "                        help=\"Number of recurrent step for transformer.\")\n",
    "    parser.add_argument(\"--tran_ff_n\", default=256, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer ff .\")\n",
    "    parser.add_argument(\"--tran_skip\", action=\"store_true\",\n",
    "                        help=\"Whether to enable skip conn.\")\n",
    "    parser.add_argument(\"--tran_norm_first\", action=\"store_true\",\n",
    "                        help=\"Whether to use norm first in transformer.\")\n",
    "    parser.add_argument(\"--tran_rpos\", action=\"store_true\",\n",
    "                        help=\"Whether to use relative position in transformer.\")\n",
    "    parser.add_argument(\"--tran_lstm\", action=\"store_true\",\n",
    "                        help=\"Whether to use LSTM-transformer.\")\n",
    "    parser.add_argument(\"--tran_lstm_new\", action=\"store_true\",\n",
    "                        help=\"Whether to use a speed-up version of LSTM-transformer.\")    \n",
    "    parser.add_argument(\"--tran_lstm_no_attn\", action=\"store_true\",\n",
    "                        help=\"Whether to disable attention in LSTM-transformer.\")\n",
    "    parser.add_argument(\"--tran_attn_b\", default=5.,\n",
    "                        type=float, help=\"Bias attention for current position.\")    \n",
    "    parser.add_argument(\"--tran_erasep\", action=\"store_true\",\n",
    "                        help=\"Whether to erase past memories if not planning.\")\n",
    "    \n",
    "    \n",
    "    # Loss settings.\n",
    "    parser.add_argument(\"--entropy_cost\", default=0.0001,\n",
    "                        type=float, help=\"Entropy cost/multiplier.\")\n",
    "    parser.add_argument(\"--im_entropy_cost\", default=0.0001,\n",
    "                        type=float, help=\"Imagainary Entropy cost/multiplier.\")         \n",
    "    parser.add_argument(\"--baseline_cost\", default=0.5,\n",
    "                        type=float, help=\"Baseline cost/multiplier.\")\n",
    "    parser.add_argument(\"--reg_cost\", default=0.1,\n",
    "                        type=float, help=\"Reg cost/multiplier.\")\n",
    "    parser.add_argument(\"--real_cost\", default=1,\n",
    "                        type=float, help=\"Real reward - real action cost/multiplier.\")      \n",
    "    parser.add_argument(\"--real_im_cost\", default=1,\n",
    "                        type=float, help=\"Real reward - imagainary action cost/multiplier.\")          \n",
    "    parser.add_argument(\"--im_cost\", default=1,\n",
    "                        type=float, help=\"Imaginary reward cost/multiplier.\")   \n",
    "    parser.add_argument(\"--discounting\", default=0.99,\n",
    "                        type=float, help=\"Discounting factor.\")\n",
    "    parser.add_argument(\"--lamb\", default=1.,\n",
    "                        type=float, help=\"Lambda when computing trace.\")\n",
    "    parser.add_argument(\"--reward_clipping\", default=10, type=int, \n",
    "                        metavar=\"N\", help=\"Reward clipping.\")\n",
    "    parser.add_argument(\"--trun_bs\", action=\"store_true\",\n",
    "                        help=\"Whether to add baseline as reward when truncated.\")\n",
    "    \n",
    "    # Model settings\n",
    "    parser.add_argument(\"--reward_type\", default=1, type=int, metavar=\"N\",\n",
    "                        help=\"Reward type\")   \n",
    "    parser.add_argument(\"--reset_m\", default=-1, type=int, metavar=\"N\",\n",
    "                        help=\"Auto reset after passing m node since an unexpanded noded\")    \n",
    "    parser.add_argument(\"--model_type_nn\", default=0,\n",
    "                        type=float, help=\"Model type.\")     \n",
    "    parser.add_argument(\"--perfect_model\", action=\"store_true\",\n",
    "                        help=\"Whether to use perfect model.\")    \n",
    "    parser.add_argument(\"--stat_pos_encode\", action=\"store_true\",\n",
    "                        help=\"Whether to use positional encoding for integers\")       \n",
    "    parser.add_argument(\"--stat_pos_encode_dim\", default=32, type=int, metavar=\"N\",\n",
    "                        help=\"Dimension of positional encoding (only enabled when stat_pos_encode == True).\")        \n",
    "    parser.add_argument(\"--rec_t\", default=5, type=int, metavar=\"N\",\n",
    "                        help=\"Number of planning steps.\")\n",
    "    parser.add_argument(\"--flex_t\", action=\"store_true\",\n",
    "                        help=\"Whether to enable flexible planning steps.\") \n",
    "    parser.add_argument(\"--flex_t_cost\", default=-1e-5,\n",
    "                        type=float, help=\"Cost of planning step (only enabled when flex_t == True).\")\n",
    "    parser.add_argument(\"--flex_t_cost_m\", default=-1e-2,\n",
    "                        type=float, help=\"Multipler to exp. of planning cost (only enabled when flex_t_cost_type == 1).\")    \n",
    "    parser.add_argument(\"--flex_t_cost_type\", default=0,\n",
    "                        type=int, help=\"Type of planning cost; 0 for constant, 1 for exp. decay\")                    \n",
    "    parser.add_argument(\"--flex_t_term_b\", default=-5,\n",
    "                        type=float, help=\"Bias added to the logit of term action.\")      \n",
    "    parser.add_argument(\"--no_mem\", action=\"store_true\",\n",
    "                        help=\"Whether to erase all memories after each real action.\")   \n",
    "    parser.add_argument(\"--tree_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry over the tree.\")   \n",
    "    parser.add_argument(\"--tree_vb\", default=0., type=float,\n",
    "                        help=\"Adjustment to initial max-Q.\")    \n",
    "    parser.add_argument(\"--thres_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry threshold over.\")   \n",
    "    parser.add_argument(\"--reward_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry planning reward over.\")      \n",
    "    parser.add_argument(\"--thres_discounting\", default=0.99,\n",
    "                        type=float, help=\"Threshold discounting factor.\")    \n",
    "    \n",
    "\n",
    "    # Optimizer settings.\n",
    "    parser.add_argument(\"--learning_rate\", default=0.00005,\n",
    "                        type=float, metavar=\"LR\", help=\"Learning rate.\")\n",
    "    parser.add_argument(\"--disable_adam\", action=\"store_true\",\n",
    "                        help=\"Use Aadm optimizer or not.\")\n",
    "    parser.add_argument(\"--alpha\", default=0.99, type=float,\n",
    "                        help=\"RMSProp smoothing constant.\")\n",
    "    parser.add_argument(\"--momentum\", default=0, type=float,\n",
    "                        help=\"RMSProp momentum.\")\n",
    "    parser.add_argument(\"--epsilon\", default=0.01, type=float,\n",
    "                        help=\"RMSProp epsilon.\")\n",
    "    parser.add_argument(\"--grad_norm_clipping\", default=0.0, type=float,\n",
    "                        help=\"Global gradient norm clip.\")\n",
    "    # yapf: enable\n",
    "\n",
    "    return parser\n",
    "\n",
    "parser = define_parser()\n",
    "flags = parser.parse_args([])        \n",
    "\n",
    "flags.xpid = None\n",
    "flags.load_checkpoint = \"\"\n",
    "\n",
    "flags.env = \"Sokoban-v0\"\n",
    "flags.num_actors = 1\n",
    "flags.batch_size = 8\n",
    "flags.unroll_length = 50\n",
    "flags.learning_rate = 0.0001\n",
    "flags.grad_norm_clipping = 60\n",
    "\n",
    "flags.entropy_cost = 0.00001\n",
    "flags.im_entropy_cost = 0.00001\n",
    "flags.reg_cost = 0.01\n",
    "flags.real_cost = 1\n",
    "flags.real_im_cost = 1\n",
    "flags.im_cost = 1\n",
    "flags.discounting = 0.97\n",
    "flags.lamb = 1.\n",
    "\n",
    "flags.trun_bs = False\n",
    "flags.total_steps = 500000000\n",
    "flags.disable_adam = False\n",
    "\n",
    "flags.tran_t = 1\n",
    "flags.tran_mem_n = 5\n",
    "flags.tran_layer_n = 3\n",
    "flags.tran_lstm = True\n",
    "flags.tran_lstm_no_attn = False\n",
    "flags.tran_attn_b = 5\n",
    "flags.tran_norm_first = False\n",
    "flags.tran_ff_n = 256\n",
    "flags.tran_skip = False\n",
    "flags.tran_erasep = False\n",
    "flags.tran_dim = 64\n",
    "flags.tran_rpos = True\n",
    "\n",
    "flags.no_mem = True\n",
    "flags.rec_t = 10\n",
    "flags.model_type_nn = 0\n",
    "flags.perfect_model = True\n",
    "flags.reward_type = 1\n",
    "flags.stat_pos_encode = False\n",
    "flags.stat_pos_encode_dim = 32\n",
    "\n",
    "flags.reset_m = -1\n",
    "flags.tree_carry = True\n",
    "flags.thres_carry = True\n",
    "flags.reward_carry = False\n",
    "flags.thres_discounting = 0.97\n",
    "flags.flex_t = False\n",
    "flags.flex_t_cost = 1e-6\n",
    "flags.flex_t_cost_m = 1e-2\n",
    "flags.flex_t_cost_type = 0\n",
    "flags.flex_t_term_b = -3.\n",
    "\n",
    "flags.savedir = \"~/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04a968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating log directory: /home/schk/tmp/torchbeast-20221202-203848\n",
      "Creating log directory: /home/schk/tmp/torchbeast-20221202-203848\n",
      "Symlinked log directory: /home/schk/tmp/latest\n",
      "Symlinked log directory: /home/schk/tmp/latest\n",
      "Saving arguments to /home/schk/tmp/torchbeast-20221202-203848/meta.json\n",
      "Saving arguments to /home/schk/tmp/torchbeast-20221202-203848/meta.json\n",
      "Saving messages to /home/schk/tmp/torchbeast-20221202-203848/out.log\n",
      "Saving messages to /home/schk/tmp/torchbeast-20221202-203848/out.log\n",
      "Saving logs data to /home/schk/tmp/torchbeast-20221202-203848/logs.csv\n",
      "Saving logs data to /home/schk/tmp/torchbeast-20221202-203848/logs.csv\n",
      "Saving logs' fields to /home/schk/tmp/torchbeast-20221202-203848/fields.csv\n",
      "Saving logs' fields to /home/schk/tmp/torchbeast-20221202-203848/fields.csv\n",
      "Using CUDA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  298694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actor 0 started.\n",
      "# Step\tmean_episode_return\tepisode_returns\ttotal_loss\tpg_loss\tbaseline_loss\tentropy_loss\tmax_rollout_depth\tim_pg_loss\tim_baseline_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  298694\n",
      "Using Adam...\n",
      "All parameters: \n",
      "conv1.weight 2208\n",
      "conv1.bias 32\n",
      "conv2.weight 2048\n",
      "conv2.bias 64\n",
      "core.layers.0.pos_w 320\n",
      "core.layers.0.pos_b 40\n",
      "core.layers.0.main.weight 61440\n",
      "core.layers.0.main.bias 320\n",
      "core.layers.0.proj.weight 24576\n",
      "core.layers.0.proj.bias 192\n",
      "core.layers.0.out.weight 4096\n",
      "core.layers.0.out.bias 64\n",
      "core.layers.0.norm.weight 64\n",
      "core.layers.0.norm.bias 64\n",
      "core.layers.1.pos_w 320\n",
      "core.layers.1.pos_b 40\n",
      "core.layers.1.main.weight 61440\n",
      "core.layers.1.main.bias 320\n",
      "core.layers.1.proj.weight 24576\n",
      "core.layers.1.proj.bias 192\n",
      "core.layers.1.out.weight 4096\n",
      "core.layers.1.out.bias 64\n",
      "core.layers.1.norm.weight 64\n",
      "core.layers.1.norm.bias 64\n",
      "core.layers.2.pos_w 320\n",
      "core.layers.2.pos_b 40\n",
      "core.layers.2.main.weight 61440\n",
      "core.layers.2.main.bias 320\n",
      "core.layers.2.proj.weight 24576\n",
      "core.layers.2.proj.bias 192\n",
      "core.layers.2.out.weight 4096\n",
      "core.layers.2.out.bias 64\n",
      "core.layers.2.norm.weight 64\n",
      "core.layers.2.norm.bias 64\n",
      "core.proj_list.0.weight 128\n",
      "core.proj_list.0.bias 64\n",
      "core.proj_list.1.weight 128\n",
      "core.proj_list.1.bias 64\n",
      "core.proj_list.2.weight 128\n",
      "core.proj_list.2.bias 64\n",
      "fc.weight 16384\n",
      "fc.bias 256\n",
      "im_policy.weight 1280\n",
      "im_policy.bias 5\n",
      "policy.weight 1280\n",
      "policy.bias 5\n",
      "baseline.weight 512\n",
      "baseline.bias 2\n",
      "reset.weight 512\n",
      "reset.bias 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0 (0) @ 0.0 SPS. Eps 0. Return 0.000000 (0.000000). Loss inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-21.982611 im_pg_loss -31.898668 baseline_loss 0.097039 im_baseline_loss 0.626263 entropy_loss -0.024783\n",
      "tensor(-21.9826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-21.982611 im_pg_loss -31.898668 baseline_loss 0.097039 im_baseline_loss 0.626263 entropy_loss -0.024783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated log fields: ['_tick', '_time', 'step', 'real_step', 'mean_episode_return', 'episode_returns', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'max_rollout_depth', 'im_pg_loss', 'im_baseline_loss', 'rmean_im_episode_return', 'rmean_episode_return', 'episode']\n",
      "Updated log fields: ['_tick', '_time', 'step', 'real_step', 'mean_episode_return', 'episode_returns', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'max_rollout_depth', 'im_pg_loss', 'im_baseline_loss', 'rmean_im_episode_return', 'rmean_episode_return', 'episode']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-24.180264 im_pg_loss -25.612789 baseline_loss 5.909195 im_baseline_loss 0.127301 entropy_loss -0.024767\n",
      "tensor(-24.1803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-24.180264 im_pg_loss -25.612789 baseline_loss 5.909195 im_baseline_loss 0.127301 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 80 (800) @ 159.8 SPS. Eps 0. Return 0.000000 (0.008395). Loss -43.78 mean_plan_step 10.00 max_rollout_depth 4.00 pg_loss -24.18 baseline_loss 5.91 im_pg_loss -25.61 im_baseline_loss 0.13 entropy_loss -0.02 reg_loss 0.00 total_norm 25.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:8.089774 im_pg_loss -13.164391 baseline_loss 4.276623 im_baseline_loss 0.110272 entropy_loss -0.024779\n",
      "tensor(8.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:8.089774 im_pg_loss -13.164391 baseline_loss 4.276623 im_baseline_loss 0.110272 entropy_loss -0.024779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 120 (1200) @ 79.9 SPS. Eps 1. Return -0.159999 (0.008045). Loss -0.71 mean_plan_step 10.00 max_rollout_depth 4.22 pg_loss 8.09 baseline_loss 4.28 im_pg_loss -13.16 im_baseline_loss 0.11 entropy_loss -0.02 reg_loss 0.00 total_norm 15.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-39.564789 im_pg_loss -18.707390 baseline_loss 0.237152 im_baseline_loss 0.096955 entropy_loss -0.024794\n",
      "tensor(-39.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-39.564789 im_pg_loss -18.707390 baseline_loss 0.237152 im_baseline_loss 0.096955 entropy_loss -0.024794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 160 (1600) @ 79.9 SPS. Eps 1. Return -0.159999 (0.006034). Loss -57.96 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss -39.56 baseline_loss 0.24 im_pg_loss -18.71 im_baseline_loss 0.10 entropy_loss -0.02 reg_loss 0.00 total_norm 24.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-36.356842 im_pg_loss -12.672612 baseline_loss 0.198722 im_baseline_loss 0.081321 entropy_loss -0.024793\n",
      "tensor(-36.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-36.356842 im_pg_loss -12.672612 baseline_loss 0.198722 im_baseline_loss 0.081321 entropy_loss -0.024793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 200 (2000) @ 79.9 SPS. Eps 1. Return -0.159999 (0.004827). Loss -48.77 mean_plan_step 10.00 max_rollout_depth 4.03 pg_loss -36.36 baseline_loss 0.20 im_pg_loss -12.67 im_baseline_loss 0.08 entropy_loss -0.02 reg_loss 0.00 total_norm 21.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-18.037731 im_pg_loss 6.486179 baseline_loss 0.081633 im_baseline_loss 0.086180 entropy_loss -0.024783\n",
      "tensor(-18.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-18.037731 im_pg_loss 6.486179 baseline_loss 0.081633 im_baseline_loss 0.086180 entropy_loss -0.024783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 240 (2400) @ 79.9 SPS. Eps 2. Return -0.669999 (0.004542). Loss -11.41 mean_plan_step 10.00 max_rollout_depth 3.62 pg_loss -18.04 baseline_loss 0.08 im_pg_loss 6.49 im_baseline_loss 0.09 entropy_loss -0.02 reg_loss 0.00 total_norm 12.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-14.968333 im_pg_loss -3.692109 baseline_loss 0.061292 im_baseline_loss 0.054752 entropy_loss -0.024789\n",
      "tensor(-14.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-14.968333 im_pg_loss -3.692109 baseline_loss 0.061292 im_baseline_loss 0.054752 entropy_loss -0.024789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 280 (2800) @ 79.9 SPS. Eps 2. Return -0.669999 (0.004135). Loss -18.57 mean_plan_step 10.00 max_rollout_depth 4.07 pg_loss -14.97 baseline_loss 0.06 im_pg_loss -3.69 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 8.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:72.481026 im_pg_loss 4.582042 baseline_loss 8.048738 im_baseline_loss 0.071169 entropy_loss -0.024783\n",
      "tensor(72.4810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:72.481026 im_pg_loss 4.582042 baseline_loss 8.048739 im_baseline_loss 0.071169 entropy_loss -0.024783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 320 (3200) @ 79.9 SPS. Eps 2. Return -0.669999 (0.003618). Loss 85.16 mean_plan_step 10.00 max_rollout_depth 3.78 pg_loss 72.48 baseline_loss 8.05 im_pg_loss 4.58 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 42.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-2.610085 im_pg_loss 8.278430 baseline_loss 0.043121 im_baseline_loss 0.101010 entropy_loss -0.024785\n",
      "tensor(-2.6101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-2.610085 im_pg_loss 8.278430 baseline_loss 0.043121 im_baseline_loss 0.101010 entropy_loss -0.024785\n",
      "2 pg_loss:-7.970872 im_pg_loss 24.424850 baseline_loss 0.035184 im_baseline_loss 0.166641 entropy_loss -0.024763\n",
      "tensor(-7.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-7.970872 im_pg_loss 24.424850 baseline_loss 0.035184 im_baseline_loss 0.166641 entropy_loss -0.024763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 400 (4000) @ 159.8 SPS. Eps 3. Return -0.503333 (0.002913). Loss 16.63 mean_plan_step 10.00 max_rollout_depth 4.10 pg_loss -7.97 baseline_loss 0.04 im_pg_loss 24.42 im_baseline_loss 0.17 entropy_loss -0.02 reg_loss 0.00 total_norm 17.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:99.032043 im_pg_loss 20.614811 baseline_loss 10.381981 im_baseline_loss 0.133336 entropy_loss -0.024774\n",
      "tensor(99.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:99.032043 im_pg_loss 20.614811 baseline_loss 10.381981 im_baseline_loss 0.133336 entropy_loss -0.024774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 440 (4400) @ 79.9 SPS. Eps 3. Return -0.503333 (0.002746). Loss 130.14 mean_plan_step 10.00 max_rollout_depth 4.10 pg_loss 99.03 baseline_loss 10.38 im_pg_loss 20.61 im_baseline_loss 0.13 entropy_loss -0.02 reg_loss 0.00 total_norm 59.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.677096 im_pg_loss 9.160686 baseline_loss 0.057825 im_baseline_loss 0.072152 entropy_loss -0.024789\n",
      "tensor(-4.6771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.677096 im_pg_loss 9.160686 baseline_loss 0.057825 im_baseline_loss 0.072152 entropy_loss -0.024789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 480 (4800) @ 79.9 SPS. Eps 4. Return -0.424999 (0.002517). Loss 4.59 mean_plan_step 10.00 max_rollout_depth 3.65 pg_loss -4.68 baseline_loss 0.06 im_pg_loss 9.16 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 7.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:6.103445 im_pg_loss 4.019949 baseline_loss 2.266552 im_baseline_loss 0.065555 entropy_loss -0.024785\n",
      "tensor(6.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:6.103445 im_pg_loss 4.019949 baseline_loss 2.266552 im_baseline_loss 0.065555 entropy_loss -0.024785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 520 (5200) @ 79.9 SPS. Eps 4. Return -0.424999 (0.002608). Loss 12.43 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss 6.10 baseline_loss 2.27 im_pg_loss 4.02 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 8.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-90.112885 im_pg_loss -4.636760 baseline_loss 9.035608 im_baseline_loss 0.053979 entropy_loss -0.024786\n",
      "tensor(-90.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-90.112885 im_pg_loss -4.636760 baseline_loss 9.035608 im_baseline_loss 0.053979 entropy_loss -0.024786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 560 (5600) @ 79.9 SPS. Eps 4. Return -0.424999 (0.002421). Loss -85.68 mean_plan_step 10.00 max_rollout_depth 3.67 pg_loss -90.11 baseline_loss 9.04 im_pg_loss -4.64 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 49.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.899136 im_pg_loss -9.184273 baseline_loss 0.061954 im_baseline_loss 0.121447 entropy_loss -0.024793\n",
      "tensor(-4.8991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.899136 im_pg_loss -9.184273 baseline_loss 0.061954 im_baseline_loss 0.121447 entropy_loss -0.024793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 600 (6000) @ 79.9 SPS. Eps 5. Return -0.569999 (0.003021). Loss -13.92 mean_plan_step 10.00 max_rollout_depth 3.90 pg_loss -4.90 baseline_loss 0.06 im_pg_loss -9.18 im_baseline_loss 0.12 entropy_loss -0.02 reg_loss 0.00 total_norm 6.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:9.127005 im_pg_loss 1.938498 baseline_loss 0.045318 im_baseline_loss 0.027345 entropy_loss -0.024787\n",
      "tensor(9.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:9.127005 im_pg_loss 1.938498 baseline_loss 0.045318 im_baseline_loss 0.027345 entropy_loss -0.024787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 640 (6400) @ 79.9 SPS. Eps 5. Return -0.569999 (0.002832). Loss 11.11 mean_plan_step 10.00 max_rollout_depth 4.20 pg_loss 9.13 baseline_loss 0.05 im_pg_loss 1.94 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 6.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:10.302996 im_pg_loss -0.924278 baseline_loss 0.051312 im_baseline_loss 0.021040 entropy_loss -0.024788\n",
      "tensor(10.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:10.302996 im_pg_loss -0.924278 baseline_loss 0.051312 im_baseline_loss 0.021040 entropy_loss -0.024788\n",
      "2 pg_loss:0.550555 im_pg_loss 12.104568 baseline_loss 0.096155 im_baseline_loss 0.349094 entropy_loss -0.024788\n",
      "tensor(0.5506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:0.550555 im_pg_loss 12.104568 baseline_loss 0.096155 im_baseline_loss 0.349094 entropy_loss -0.024788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 720 (7200) @ 159.8 SPS. Eps 6. Return -0.666666 (0.003165). Loss 13.08 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss 0.55 baseline_loss 0.10 im_pg_loss 12.10 im_baseline_loss 0.35 entropy_loss -0.02 reg_loss 0.00 total_norm 9.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:63.848694 im_pg_loss -4.669424 baseline_loss 8.382017 im_baseline_loss 0.033434 entropy_loss -0.024771\n",
      "tensor(63.8487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:63.848694 im_pg_loss -4.669424 baseline_loss 8.382017 im_baseline_loss 0.033434 entropy_loss -0.024771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 760 (7600) @ 79.9 SPS. Eps 6. Return -0.666666 (0.002999). Loss 67.57 mean_plan_step 10.00 max_rollout_depth 3.80 pg_loss 63.85 baseline_loss 8.38 im_pg_loss -4.67 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 40.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.643395 im_pg_loss -1.061609 baseline_loss 0.045113 im_baseline_loss 0.026068 entropy_loss -0.024760\n",
      "tensor(-4.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.643395 im_pg_loss -1.061609 baseline_loss 0.045113 im_baseline_loss 0.026068 entropy_loss -0.024760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 800 (8000) @ 79.9 SPS. Eps 6. Return -0.666666 (0.002849). Loss -5.66 mean_plan_step 10.00 max_rollout_depth 3.58 pg_loss -4.64 baseline_loss 0.05 im_pg_loss -1.06 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 3.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-14.525692 im_pg_loss -2.776003 baseline_loss 0.103867 im_baseline_loss 0.048840 entropy_loss -0.024785\n",
      "tensor(-14.5257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-14.525692 im_pg_loss -2.776003 baseline_loss 0.103867 im_baseline_loss 0.048840 entropy_loss -0.024785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 840 (8400) @ 80.0 SPS. Eps 7. Return -0.598571 (0.003243). Loss -17.17 mean_plan_step 10.00 max_rollout_depth 4.03 pg_loss -14.53 baseline_loss 0.10 im_pg_loss -2.78 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 8.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-19.370605 im_pg_loss -8.113482 baseline_loss 0.073044 im_baseline_loss 0.027150 entropy_loss -0.024764\n",
      "tensor(-19.3706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-19.370605 im_pg_loss -8.113482 baseline_loss 0.073044 im_baseline_loss 0.027150 entropy_loss -0.024764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 880 (8800) @ 79.9 SPS. Eps 7. Return -0.598571 (0.003095). Loss -27.41 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss -19.37 baseline_loss 0.07 im_pg_loss -8.11 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 11.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-5.540283 im_pg_loss -14.289096 baseline_loss 2.311052 im_baseline_loss 0.049038 entropy_loss -0.024769\n",
      "tensor(-5.5403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-5.540283 im_pg_loss -14.289096 baseline_loss 2.311052 im_baseline_loss 0.049038 entropy_loss -0.024769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 920 (9200) @ 79.9 SPS. Eps 7. Return -0.598571 (0.002961). Loss -17.49 mean_plan_step 10.00 max_rollout_depth 3.95 pg_loss -5.54 baseline_loss 2.31 im_pg_loss -14.29 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 11.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-1.255434 im_pg_loss -15.095521 baseline_loss 15.685250 im_baseline_loss 0.060039 entropy_loss -0.024780\n",
      "tensor(-1.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-1.255434 im_pg_loss -15.095521 baseline_loss 15.685250 im_baseline_loss 0.060039 entropy_loss -0.024780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 960 (9600) @ 79.9 SPS. Eps 8. Return -0.669999 (0.002839). Loss -0.63 mean_plan_step 10.00 max_rollout_depth 3.95 pg_loss -1.26 baseline_loss 15.69 im_pg_loss -15.10 im_baseline_loss 0.06 entropy_loss -0.02 reg_loss 0.00 total_norm 30.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-18.384594 im_pg_loss -9.284371 baseline_loss 0.081013 im_baseline_loss 0.028721 entropy_loss -0.024801\n",
      "tensor(-18.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-18.384594 im_pg_loss -9.284371 baseline_loss 0.081013 im_baseline_loss 0.028721 entropy_loss -0.024801\n",
      "2 pg_loss:-59.301365 im_pg_loss -10.195182 baseline_loss 5.234189 im_baseline_loss 0.031454 entropy_loss -0.024781\n",
      "tensor(-59.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-59.301365 im_pg_loss -10.195182 baseline_loss 5.234189 im_baseline_loss 0.031454 entropy_loss -0.024781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1040 (10400) @ 159.8 SPS. Eps 8. Return -0.669999 (0.002621). Loss -64.26 mean_plan_step 10.00 max_rollout_depth 3.80 pg_loss -59.30 baseline_loss 5.23 im_pg_loss -10.20 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 34.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-12.764179 im_pg_loss -8.510126 baseline_loss 0.066302 im_baseline_loss 0.102130 entropy_loss -0.024774\n",
      "tensor(-12.7642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-12.764179 im_pg_loss -8.510126 baseline_loss 0.066302 im_baseline_loss 0.102130 entropy_loss -0.024774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1080 (10800) @ 79.9 SPS. Eps 9. Return -0.725555 (0.002883). Loss -21.13 mean_plan_step 10.00 max_rollout_depth 3.42 pg_loss -12.76 baseline_loss 0.07 im_pg_loss -8.51 im_baseline_loss 0.10 entropy_loss -0.02 reg_loss 0.00 total_norm 8.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:67.148209 im_pg_loss -9.959356 baseline_loss 8.246442 im_baseline_loss 0.029821 entropy_loss -0.024763\n",
      "tensor(67.1482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:67.148209 im_pg_loss -9.959356 baseline_loss 8.246442 im_baseline_loss 0.029821 entropy_loss -0.024763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1120 (11200) @ 80.0 SPS. Eps 9. Return -0.725555 (0.002780). Loss 65.44 mean_plan_step 10.00 max_rollout_depth 3.95 pg_loss 67.15 baseline_loss 8.25 im_pg_loss -9.96 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 42.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-117.889099 im_pg_loss -2.376122 baseline_loss 10.901627 im_baseline_loss 0.019571 entropy_loss -0.024761\n",
      "tensor(-117.8891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-117.889099 im_pg_loss -2.376122 baseline_loss 10.901627 im_baseline_loss 0.019571 entropy_loss -0.024761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1160 (11600) @ 79.9 SPS. Eps 9. Return -0.725555 (0.002684). Loss -109.37 mean_plan_step 10.00 max_rollout_depth 3.78 pg_loss -117.89 baseline_loss 10.90 im_pg_loss -2.38 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 64.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-11.589557 im_pg_loss -6.634480 baseline_loss 0.050756 im_baseline_loss 0.028310 entropy_loss -0.024761\n",
      "tensor(-11.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-11.589557 im_pg_loss -6.634480 baseline_loss 0.050756 im_baseline_loss 0.028310 entropy_loss -0.024761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1200 (12000) @ 79.9 SPS. Eps 10. Return -0.770999 (0.002619). Loss -18.17 mean_plan_step 10.00 max_rollout_depth 3.85 pg_loss -11.59 baseline_loss 0.05 im_pg_loss -6.63 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 7.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:17.762756 im_pg_loss -3.730259 baseline_loss 2.194816 im_baseline_loss 0.012801 entropy_loss -0.024776\n",
      "tensor(17.7628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:17.762756 im_pg_loss -3.730259 baseline_loss 2.194816 im_baseline_loss 0.012801 entropy_loss -0.024776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1240 (12400) @ 79.9 SPS. Eps 10. Return -0.770999 (0.002573). Loss 16.22 mean_plan_step 10.00 max_rollout_depth 3.97 pg_loss 17.76 baseline_loss 2.19 im_pg_loss -3.73 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 14.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:1.144075 im_pg_loss -2.407392 baseline_loss 0.036823 im_baseline_loss 0.008560 entropy_loss -0.024772\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:1.144075 im_pg_loss -2.407392 baseline_loss 0.036823 im_baseline_loss 0.008560 entropy_loss -0.024772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1280 (12800) @ 79.9 SPS. Eps 10. Return -0.770999 (0.002493). Loss -1.24 mean_plan_step 10.00 max_rollout_depth 4.30 pg_loss 1.14 baseline_loss 0.04 im_pg_loss -2.41 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 2.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-69.840607 im_pg_loss -0.199708 baseline_loss 15.109096 im_baseline_loss 0.045478 entropy_loss -0.024772\n",
      "tensor(-69.8406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-69.840607 im_pg_loss -0.199708 baseline_loss 15.109097 im_baseline_loss 0.045478 entropy_loss -0.024772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1320 (13200) @ 79.9 SPS. Eps 11. Return -0.807272 (0.002656). Loss -54.91 mean_plan_step 10.00 max_rollout_depth 3.50 pg_loss -69.84 baseline_loss 15.11 im_pg_loss -0.20 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 54.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-55.920940 im_pg_loss 5.688570 baseline_loss 14.335670 im_baseline_loss 0.018983 entropy_loss -0.024776\n",
      "tensor(-55.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-55.920940 im_pg_loss 5.688570 baseline_loss 14.335670 im_baseline_loss 0.018983 entropy_loss -0.024776\n",
      "2 pg_loss:46.215515 im_pg_loss 1.685118 baseline_loss 4.109548 im_baseline_loss 0.013623 entropy_loss -0.024772\n",
      "tensor(46.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:46.215515 im_pg_loss 1.685118 baseline_loss 4.109548 im_baseline_loss 0.013623 entropy_loss -0.024772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1400 (14000) @ 159.8 SPS. Eps 11. Return -0.807272 (0.002504). Loss 52.00 mean_plan_step 10.00 max_rollout_depth 3.53 pg_loss 46.22 baseline_loss 4.11 im_pg_loss 1.69 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 27.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:14.152977 im_pg_loss 0.478529 baseline_loss 0.139586 im_baseline_loss 0.124875 entropy_loss -0.024794\n",
      "tensor(14.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:14.152977 im_pg_loss 0.478529 baseline_loss 0.139586 im_baseline_loss 0.124875 entropy_loss -0.024794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1440 (14400) @ 79.9 SPS. Eps 12. Return -0.669999 (0.002698). Loss 14.87 mean_plan_step 10.00 max_rollout_depth 3.88 pg_loss 14.15 baseline_loss 0.14 im_pg_loss 0.48 im_baseline_loss 0.12 entropy_loss -0.02 reg_loss 0.00 total_norm 9.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:3.490449 im_pg_loss -6.214094 baseline_loss 0.051870 im_baseline_loss 0.015803 entropy_loss -0.024796\n",
      "tensor(3.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:3.490449 im_pg_loss -6.214094 baseline_loss 0.051870 im_baseline_loss 0.015803 entropy_loss -0.024796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1480 (14800) @ 79.9 SPS. Eps 12. Return -0.669999 (0.002625). Loss -2.68 mean_plan_step 10.00 max_rollout_depth 3.80 pg_loss 3.49 baseline_loss 0.05 im_pg_loss -6.21 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 4.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:1.784572 im_pg_loss -2.195604 baseline_loss 0.068022 im_baseline_loss 0.016059 entropy_loss -0.024796\n",
      "tensor(1.7846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:1.784572 im_pg_loss -2.195604 baseline_loss 0.068022 im_baseline_loss 0.016059 entropy_loss -0.024796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1520 (15200) @ 79.9 SPS. Eps 12. Return -0.669999 (0.002556). Loss -0.35 mean_plan_step 10.00 max_rollout_depth 3.90 pg_loss 1.78 baseline_loss 0.07 im_pg_loss -2.20 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 3.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-1.062934 im_pg_loss 2.146768 baseline_loss 0.044770 im_baseline_loss 0.019621 entropy_loss -0.024815\n",
      "tensor(-1.0629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-1.062934 im_pg_loss 2.146768 baseline_loss 0.044770 im_baseline_loss 0.019621 entropy_loss -0.024815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1560 (15600) @ 79.9 SPS. Eps 13. Return -0.708461 (0.002490). Loss 1.12 mean_plan_step 10.00 max_rollout_depth 3.85 pg_loss -1.06 baseline_loss 0.04 im_pg_loss 2.15 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 2.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-1.774154 im_pg_loss 0.068372 baseline_loss 0.033554 im_baseline_loss 0.017057 entropy_loss -0.024804\n",
      "tensor(-1.7742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-1.774154 im_pg_loss 0.068372 baseline_loss 0.033554 im_baseline_loss 0.017057 entropy_loss -0.024804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1600 (16000) @ 79.9 SPS. Eps 13. Return -0.708461 (0.002428). Loss -1.68 mean_plan_step 10.00 max_rollout_depth 4.15 pg_loss -1.77 baseline_loss 0.03 im_pg_loss 0.07 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 2.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:16.518961 im_pg_loss 2.346258 baseline_loss 2.341352 im_baseline_loss 0.021915 entropy_loss -0.024803\n",
      "tensor(16.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:16.518961 im_pg_loss 2.346258 baseline_loss 2.341352 im_baseline_loss 0.021915 entropy_loss -0.024803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1640 (16400) @ 79.9 SPS. Eps 14. Return -0.742142 (0.002416). Loss 21.20 mean_plan_step 10.00 max_rollout_depth 3.35 pg_loss 16.52 baseline_loss 2.34 im_pg_loss 2.35 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 18.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-97.929047 im_pg_loss 7.962993 baseline_loss 8.713795 im_baseline_loss 0.065534 entropy_loss -0.024803\n",
      "tensor(-97.9290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-97.929047 im_pg_loss 7.962993 baseline_loss 8.713795 im_baseline_loss 0.065534 entropy_loss -0.024803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1680 (16800) @ 79.9 SPS. Eps 14. Return -0.742142 (0.002550). Loss -81.21 mean_plan_step 10.00 max_rollout_depth 4.15 pg_loss -97.93 baseline_loss 8.71 im_pg_loss 7.96 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 58.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:3.557861 im_pg_loss 7.548687 baseline_loss 0.080521 im_baseline_loss 0.021276 entropy_loss -0.024776\n",
      "tensor(3.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:3.557861 im_pg_loss 7.548687 baseline_loss 0.080521 im_baseline_loss 0.021276 entropy_loss -0.024776\n",
      "2 pg_loss:2.693415 im_pg_loss 8.082220 baseline_loss 0.097306 im_baseline_loss 0.052516 entropy_loss -0.024782\n",
      "tensor(2.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:2.693415 im_pg_loss 8.082220 baseline_loss 0.097306 im_baseline_loss 0.052516 entropy_loss -0.024782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1760 (17600) @ 159.8 SPS. Eps 15. Return -0.769999 (0.002583). Loss 10.90 mean_plan_step 10.00 max_rollout_depth 3.60 pg_loss 2.69 baseline_loss 0.10 im_pg_loss 8.08 im_baseline_loss 0.05 entropy_loss -0.02 reg_loss 0.00 total_norm 6.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:45.593327 im_pg_loss 11.259272 baseline_loss 5.994359 im_baseline_loss 0.040462 entropy_loss -0.024786\n",
      "tensor(45.5933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:45.593327 im_pg_loss 11.259272 baseline_loss 5.994359 im_baseline_loss 0.040462 entropy_loss -0.024786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1800 (18000) @ 79.9 SPS. Eps 15. Return -0.769999 (0.002526). Loss 62.86 mean_plan_step 10.00 max_rollout_depth 3.58 pg_loss 45.59 baseline_loss 5.99 im_pg_loss 11.26 im_baseline_loss 0.04 entropy_loss -0.02 reg_loss 0.00 total_norm 29.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-13.051582 im_pg_loss 18.279793 baseline_loss 0.058893 im_baseline_loss 0.068399 entropy_loss -0.024794\n",
      "tensor(-13.0516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-13.051582 im_pg_loss 18.279793 baseline_loss 0.058893 im_baseline_loss 0.068399 entropy_loss -0.024794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1840 (18400) @ 79.9 SPS. Eps 15. Return -0.769999 (0.002471). Loss 5.33 mean_plan_step 10.00 max_rollout_depth 4.03 pg_loss -13.05 baseline_loss 0.06 im_pg_loss 18.28 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 13.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-34.708111 im_pg_loss 8.607809 baseline_loss 4.526460 im_baseline_loss 0.033796 entropy_loss -0.024792\n",
      "tensor(-34.7081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-34.708111 im_pg_loss 8.607809 baseline_loss 4.526460 im_baseline_loss 0.033796 entropy_loss -0.024792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1880 (18800) @ 79.9 SPS. Eps 16. Return -0.733124 (0.002422). Loss -21.56 mean_plan_step 10.00 max_rollout_depth 3.75 pg_loss -34.71 baseline_loss 4.53 im_pg_loss 8.61 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 24.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:18.203690 im_pg_loss -5.115251 baseline_loss 0.101588 im_baseline_loss 0.013861 entropy_loss -0.024807\n",
      "tensor(18.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:18.203690 im_pg_loss -5.115251 baseline_loss 0.101588 im_baseline_loss 0.013861 entropy_loss -0.024807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1920 (19200) @ 79.9 SPS. Eps 16. Return -0.733124 (0.002383). Loss 13.18 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss 18.20 baseline_loss 0.10 im_pg_loss -5.12 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 11.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:13.977148 im_pg_loss -9.273825 baseline_loss 0.079648 im_baseline_loss 0.019608 entropy_loss -0.024804\n",
      "tensor(13.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:13.977148 im_pg_loss -9.273825 baseline_loss 0.079648 im_baseline_loss 0.019608 entropy_loss -0.024804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 1960 (19600) @ 79.9 SPS. Eps 16. Return -0.733124 (0.002335). Loss 4.78 mean_plan_step 10.00 max_rollout_depth 4.10 pg_loss 13.98 baseline_loss 0.08 im_pg_loss -9.27 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 10.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:97.415024 im_pg_loss 3.063528 baseline_loss 8.766880 im_baseline_loss 0.139735 entropy_loss -0.024804\n",
      "tensor(97.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:97.415024 im_pg_loss 3.063528 baseline_loss 8.766879 im_baseline_loss 0.139735 entropy_loss -0.024804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2000 (20000) @ 79.9 SPS. Eps 17. Return -0.698823 (0.002613). Loss 109.36 mean_plan_step 10.00 max_rollout_depth 3.33 pg_loss 97.42 baseline_loss 8.77 im_pg_loss 3.06 im_baseline_loss 0.14 entropy_loss -0.02 reg_loss 0.00 total_norm 59.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:14.061212 im_pg_loss -6.193791 baseline_loss 0.089802 im_baseline_loss 0.013313 entropy_loss -0.024784\n",
      "tensor(14.0612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:14.061212 im_pg_loss -6.193791 baseline_loss 0.089802 im_baseline_loss 0.013313 entropy_loss -0.024784\n",
      "2 pg_loss:13.379150 im_pg_loss -4.314401 baseline_loss 0.082121 im_baseline_loss 0.013724 entropy_loss -0.024780\n",
      "tensor(13.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:13.379150 im_pg_loss -4.314401 baseline_loss 0.082121 im_baseline_loss 0.013724 entropy_loss -0.024780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2080 (20800) @ 159.8 SPS. Eps 17. Return -0.698823 (0.002512). Loss 9.14 mean_plan_step 10.00 max_rollout_depth 3.53 pg_loss 13.38 baseline_loss 0.08 im_pg_loss -4.31 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 9.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:92.125870 im_pg_loss -2.454682 baseline_loss 7.764694 im_baseline_loss 0.068580 entropy_loss -0.024789\n",
      "tensor(92.1259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:92.125870 im_pg_loss -2.454682 baseline_loss 7.764694 im_baseline_loss 0.068580 entropy_loss -0.024789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2120 (21200) @ 80.0 SPS. Eps 18. Return -0.726110 (0.002659). Loss 97.48 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss 92.13 baseline_loss 7.76 im_pg_loss -2.45 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 53.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:4.403358 im_pg_loss -5.814866 baseline_loss 0.047719 im_baseline_loss 0.015234 entropy_loss -0.024779\n",
      "tensor(4.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:4.403358 im_pg_loss -5.814866 baseline_loss 0.047719 im_baseline_loss 0.015234 entropy_loss -0.024779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2160 (21600) @ 79.9 SPS. Eps 18. Return -0.726110 (0.002610). Loss -1.37 mean_plan_step 10.00 max_rollout_depth 3.90 pg_loss 4.40 baseline_loss 0.05 im_pg_loss -5.81 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 4.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:1.213938 im_pg_loss -8.560818 baseline_loss 0.052319 im_baseline_loss 0.020027 entropy_loss -0.024763\n",
      "tensor(1.2139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:1.213938 im_pg_loss -8.560818 baseline_loss 0.052319 im_baseline_loss 0.020027 entropy_loss -0.024763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2200 (22000) @ 79.9 SPS. Eps 18. Return -0.726110 (0.002562). Loss -7.30 mean_plan_step 10.00 max_rollout_depth 3.70 pg_loss 1.21 baseline_loss 0.05 im_pg_loss -8.56 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 5.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-7.058952 im_pg_loss -2.120405 baseline_loss 16.857508 im_baseline_loss 0.069810 entropy_loss -0.024781\n",
      "tensor(-7.0590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-7.058952 im_pg_loss -2.120405 baseline_loss 16.857506 im_baseline_loss 0.069810 entropy_loss -0.024781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2240 (22400) @ 79.9 SPS. Eps 19. Return -0.697894 (0.002672). Loss 7.72 mean_plan_step 10.00 max_rollout_depth 3.65 pg_loss -7.06 baseline_loss 16.86 im_pg_loss -2.12 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 23.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-24.047043 im_pg_loss -4.176850 baseline_loss 0.129696 im_baseline_loss 0.012354 entropy_loss -0.024784\n",
      "tensor(-24.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-24.047043 im_pg_loss -4.176850 baseline_loss 0.129696 im_baseline_loss 0.012354 entropy_loss -0.024784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2280 (22800) @ 79.9 SPS. Eps 19. Return -0.697894 (0.002625). Loss -28.11 mean_plan_step 10.00 max_rollout_depth 3.65 pg_loss -24.05 baseline_loss 0.13 im_pg_loss -4.18 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 13.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:63.633888 im_pg_loss -2.000671 baseline_loss 6.151706 im_baseline_loss 0.011141 entropy_loss -0.024772\n",
      "tensor(63.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:63.633888 im_pg_loss -2.000671 baseline_loss 6.151706 im_baseline_loss 0.011141 entropy_loss -0.024772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2320 (23200) @ 79.9 SPS. Eps 19. Return -0.697894 (0.002580). Loss 67.77 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss 63.63 baseline_loss 6.15 im_pg_loss -2.00 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 35.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-7.440865 im_pg_loss -3.246544 baseline_loss 0.087091 im_baseline_loss 0.019896 entropy_loss -0.024790\n",
      "tensor(-7.4409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-7.440865 im_pg_loss -3.246544 baseline_loss 0.087091 im_baseline_loss 0.019896 entropy_loss -0.024790\n",
      "2 pg_loss:-28.098232 im_pg_loss -0.506751 baseline_loss 0.139144 im_baseline_loss 0.012474 entropy_loss -0.024816\n",
      "tensor(-28.0982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-28.098232 im_pg_loss -0.506751 baseline_loss 0.139144 im_baseline_loss 0.012474 entropy_loss -0.024816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2400 (24000) @ 159.8 SPS. Eps 20. Return -0.671499 (0.002587). Loss -28.48 mean_plan_step 10.00 max_rollout_depth 3.33 pg_loss -28.10 baseline_loss 0.14 im_pg_loss -0.51 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 17.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-24.627522 im_pg_loss -1.220058 baseline_loss 0.132879 im_baseline_loss 0.014987 entropy_loss -0.024812\n",
      "tensor(-24.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-24.627522 im_pg_loss -1.220058 baseline_loss 0.132879 im_baseline_loss 0.014987 entropy_loss -0.024812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2440 (24400) @ 79.9 SPS. Eps 20. Return -0.671499 (0.002545). Loss -25.72 mean_plan_step 10.00 max_rollout_depth 3.97 pg_loss -24.63 baseline_loss 0.13 im_pg_loss -1.22 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 14.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:6.341821 im_pg_loss 5.143303 baseline_loss 2.231728 im_baseline_loss 0.024643 entropy_loss -0.024819\n",
      "tensor(6.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:6.341821 im_pg_loss 5.143303 baseline_loss 2.231728 im_baseline_loss 0.024643 entropy_loss -0.024819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2480 (24800) @ 79.9 SPS. Eps 21. Return -0.694285 (0.002522). Loss 13.72 mean_plan_step 10.00 max_rollout_depth 3.88 pg_loss 6.34 baseline_loss 2.23 im_pg_loss 5.14 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 9.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.799827 im_pg_loss 2.858484 baseline_loss 0.042372 im_baseline_loss 0.067876 entropy_loss -0.024799\n",
      "tensor(-4.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.799827 im_pg_loss 2.858484 baseline_loss 0.042372 im_baseline_loss 0.067876 entropy_loss -0.024799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2520 (25200) @ 79.9 SPS. Eps 21. Return -0.694285 (0.002634). Loss -1.86 mean_plan_step 10.00 max_rollout_depth 3.65 pg_loss -4.80 baseline_loss 0.04 im_pg_loss 2.86 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 3.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-3.375173 im_pg_loss -1.050838 baseline_loss 0.053777 im_baseline_loss 0.007112 entropy_loss -0.024791\n",
      "tensor(-3.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-3.375173 im_pg_loss -1.050838 baseline_loss 0.053777 im_baseline_loss 0.007112 entropy_loss -0.024791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2560 (25600) @ 79.9 SPS. Eps 21. Return -0.694285 (0.002593). Loss -4.39 mean_plan_step 10.00 max_rollout_depth 3.53 pg_loss -3.38 baseline_loss 0.05 im_pg_loss -1.05 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 2.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:89.547081 im_pg_loss 3.305906 baseline_loss 13.946928 im_baseline_loss 0.094668 entropy_loss -0.024783\n",
      "tensor(89.5471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:89.547081 im_pg_loss 3.305906 baseline_loss 13.946927 im_baseline_loss 0.094668 entropy_loss -0.024783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2600 (26000) @ 79.9 SPS. Eps 22. Return -0.670454 (0.002699). Loss 106.87 mean_plan_step 10.00 max_rollout_depth 3.40 pg_loss 89.55 baseline_loss 13.95 im_pg_loss 3.31 im_baseline_loss 0.09 entropy_loss -0.02 reg_loss 0.00 total_norm 56.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-67.897957 im_pg_loss 3.693348 baseline_loss 6.488945 im_baseline_loss 0.009633 entropy_loss -0.024775\n",
      "tensor(-67.8980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-67.897957 im_pg_loss 3.693348 baseline_loss 6.488945 im_baseline_loss 0.009633 entropy_loss -0.024775\n",
      "2 pg_loss:-13.643190 im_pg_loss 2.889792 baseline_loss 0.052644 im_baseline_loss 0.010732 entropy_loss -0.024767\n",
      "tensor(-13.6432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-13.643190 im_pg_loss 2.889792 baseline_loss 0.052644 im_baseline_loss 0.010732 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2680 (26800) @ 159.8 SPS. Eps 22. Return -0.670454 (0.002619). Loss -10.71 mean_plan_step 10.00 max_rollout_depth 3.75 pg_loss -13.64 baseline_loss 0.05 im_pg_loss 2.89 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 8.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-39.079910 im_pg_loss 0.163488 baseline_loss 0.301913 im_baseline_loss 0.096090 entropy_loss -0.024781\n",
      "tensor(-39.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-39.079910 im_pg_loss 0.163488 baseline_loss 0.301913 im_baseline_loss 0.096090 entropy_loss -0.024781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2720 (27200) @ 79.9 SPS. Eps 23. Return -0.648260 (0.002784). Loss -38.54 mean_plan_step 10.00 max_rollout_depth 3.78 pg_loss -39.08 baseline_loss 0.30 im_pg_loss 0.16 im_baseline_loss 0.10 entropy_loss -0.02 reg_loss 0.00 total_norm 23.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-44.898285 im_pg_loss -10.218399 baseline_loss 0.332480 im_baseline_loss 0.021903 entropy_loss -0.024770\n",
      "tensor(-44.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-44.898285 im_pg_loss -10.218399 baseline_loss 0.332480 im_baseline_loss 0.021903 entropy_loss -0.024770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2760 (27600) @ 79.9 SPS. Eps 23. Return -0.648260 (0.002744). Loss -54.79 mean_plan_step 10.00 max_rollout_depth 3.58 pg_loss -44.90 baseline_loss 0.33 im_pg_loss -10.22 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 28.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-29.653702 im_pg_loss -3.536734 baseline_loss 0.166444 im_baseline_loss 0.010457 entropy_loss -0.024767\n",
      "tensor(-29.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-29.653702 im_pg_loss -3.536734 baseline_loss 0.166444 im_baseline_loss 0.010457 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2800 (28000) @ 79.9 SPS. Eps 23. Return -0.648260 (0.002704). Loss -33.04 mean_plan_step 10.00 max_rollout_depth 3.62 pg_loss -29.65 baseline_loss 0.17 im_pg_loss -3.54 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 18.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:16.753313 im_pg_loss -0.012151 baseline_loss 4.006506 im_baseline_loss 0.026371 entropy_loss -0.024792\n",
      "tensor(16.7533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:16.753313 im_pg_loss -0.012151 baseline_loss 4.006506 im_baseline_loss 0.026371 entropy_loss -0.024792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2840 (28400) @ 79.9 SPS. Eps 24. Return -0.670833 (0.002734). Loss 20.75 mean_plan_step 10.00 max_rollout_depth 3.85 pg_loss 16.75 baseline_loss 4.01 im_pg_loss -0.01 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 14.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-36.282837 im_pg_loss -1.030671 baseline_loss 2.730711 im_baseline_loss 0.008433 entropy_loss -0.024785\n",
      "tensor(-36.2828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-36.282837 im_pg_loss -1.030671 baseline_loss 2.730710 im_baseline_loss 0.008433 entropy_loss -0.024785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2880 (28800) @ 79.9 SPS. Eps 24. Return -0.670833 (0.002696). Loss -34.60 mean_plan_step 10.00 max_rollout_depth 3.80 pg_loss -36.28 baseline_loss 2.73 im_pg_loss -1.03 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 21.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-25.395542 im_pg_loss -5.426757 baseline_loss 0.131729 im_baseline_loss 0.010474 entropy_loss -0.024790\n",
      "tensor(-25.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-25.395542 im_pg_loss -5.426757 baseline_loss 0.131729 im_baseline_loss 0.010474 entropy_loss -0.024790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2920 (29200) @ 79.9 SPS. Eps 24. Return -0.670833 (0.002659). Loss -30.70 mean_plan_step 10.00 max_rollout_depth 3.85 pg_loss -25.40 baseline_loss 0.13 im_pg_loss -5.43 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 15.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-45.117210 im_pg_loss -5.589546 baseline_loss 0.379551 im_baseline_loss 0.087285 entropy_loss -0.024778\n",
      "tensor(-45.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-45.117210 im_pg_loss -5.589546 baseline_loss 0.379551 im_baseline_loss 0.087285 entropy_loss -0.024778\n",
      "2 pg_loss:49.339703 im_pg_loss -0.627087 baseline_loss 11.681783 im_baseline_loss 0.007333 entropy_loss -0.024767\n",
      "tensor(49.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:49.339703 im_pg_loss -0.627087 baseline_loss 11.681782 im_baseline_loss 0.007333 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 2960 (29600) @ 79.9 SPS. Eps 25. Return -0.690799 (0.002717). Loss -50.26 mean_plan_step 10.00 max_rollout_depth 3.62 pg_loss -45.12 baseline_loss 0.38 im_pg_loss -5.59 im_baseline_loss 0.09 entropy_loss -0.02 reg_loss 0.00 total_norm 27.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.825790 im_pg_loss -0.731172 baseline_loss 0.037454 im_baseline_loss 0.005491 entropy_loss -0.024770\n",
      "tensor(-4.8258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.825790 im_pg_loss -0.731172 baseline_loss 0.037454 im_baseline_loss 0.005491 entropy_loss -0.024770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3040 (30400) @ 159.8 SPS. Eps 25. Return -0.690799 (0.002646). Loss -5.54 mean_plan_step 10.00 max_rollout_depth 3.67 pg_loss -4.83 baseline_loss 0.04 im_pg_loss -0.73 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 2.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:159.160706 im_pg_loss 10.149606 baseline_loss 16.122147 im_baseline_loss 0.219024 entropy_loss -0.024774\n",
      "tensor(159.1607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:159.160706 im_pg_loss 10.149606 baseline_loss 16.122147 im_baseline_loss 0.219024 entropy_loss -0.024774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3080 (30800) @ 79.9 SPS. Eps 26. Return -0.709999 (0.002917). Loss 185.63 mean_plan_step 10.00 max_rollout_depth 3.97 pg_loss 159.16 baseline_loss 16.12 im_pg_loss 10.15 im_baseline_loss 0.22 entropy_loss -0.02 reg_loss 0.00 total_norm 93.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-33.054031 im_pg_loss 2.240372 baseline_loss 4.473700 im_baseline_loss 0.008082 entropy_loss -0.024784\n",
      "tensor(-33.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-33.054031 im_pg_loss 2.240372 baseline_loss 4.473700 im_baseline_loss 0.008082 entropy_loss -0.024784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3120 (31200) @ 79.9 SPS. Eps 26. Return -0.709999 (0.002879). Loss -26.36 mean_plan_step 10.00 max_rollout_depth 3.90 pg_loss -33.05 baseline_loss 4.47 im_pg_loss 2.24 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 19.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:1.283344 im_pg_loss 3.392208 baseline_loss 0.056115 im_baseline_loss 0.006818 entropy_loss -0.024772\n",
      "tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:1.283344 im_pg_loss 3.392208 baseline_loss 0.056115 im_baseline_loss 0.006818 entropy_loss -0.024772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3160 (31600) @ 79.9 SPS. Eps 26. Return -0.709999 (0.002843). Loss 4.71 mean_plan_step 10.00 max_rollout_depth 3.12 pg_loss 1.28 baseline_loss 0.06 im_pg_loss 3.39 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 3.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-7.505888 im_pg_loss -1.195600 baseline_loss 2.390423 im_baseline_loss 0.026930 entropy_loss -0.024770\n",
      "tensor(-7.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-7.505888 im_pg_loss -1.195600 baseline_loss 2.390423 im_baseline_loss 0.026930 entropy_loss -0.024770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3200 (32000) @ 79.9 SPS. Eps 27. Return -0.690740 (0.002875). Loss -6.31 mean_plan_step 10.00 max_rollout_depth 3.53 pg_loss -7.51 baseline_loss 2.39 im_pg_loss -1.20 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 11.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-153.786530 im_pg_loss -4.073963 baseline_loss 12.379488 im_baseline_loss 0.015520 entropy_loss -0.024779\n",
      "tensor(-153.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-153.786530 im_pg_loss -4.073963 baseline_loss 12.379489 im_baseline_loss 0.015520 entropy_loss -0.024779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3240 (32400) @ 79.9 SPS. Eps 27. Return -0.690740 (0.002840). Loss -145.49 mean_plan_step 10.00 max_rollout_depth 3.78 pg_loss -153.79 baseline_loss 12.38 im_pg_loss -4.07 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 93.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:40.320877 im_pg_loss 1.904043 baseline_loss 8.037468 im_baseline_loss 0.019488 entropy_loss -0.024785\n",
      "tensor(40.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:40.320877 im_pg_loss 1.904043 baseline_loss 8.037468 im_baseline_loss 0.019488 entropy_loss -0.024785\n",
      "2 pg_loss:11.321393 im_pg_loss -0.422599 baseline_loss 0.080021 im_baseline_loss 0.006620 entropy_loss -0.024782\n",
      "tensor(11.3214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:11.321393 im_pg_loss -0.422599 baseline_loss 0.080021 im_baseline_loss 0.006620 entropy_loss -0.024782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3320 (33200) @ 159.8 SPS. Eps 28. Return -0.672142 (0.002771). Loss 10.96 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss 11.32 baseline_loss 0.08 im_pg_loss -0.42 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 7.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.415282 im_pg_loss -1.282079 baseline_loss 0.053710 im_baseline_loss 0.006155 entropy_loss -0.024765\n",
      "tensor(-4.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.415282 im_pg_loss -1.282079 baseline_loss 0.053710 im_baseline_loss 0.006155 entropy_loss -0.024765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3360 (33600) @ 79.9 SPS. Eps 28. Return -0.672142 (0.002738). Loss -5.66 mean_plan_step 10.00 max_rollout_depth 3.83 pg_loss -4.42 baseline_loss 0.05 im_pg_loss -1.28 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 3.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:6.697137 im_pg_loss 1.399448 baseline_loss 0.061985 im_baseline_loss 0.025476 entropy_loss -0.024767\n",
      "tensor(6.6971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:6.697137 im_pg_loss 1.399448 baseline_loss 0.061985 im_baseline_loss 0.025476 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3400 (34000) @ 79.9 SPS. Eps 29. Return -0.688965 (0.002769). Loss 8.16 mean_plan_step 10.00 max_rollout_depth 3.95 pg_loss 6.70 baseline_loss 0.06 im_pg_loss 1.40 im_baseline_loss 0.03 entropy_loss -0.02 reg_loss 0.00 total_norm 5.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-40.772747 im_pg_loss -7.784234 baseline_loss 0.291686 im_baseline_loss 0.017886 entropy_loss -0.024767\n",
      "tensor(-40.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-40.772747 im_pg_loss -7.784234 baseline_loss 0.291686 im_baseline_loss 0.017886 entropy_loss -0.024767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3440 (34400) @ 79.9 SPS. Eps 29. Return -0.688965 (0.002737). Loss -48.27 mean_plan_step 10.00 max_rollout_depth 3.60 pg_loss -40.77 baseline_loss 0.29 im_pg_loss -7.78 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 24.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-62.390518 im_pg_loss -3.729934 baseline_loss 8.773433 im_baseline_loss 0.009259 entropy_loss -0.024773\n",
      "tensor(-62.3905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-62.390518 im_pg_loss -3.729934 baseline_loss 8.773433 im_baseline_loss 0.009259 entropy_loss -0.024773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3480 (34800) @ 79.9 SPS. Eps 29. Return -0.688965 (0.002705). Loss -57.36 mean_plan_step 10.00 max_rollout_depth 3.65 pg_loss -62.39 baseline_loss 8.77 im_pg_loss -3.73 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 40.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-8.933637 im_pg_loss 0.205594 baseline_loss 0.094317 im_baseline_loss 0.072425 entropy_loss -0.024768\n",
      "tensor(-8.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-8.933637 im_pg_loss 0.205594 baseline_loss 0.094317 im_baseline_loss 0.072425 entropy_loss -0.024768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3520 (35200) @ 79.9 SPS. Eps 30. Return -0.705333 (0.002779). Loss -8.59 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss -8.93 baseline_loss 0.09 im_pg_loss 0.21 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 5.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-12.993177 im_pg_loss -7.888983 baseline_loss 0.112645 im_baseline_loss 0.016365 entropy_loss -0.024785\n",
      "tensor(-12.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-12.993177 im_pg_loss -7.888983 baseline_loss 0.112645 im_baseline_loss 0.016365 entropy_loss -0.024785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3560 (35600) @ 79.9 SPS. Eps 30. Return -0.705333 (0.002748). Loss -20.78 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss -12.99 baseline_loss 0.11 im_pg_loss -7.89 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 9.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-29.567379 im_pg_loss -5.502733 baseline_loss 0.164785 im_baseline_loss 0.010074 entropy_loss -0.024775\n",
      "tensor(-29.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-29.567379 im_pg_loss -5.502733 baseline_loss 0.164785 im_baseline_loss 0.010074 entropy_loss -0.024775\n",
      "2 pg_loss:-11.011219 im_pg_loss -5.190502 baseline_loss 0.157740 im_baseline_loss 0.016212 entropy_loss -0.024776\n",
      "tensor(-11.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-11.011219 im_pg_loss -5.190502 baseline_loss 0.157740 im_baseline_loss 0.016212 entropy_loss -0.024776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3640 (36400) @ 159.8 SPS. Eps 31. Return -0.720644 (0.002705). Loss -16.05 mean_plan_step 10.00 max_rollout_depth 3.62 pg_loss -11.01 baseline_loss 0.16 im_pg_loss -5.19 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 7.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:89.000069 im_pg_loss -3.225622 baseline_loss 8.803403 im_baseline_loss 0.098891 entropy_loss -0.024774\n",
      "tensor(89.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:89.000069 im_pg_loss -3.225622 baseline_loss 8.803403 im_baseline_loss 0.098891 entropy_loss -0.024774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3680 (36800) @ 79.9 SPS. Eps 31. Return -0.720644 (0.002867). Loss 94.65 mean_plan_step 10.00 max_rollout_depth 3.78 pg_loss 89.00 baseline_loss 8.80 im_pg_loss -3.23 im_baseline_loss 0.10 entropy_loss -0.02 reg_loss 0.00 total_norm 53.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:16.967949 im_pg_loss -0.767006 baseline_loss 2.465342 im_baseline_loss 0.010765 entropy_loss -0.024776\n",
      "tensor(16.9679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:16.967949 im_pg_loss -0.767006 baseline_loss 2.465342 im_baseline_loss 0.010765 entropy_loss -0.024776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3720 (37200) @ 79.9 SPS. Eps 31. Return -0.720644 (0.002837). Loss 18.65 mean_plan_step 10.00 max_rollout_depth 3.72 pg_loss 16.97 baseline_loss 2.47 im_pg_loss -0.77 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 13.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-26.096836 im_pg_loss 0.292316 baseline_loss 2.553777 im_baseline_loss 0.005778 entropy_loss -0.024766\n",
      "tensor(-26.0968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-26.096836 im_pg_loss 0.292316 baseline_loss 2.553777 im_baseline_loss 0.005778 entropy_loss -0.024766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3760 (37600) @ 79.9 SPS. Eps 32. Return -0.703124 (0.002809). Loss -23.27 mean_plan_step 10.00 max_rollout_depth 3.92 pg_loss -26.10 baseline_loss 2.55 im_pg_loss 0.29 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 17.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-21.605978 im_pg_loss -2.526488 baseline_loss 0.140227 im_baseline_loss 0.006989 entropy_loss -0.024763\n",
      "tensor(-21.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-21.605978 im_pg_loss -2.526488 baseline_loss 0.140227 im_baseline_loss 0.006989 entropy_loss -0.024763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3800 (38000) @ 79.9 SPS. Eps 32. Return -0.703124 (0.002779). Loss -24.01 mean_plan_step 10.00 max_rollout_depth 3.95 pg_loss -21.61 baseline_loss 0.14 im_pg_loss -2.53 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 13.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-13.167460 im_pg_loss 1.469245 baseline_loss 2.410500 im_baseline_loss 0.015031 entropy_loss -0.024785\n",
      "tensor(-13.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-13.167460 im_pg_loss 1.469245 baseline_loss 2.410501 im_baseline_loss 0.015031 entropy_loss -0.024785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3840 (38400) @ 79.9 SPS. Eps 32. Return -0.703124 (0.002750). Loss -9.30 mean_plan_step 10.00 max_rollout_depth 3.80 pg_loss -13.17 baseline_loss 2.41 im_pg_loss 1.47 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 11.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-4.573384 im_pg_loss 2.155107 baseline_loss 11.918609 im_baseline_loss 0.012276 entropy_loss -0.024778\n",
      "tensor(-4.5734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-4.573384 im_pg_loss 2.155107 baseline_loss 11.918609 im_baseline_loss 0.012276 entropy_loss -0.024778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3880 (38800) @ 79.9 SPS. Eps 33. Return -0.717272 (0.002722). Loss 9.49 mean_plan_step 10.00 max_rollout_depth 3.75 pg_loss -4.57 baseline_loss 11.92 im_pg_loss 2.16 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 25.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:22.524019 im_pg_loss 6.050477 baseline_loss 0.162827 im_baseline_loss 0.012023 entropy_loss -0.024778\n",
      "tensor(22.5240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:22.524019 im_pg_loss 6.050477 baseline_loss 0.162827 im_baseline_loss 0.012023 entropy_loss -0.024778\n",
      "2 pg_loss:31.389118 im_pg_loss 7.856558 baseline_loss 0.195708 im_baseline_loss 0.012852 entropy_loss -0.024783\n",
      "tensor(31.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:31.389118 im_pg_loss 7.856558 baseline_loss 0.195708 im_baseline_loss 0.012852 entropy_loss -0.024783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 3960 (39600) @ 159.8 SPS. Eps 33. Return -0.717272 (0.002667). Loss 39.43 mean_plan_step 10.00 max_rollout_depth 3.35 pg_loss 31.39 baseline_loss 0.20 im_pg_loss 7.86 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 20.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:17.297112 im_pg_loss 8.055494 baseline_loss 0.243483 im_baseline_loss 0.066542 entropy_loss -0.024778\n",
      "tensor(17.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:17.297112 im_pg_loss 8.055494 baseline_loss 0.243483 im_baseline_loss 0.066542 entropy_loss -0.024778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4000 (40000) @ 79.9 SPS. Eps 34. Return -0.730293 (0.002732). Loss 25.64 mean_plan_step 10.00 max_rollout_depth 3.97 pg_loss 17.30 baseline_loss 0.24 im_pg_loss 8.06 im_baseline_loss 0.07 entropy_loss -0.02 reg_loss 0.00 total_norm 12.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:14.100916 im_pg_loss 2.329252 baseline_loss 0.067329 im_baseline_loss 0.003221 entropy_loss -0.024781\n",
      "tensor(14.1009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:14.100916 im_pg_loss 2.329252 baseline_loss 0.067329 im_baseline_loss 0.003221 entropy_loss -0.024781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4040 (40400) @ 79.9 SPS. Eps 34. Return -0.730293 (0.002705). Loss 16.48 mean_plan_step 10.00 max_rollout_depth 3.67 pg_loss 14.10 baseline_loss 0.07 im_pg_loss 2.33 im_baseline_loss 0.00 entropy_loss -0.02 reg_loss 0.00 total_norm 9.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:7.768983 im_pg_loss -0.368975 baseline_loss 0.042855 im_baseline_loss 0.003698 entropy_loss -0.024778\n",
      "tensor(7.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:7.768983 im_pg_loss -0.368975 baseline_loss 0.042855 im_baseline_loss 0.003698 entropy_loss -0.024778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4080 (40800) @ 79.9 SPS. Eps 34. Return -0.730293 (0.002679). Loss 7.42 mean_plan_step 10.00 max_rollout_depth 3.30 pg_loss 7.77 baseline_loss 0.04 im_pg_loss -0.37 im_baseline_loss 0.00 entropy_loss -0.02 reg_loss 0.00 total_norm 5.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-14.638808 im_pg_loss -5.319129 baseline_loss 0.145785 im_baseline_loss 0.013662 entropy_loss -0.024764\n",
      "tensor(-14.6388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-14.638808 im_pg_loss -5.319129 baseline_loss 0.145785 im_baseline_loss 0.013662 entropy_loss -0.024764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4120 (41200) @ 79.9 SPS. Eps 35. Return -0.742857 (0.002653). Loss -19.82 mean_plan_step 10.00 max_rollout_depth 3.58 pg_loss -14.64 baseline_loss 0.15 im_pg_loss -5.32 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-23.414810 im_pg_loss 0.308468 baseline_loss 0.125105 im_baseline_loss 0.021530 entropy_loss -0.024784\n",
      "tensor(-23.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-23.414810 im_pg_loss 0.308468 baseline_loss 0.125105 im_baseline_loss 0.021530 entropy_loss -0.024784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4160 (41600) @ 79.9 SPS. Eps 35. Return -0.742857 (0.002627). Loss -22.98 mean_plan_step 10.00 max_rollout_depth 3.90 pg_loss -23.41 baseline_loss 0.13 im_pg_loss 0.31 im_baseline_loss 0.02 entropy_loss -0.02 reg_loss 0.00 total_norm 13.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-25.172646 im_pg_loss 0.934127 baseline_loss 0.125473 im_baseline_loss 0.007543 entropy_loss -0.024766\n",
      "tensor(-25.1726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-25.172646 im_pg_loss 0.934127 baseline_loss 0.125473 im_baseline_loss 0.007543 entropy_loss -0.024766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4200 (42000) @ 79.9 SPS. Eps 35. Return -0.742857 (0.002602). Loss -24.13 mean_plan_step 10.00 max_rollout_depth 3.83 pg_loss -25.17 baseline_loss 0.13 im_pg_loss 0.93 im_baseline_loss 0.01 entropy_loss -0.02 reg_loss 0.00 total_norm 14.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pg_loss:-0.948712 im_pg_loss 4.626505 baseline_loss 0.079813 im_baseline_loss 0.120086 entropy_loss -0.024768\n",
      "tensor(-0.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-0.948712 im_pg_loss 4.626505 baseline_loss 0.079813 im_baseline_loss 0.120086 entropy_loss -0.024768\n",
      "2 pg_loss:-14.719625 im_pg_loss -2.777133 baseline_loss 0.060831 im_baseline_loss 0.006774 entropy_loss -0.024771\n",
      "tensor(-14.7196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1 pg_loss:-14.719625 im_pg_loss -2.777133 baseline_loss 0.060831 im_baseline_loss 0.006774 entropy_loss -0.024771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 4240 (42400) @ 79.9 SPS. Eps 36. Return -0.754166 (0.002659). Loss 3.85 mean_plan_step 10.00 max_rollout_depth 4.12 pg_loss -0.95 baseline_loss 0.08 im_pg_loss 4.63 im_baseline_loss 0.12 entropy_loss -0.02 reg_loss 0.00 total_norm 4.24\n"
     ]
    }
   ],
   "source": [
    "if flags.reward_type == 0:\n",
    "    flags.num_rewards = num_rewards = 1\n",
    "else:\n",
    "    flags.num_rewards = num_rewards = 2\n",
    "flags.im_discounting = flags.discounting ** (1/flags.rec_t)    \n",
    "    \n",
    "raw_env = SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "\n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])    \n",
    "\n",
    "env = Environment(ModelWrapper(SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop), \n",
    "     model=model, flags=flags))\n",
    "obs_shape = env.gym_env.observation_space.shape\n",
    "\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "if flags.load_checkpoint:\n",
    "    flags.savedir = os.path.split(os.path.split(flags.load_checkpoint)[0])[0]\n",
    "    flags.xpid = os.path.split(os.path.split(flags.load_checkpoint)[0])[-1]    \n",
    "else:\n",
    "    if flags.xpid is None:\n",
    "        flags.xpid = \"torchbeast-%s\" % time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "flags.git_revision = get_git_revision_hash()\n",
    "\n",
    "plogger = file_writer.FileWriter(\n",
    "    xpid=flags.xpid, xp_args=flags.__dict__, rootdir=flags.savedir\n",
    ")\n",
    "\n",
    "flags.device = None\n",
    "if not flags.disable_cuda and torch.cuda.is_available():\n",
    "    logging.info(\"Using CUDA.\")\n",
    "    flags.device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logging.info(\"Not using CUDA.\")\n",
    "    flags.device = torch.device(\"cpu\")\n",
    "\n",
    "checkpointpath = os.path.expandvars(\n",
    "    os.path.expanduser(\"%s/%s/%s\" % (flags.savedir, flags.xpid, \"model.tar\"))\n",
    ")\n",
    "\n",
    "if flags.num_buffers is None:  # Set sensible default for num_buffers.\n",
    "    flags.num_buffers = max(2 * flags.num_actors, flags.batch_size)\n",
    "if flags.num_actors >= flags.num_buffers:\n",
    "    raise ValueError(\"num_buffers should be larger than num_actors\")\n",
    "if flags.num_buffers < flags.batch_size:\n",
    "    raise ValueError(\"num_buffers should be larger than batch_size\")\n",
    "\n",
    "T = flags.unroll_length\n",
    "B = flags.batch_size\n",
    "\n",
    "actor_net = Actor_net(obs_shape, num_actions, flags)\n",
    "buffers = create_buffers(flags, obs_shape, num_actions, num_rewards)\n",
    "\n",
    "if flags.load_checkpoint:\n",
    "    train_checkpoint = torch.load(flags.load_checkpoint)\n",
    "    actor_net.load_state_dict(train_checkpoint[\"model_state_dict\"])  \n",
    "\n",
    "actor_net.share_memory()\n",
    "\n",
    "# Add initial RNN state.\n",
    "initial_agent_state_buffers = []\n",
    "for _ in range(flags.num_buffers):\n",
    "    state = actor_net.initial_state(batch_size=1)\n",
    "    for t in state:\n",
    "        t.share_memory_()\n",
    "    initial_agent_state_buffers.append(state)\n",
    "\n",
    "actor_processes = []\n",
    "ctx = mp.get_context()\n",
    "free_queue = ctx.SimpleQueue()\n",
    "full_queue = ctx.SimpleQueue()\n",
    "\n",
    "for i in range(flags.num_actors):\n",
    "    actor = ctx.Process(target=act, args=(flags, i, free_queue, full_queue,\n",
    "            actor_net, model, buffers, initial_agent_state_buffers,),)\n",
    "    actor.start()\n",
    "    actor_processes.append(actor)\n",
    "\n",
    "learner_net = Actor_net(obs_shape, num_actions, flags)\n",
    "if flags.load_checkpoint:\n",
    "    learner_net.load_state_dict(train_checkpoint[\"model_state_dict\"])\n",
    "#learner_net= DataParallelWrapper(nn.DataParallel(learner_net))   # commented out if no need multi-gpu\n",
    "learner_net = learner_net.to(device=flags.device)  \n",
    "\n",
    "if not flags.disable_adam:\n",
    "    print(\"Using Adam...\")        \n",
    "    optimizer = torch.optim.Adam(learner_net.parameters(),lr=flags.learning_rate)\n",
    "else:\n",
    "    print(\"Using RMS Prop...\")\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        learner_net.actor.parameters(),\n",
    "        lr=flags.learning_rate,\n",
    "        momentum=flags.momentum,\n",
    "        eps=flags.epsilon,\n",
    "        alpha=flags.alpha,)\n",
    "    \n",
    "if flags.load_checkpoint:\n",
    "    optimizer.load_state_dict(train_checkpoint[\"optimizer_state_dict\"])    \n",
    "    \n",
    "print(\"All parameters: \")\n",
    "for k, v in learner_net.named_parameters(): print(k, v.numel())    \n",
    "\n",
    "if not flags.flex_t:\n",
    "    lr_lambda = lambda epoch: 1 - min(epoch * T * B, flags.total_steps * flags.rec_t) / (flags.total_steps * flags.rec_t)\n",
    "else:\n",
    "    lr_lambda = lambda epoch: 1 - min(epoch, flags.total_steps) / flags.total_steps\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "if flags.load_checkpoint:\n",
    "    scheduler.load_state_dict(train_checkpoint[\"scheduler_state_dict\"])\n",
    "    \n",
    "logger = logging.getLogger(\"logfile\")\n",
    "stat_keys = [\"mean_episode_return\", \"episode_returns\", \"total_loss\",\n",
    "    \"pg_loss\", \"baseline_loss\", \"entropy_loss\", \"max_rollout_depth\"]\n",
    "if flags.reward_type == 1:\n",
    "    stat_keys.extend([\"im_pg_loss\", \"im_baseline_loss\"])\n",
    "\n",
    "logger.info(\"# Step\\t%s\", \"\\t\".join(stat_keys))\n",
    "\n",
    "step, real_step, stats, last_returns, last_im_returns, tot_eps = 0, 0, {}, deque(maxlen=400), deque(maxlen=40000), 0\n",
    "if flags.load_checkpoint:\n",
    "    if \"step\" in train_checkpoint.keys():    \n",
    "        step = train_checkpoint[\"step\"]\n",
    "        real_step = train_checkpoint[\"real_step\"]\n",
    "    else:\n",
    "        # legacy support\n",
    "        step = train_checkpoint[\"scheduler_state_dict\"][\"_step_count\"] * T * B\n",
    "    \n",
    "def batch_and_learn(i, lock=threading.Lock()):\n",
    "    \"\"\"Thread target for the learning process.\"\"\"\n",
    "    #nonlocal step, stats, last_returns, tot_eps\n",
    "    global step, real_step, stats, last_returns, last_im_returns, tot_eps\n",
    "    timings = prof.Timings()\n",
    "    #while step < flags.total_steps:\n",
    "    while real_step < flags.total_steps:\n",
    "        timings.reset()\n",
    "        batch, agent_state = get_batch(flags, free_queue, full_queue, buffers,\n",
    "            initial_agent_state_buffers, timings,)\n",
    "        stats = learn(flags, actor_net, learner_net, batch, \n",
    "                      agent_state, optimizer, scheduler, real_step)\n",
    "        last_returns.extend(stats[\"episode_returns\"])\n",
    "        if \"im_episode_returns\" in stats:\n",
    "            last_im_returns.extend(stats[\"im_episode_returns\"])\n",
    "        tot_eps = tot_eps + len(stats[\"episode_returns\"])\n",
    "        timings.time(\"learn\")\n",
    "        with lock:\n",
    "            to_log = dict(step=step, real_step=real_step)\n",
    "            to_log.update({k: stats[k] for k in stat_keys})            \n",
    "            to_log.update({\"rmean_im_episode_return\": np.average(last_im_returns) if len(last_im_returns) > 0 else 0.,\n",
    "                           \"rmean_episode_return\": np.average(last_returns) if len(last_returns) > 0 else 0.,\n",
    "                           \"episode\": tot_eps})\n",
    "            plogger.log(to_log)\n",
    "            step += T * B\n",
    "            real_step += stats[\"real_step\"]\n",
    "\n",
    "    if i == 0:\n",
    "        logging.info(\"Batch and learn: %s\", timings.summary())\n",
    "\n",
    "for m in range(flags.num_buffers):\n",
    "    free_queue.put(m)\n",
    "\n",
    "threads = []\n",
    "for i in range(flags.num_learner_threads):\n",
    "    thread = threading.Thread(\n",
    "        target=batch_and_learn, name=\"batch-and-learn-%d\" % i, args=(i,)\n",
    "    )\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "def checkpoint():\n",
    "    if flags.disable_checkpoint:\n",
    "        return\n",
    "    logging.info(\"Saving checkpoint to %s\", checkpointpath)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": actor_net.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"step\": step,\n",
    "            \"real_step\": real_step,\n",
    "            \"flags\": vars(flags),\n",
    "        },\n",
    "        checkpointpath,\n",
    "    )\n",
    "\n",
    "timer = timeit.default_timer\n",
    "try:\n",
    "    last_checkpoint_time = timer()\n",
    "    train_start_time = timer()\n",
    "    while real_step < flags.total_steps:\n",
    "        start_step = step\n",
    "        start_time = timer()\n",
    "        time.sleep(5)\n",
    "\n",
    "        if timer() - last_checkpoint_time > 10 * 60:  # Save every 10 min.\n",
    "            checkpoint()\n",
    "            last_checkpoint_time = timer()\n",
    "\n",
    "        sps = (step - start_step) / (timer() - start_time)\n",
    "        if stats.get(\"episode_returns\", None):\n",
    "            mean_return = (\n",
    "                \"Return per episode: %.1f. \" % stats[\"mean_episode_return\"]\n",
    "            )\n",
    "        else:\n",
    "            mean_return = \"\"\n",
    "        total_loss = stats.get(\"total_loss\", float(\"inf\"))\n",
    "\n",
    "        print_str =  \"Steps %i (%i) @ %.1f SPS. Eps %i. Return %f (%f). Loss %.2f\" % (real_step, step, sps, tot_eps, \n",
    "            np.average(last_returns) if len(last_returns) > 0 else 0.,\n",
    "            np.average(last_im_returns) if len(last_im_returns) > 0 else 0.,\n",
    "            total_loss)\n",
    "\n",
    "        for s in [\"mean_plan_step\", \"max_rollout_depth\", \"pg_loss\", \"baseline_loss\", \"im_pg_loss\", \n",
    "                  \"im_baseline_loss\", \"entropy_loss\", \"reg_loss\", \"total_norm\"]:\n",
    "            if s in stats: print_str += \" %s %.2f\" % (s, stats[s])\n",
    "\n",
    "        logging.info(print_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    for thread in threads:\n",
    "        thread.join()        \n",
    "    # Try joining actors then quit.\n",
    "else:\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    logging.info(\"Learning finished after %d steps. (%f s)\" % (step, timer() - train_start_time))\n",
    "finally:\n",
    "    for _ in range(flags.num_actors):\n",
    "        free_queue.put(None)\n",
    "    for actor in actor_processes:\n",
    "        actor.join(timeout=1)\n",
    "\n",
    "checkpoint()\n",
    "plogger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726743",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = flags.total_steps + 1\n",
    "for thread in threads:\n",
    "     thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(flags.num_actors):\n",
    "    free_queue.put(None)\n",
    "for actor in actor_processes:\n",
    "    actor.join(timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b71ad",
   "metadata": {},
   "source": [
    "<font size=\"5\">Agent Debug and Visualize</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3d487f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "def plot_obs(x, ax=None, title=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    ax.imshow(torch.swapaxes(torch.swapaxes(x[0].cpu(),0,2),0,1), interpolation='nearest', aspect=\"auto\")\n",
    "    if title is not None: ax.set_title(title)\n",
    "    \n",
    "def plot_qn_sa(q_s_a, n_s_a, max_q_s_a=None, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    xs = np.arange(len(q_s_a))\n",
    "\n",
    "    ax.bar(xs - 0.3, q_s_a.cpu(), color = 'g', width = 0.3, label=\"q_s_a\")    \n",
    "    ax_n = ax.twinx()\n",
    "    if max_q_s_a is not None:\n",
    "        ax.bar(xs, max_q_s_a.cpu(), color = 'r', width = 0.3, label=\"max_q_s_a\")        \n",
    "    ax_n.bar(xs + (0.3 if max_q_s_a is not None else 0.), \n",
    "             n_s_a.cpu(), bottom=0, color = 'b', width = 0.3, label=\"n_s_a\")\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(len(q_s_a))))\n",
    "    ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right'))    \n",
    "    ax.legend(loc=\"upper left\")   \n",
    "    ax_n.legend(loc=\"upper right\") \n",
    "    ax.set_title(\"q_s_a and n_s_a\")\n",
    "    \n",
    "def plot_policies(model_logit, actor_logit, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    model_prob = torch.softmax(model_logit, dim=-1).detach().cpu().numpy()\n",
    "    prob = torch.softmax(actor_logit, dim=-1).detach().cpu().numpy()\n",
    "    ax.set_title(\"Real policy prob\")\n",
    "    xs = np.arange(len(model_prob))\n",
    "    ax.bar(xs - 0.1, model_prob, color = 'g', width = 0.1, label=\"model policy prob\")\n",
    "    ax.bar(xs, prob, color = 'r', width = 0.1, label=\"agent policy prob\")\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(len(model_prob))))\n",
    "    ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right'))\n",
    "    ax.set_ylim(0, 1)        \n",
    "    ax.legend()       \n",
    "        \n",
    "def plot_im_policies(im_policy_logits, reset_policy_logits, term_policy_logits, \n",
    "                     im_action, reset_action, term_action,\n",
    "                     one_hot=True, reset_ind=0, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "        \n",
    "    rec_t, num_actions = im_policy_logits.shape\n",
    "    num_actions += 1\n",
    "    rec_t -= 1\n",
    "        \n",
    "    im_prob = torch.softmax(im_policy_logits, dim=-1).detach().cpu().numpy()\n",
    "    reset_prob = torch.softmax(reset_policy_logits, dim=-1)[:,[reset_ind]].detach().cpu().numpy()\n",
    "    full_prob = np.concatenate([im_prob, reset_prob], axis=-1)\n",
    "    if term_policy_logits is not None:\n",
    "        term_prob = torch.softmax(term_policy_logits, dim=-1)[:,[reset_ind]].detach().cpu().numpy()\n",
    "        full_prob = np.concatenate([full_prob, term_prob], axis=-1)\n",
    "    \n",
    "    if not one_hot: im_action = F.one_hot(im_action, num_actions - 1)\n",
    "    im_action = im_action.detach().cpu().numpy()\n",
    "    reset_action = reset_action.unsqueeze(-1).detach().cpu().numpy()    \n",
    "    full_action = np.concatenate([im_action, reset_action], axis=-1)\n",
    "    if term_action is not None:\n",
    "        term_action = term_action.unsqueeze(-1).detach().cpu().numpy() \n",
    "        full_action = np.concatenate([full_action, term_action], axis=-1)\n",
    "    \n",
    "    #full_prob = full_prob[:-1]\n",
    "    #full_action = full_action[:-1]    \n",
    "    #xs = np.arange(rec_t)\n",
    "    \n",
    "    xs = np.arange(rec_t+1)\n",
    "    labels = ['noop', 'up', 'down', 'left', 'right', 'reset']   \n",
    "    \n",
    "    if term_action is not None:\n",
    "        labels.append('term')\n",
    "        num_actions += 1\n",
    "        \n",
    "    for i in range(num_actions):        \n",
    "        c = ax.bar(xs + 0.8 * (i / num_actions), full_prob[:,i], width = 0.8 / (num_actions), label=labels[i])  \n",
    "        color = c.patches[0].get_facecolor()\n",
    "        color = color[:3] + (color[3] * 0.5,)\n",
    "        ax.bar(xs + 0.8 * (i / num_actions), full_action[:,i], width = 0.8 / (num_actions), color=color)\n",
    "        \n",
    "    \n",
    "    #xs = np.arange(num_actions)\n",
    "    #for i in range(rec_t):\n",
    "    #    ax.bar(xs + 0.8 * (i / rec_t), im_reset_action[i], width = 0.8 / (rec_t), color=\"#cccccc\")\n",
    "    #    ax.bar(xs + 0.8 * (i / rec_t), im_reset_prob[i], width = 0.8 / (rec_t))        \n",
    "    #ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(num_actions)))\n",
    "    #ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right', 'reset'))    \n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)   \n",
    "    ax.set_title(\"Imagainary policy prob\")\n",
    "    \n",
    "def print_im_actions(im_dict, print_stat=False):\n",
    "\n",
    "    lookup_dict = {0:\"Noop\",\n",
    "                   1:\"Up\",\n",
    "                   2:\"Down\",\n",
    "                   3:\"Left\",\n",
    "                   4:\"Right\"}\n",
    "\n",
    "    print_strs = []\n",
    "    n, s = 1, \"\"\n",
    "    reset = False\n",
    "    for im, reset in zip(im_dict[\"im_action\"][:-1], im_dict[\"reset_action\"][:-1]):\n",
    "        s += lookup_dict[im.item()] + \", \"\n",
    "        if reset:        \n",
    "            s += \"Reset\"\n",
    "            print_strs.append(\"%d: %s\" %(n, s))\n",
    "            s = \"\"\n",
    "            n += 1\n",
    "    if not reset: print_strs.append(\"%d: %s\" %(n, s[:-2]))\n",
    "    if print_stat: \n",
    "        for s in print_strs: print(s) \n",
    "    return print_strs\n",
    "\n",
    "def plot_im_actions(im_dict, ax=None):    \n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    print_strs = print_im_actions(im_dict, print_stat=False)\n",
    "    for n, s in enumerate(print_strs):  \n",
    "        txt = ax.text(0, 0.8 - 0.1 * n, s, size='x-large')        \n",
    "        txt.set_clip_on(True) \n",
    "    ax.set_xlim(0,1)    \n",
    "        \n",
    "def plot_base_policies(logits, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    prob = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    rec_t, num_actions = logits.shape\n",
    "    xs = np.arange(rec_t)\n",
    "    labels = ['noop', 'up', 'down', 'left', 'right']\n",
    "    for i in range(num_actions):        \n",
    "        c = ax.bar(xs + 0.8 * (i / num_actions), prob[:,i], width = 0.8 / (num_actions), label=labels[i])  \n",
    "        color = c.patches[0].get_facecolor()\n",
    "        color = color[:3] + (color[3] * 0.5,)\n",
    "        ax.bar(xs + 0.8 * (i / num_actions), prob[:,i], width = 0.8 / (num_actions), color=color)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)   \n",
    "    ax.set_title(\"Model policy prob\")\n",
    "        \n",
    "def plot_attn(attn_output):\n",
    "    plt.figure()\n",
    "    ln = flags.tran_layer_n\n",
    "    fig, axarr = plt.subplots(ln,8, figsize=(12,4)) \n",
    "    attn_output_ = torch.concat(attn_output, dim=-2)\n",
    "    for k in range(ln):\n",
    "        for i in range(8):\n",
    "            out = attn_output_[k, i]\n",
    "            out = out.detach().cpu().numpy()\n",
    "            axarr[k, i].imshow(out, interpolation='nearest', vmin=0, vmax=1)   \n",
    "            axarr[k, i].set_xticks([])\n",
    "            axarr[k, i].set_yticks([])\n",
    "    fig.suptitle('Attention')\n",
    "    fig.text(0.5, 0.04, 'Attention Head', ha='center', va='center')\n",
    "    fig.text(0.12, 0.5, 'Layer', ha='center', va='center', rotation='vertical')\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8908d69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CUDA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  885696\n",
      "flags: Namespace(env='Sokoban-v0', env_disable_noop=False, xpid='torchbeast-20221126-161700', disable_checkpoint=False, load_checkpoint='', savedir='~/RS/thinker/logs/torchbeast', num_actors=48, total_steps=100000000, batch_size=32, unroll_length=200, num_buffers=96, num_learner_threads=1, disable_cuda=False, tran_dim=96, tran_mem_n=50, tran_layer_n=3, tran_t=1, tran_ff_n=256, tran_skip=False, tran_norm_first=False, tran_rpos=True, tran_lstm=True, tran_lstm_no_attn=False, tran_attn_b=5.0, tran_erasep=False, entropy_cost=1e-05, im_entropy_cost=1e-05, reset_entropy_cost=1e-05, term_entropy_cost=0.0, baseline_cost=0.5, reg_cost=0.01, im_cost=1.0, discounting=0.97, lamb=1.0, reward_clipping=10, trun_bs=False, reward_type=1, reset_m=-1, model_type_nn=0.0, perfect_model=True, rec_t=200, flex_t=True, flex_t_cost=5e-05, flex_t_cost_m=-0.01, flex_t_cost_type=0, flex_t_term_b=-3.0, stat_type=2, no_mem=False, tree_carry=True, tree_vb=0.0, thres_carry=True, reward_carry=False, thres_discounting=0.99, learning_rate=0.0002, disable_adam=False, alpha=0.99, momentum=0, epsilon=0.01, grad_norm_clipping=600.0, num_rewards=2, im_discounting=0.9998477155590293, device=device(type='cuda'))\n"
     ]
    }
   ],
   "source": [
    "bsz = 1\n",
    "\n",
    "name = \"alstm_3_1_flext_5e-5\"\n",
    "#checkpoint = torch.load(\"/home/sc/RS/thinker/logs/planner_logs/%s/model.tar\" % name)\n",
    "checkpoint = torch.load(\"D:/data/thinker/logs/planner_logs/%s/model.tar\" % name)\n",
    "\n",
    "flags_ = checkpoint[\"flags\"]\n",
    "parser = define_parser()\n",
    "flags = parser.parse_args([])  \n",
    "for k, v in flags_.items(): setattr(flags, k, v)\n",
    "\n",
    "if flags.reward_type == 0:\n",
    "    flags.num_rewards = num_rewards = 1\n",
    "else:\n",
    "    flags.num_rewards = num_rewards = 2\n",
    "\n",
    "raw_env = SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "model_checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(model_checkpoint[\"model_state_dict\"])   \n",
    "\n",
    "env = Environment(ModelWrapper(SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop), \n",
    "     model=model, flags=flags))\n",
    "obs_shape = env.gym_env.observation_space.shape\n",
    "\n",
    "flags.device = None\n",
    "if not flags.disable_cuda and torch.cuda.is_available():\n",
    "    logging.info(\"Using CUDA.\")\n",
    "    flags.device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logging.info(\"Not using CUDA.\")\n",
    "    flags.device = torch.device(\"cpu\")\n",
    "\n",
    "actor_net = Actor_net(obs_shape, num_actions, flags).to(flags.device)\n",
    "actor_net.load_state_dict(checkpoint[\"model_state_dict\"]) \n",
    "\n",
    "print(\"flags:\", flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb82bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "eps_n = 1000\n",
    "\n",
    "raw_env = SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])  \n",
    "model.train(False)\n",
    "env = ModelWrapper(SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=True), model=model, flags=flags)\n",
    "env = Environment(env)\n",
    "\n",
    "core_state = actor_net.initial_state(bsz)\n",
    "core_state = tuple(v.to(flags.device) for v in core_state)\n",
    "returns = []\n",
    "obs = env.initial()\n",
    "initial_obs = env.gym_env.x.clone()\n",
    "\n",
    "t = 0\n",
    "im_list = [\"im_policy_logits\", \"reset_policy_logits\", \"term_policy_logits\", \"im_action\", \"reset_action\", \"term_action\"]\n",
    "im_dict = {k: [] for k in im_list}\n",
    "model_logits, attn_output = [], []\n",
    "\n",
    "while(True):\n",
    "    if len(returns) > (0 if debug else eps_n): break    \n",
    "    with torch.no_grad():\n",
    "        obs = {k:v.to(flags.device) for k, v in obs.items()}                             \n",
    "        actor_out, core_state = actor_net(obs, core_state, debug=False)\n",
    "        action = [actor_out['action'][0].unsqueeze(-1), actor_out['im_action'][0].unsqueeze(-1), actor_out['reset_action'][0].unsqueeze(-1)]\n",
    "        if flags.flex_t: action.append(actor_out['term_action'][0].unsqueeze(-1))\n",
    "        action = torch.cat(action, dim=-1)\n",
    "        if len(im_dict['reset_action']) > 0:\n",
    "            im_dict['reset_action'][-1] = env.gym_env.ret_dict['reset'].to(flags.device)\n",
    "        for k in im_list: \n",
    "            im_dict[k].append(actor_out[k][0,0].unsqueeze(0) if k in actor_out.keys() else None)          \n",
    "        model_logits.append(env.gym_env.ret_dict[\"logit\"])\n",
    "        attn_output.append(torch.cat([x.attn_output_weights.unsqueeze(0).unsqueeze(-2) for x in actor_net.core.layers])[:, :, 0, :])           \n",
    "        ret_dict = env.gym_env.ret_dict\n",
    "        \n",
    "        obs = env.step(action.unsqueeze(0))        \n",
    "        \n",
    "        if debug and (obs[\"cur_t\"][0,0] == 0):\n",
    "            plot_attn(attn_output)\n",
    "            for k in im_list: im_dict[k] = torch.concat(im_dict[k], dim=0)            \n",
    "            fig, axs = plt.subplots(1, 5, figsize=(30,6))                          \n",
    "            title = \"step: %d; values: %.4f\" % (t, ret_dict[\"v0\"][0].cpu())\n",
    "            if \"thres\" in ret_dict: title += \" thres: %.4f\" % ret_dict[\"thres\"][0].cpu()\n",
    "            if flags.reward_type == 1: title += \" im_return: %.4f\" % obs['episode_return'][..., 1]                        \n",
    "            plot_obs(initial_obs/255, axs[0], title=title)          \n",
    "            max_q_s_a = ret_dict[\"max_q_s_a\"][0] if \"max_q_s_a\" in ret_dict else None                        \n",
    "            plot_qn_sa(ret_dict[\"q_s_a\"][0], ret_dict[\"n_s_a\"][0], max_q_s_a, ax=axs[3]) \n",
    "            plot_policies(ret_dict[\"logit0\"][0], actor_out[\"policy_logits\"][0,0], ax=axs[4])    \n",
    "            plot_base_policies(torch.concat(model_logits), ax=axs[1])  \n",
    "            plot_im_policies(**im_dict, one_hot=False, reset_ind=1, ax=axs[2])              \n",
    "            plt.show()                        \n",
    "            print_im_actions(im_dict, print_stat=True)            \n",
    "            im_dict = {k: [] for k in im_list}          \n",
    "            model_logits, attn_output = [], []          \n",
    "            initial_obs = env.gym_env.x.clone()\n",
    "        \n",
    "        if torch.any(obs['done']):\n",
    "            new_rets = obs['episode_return'][obs['done']][:,0].numpy()\n",
    "            returns.extend(new_rets)\n",
    "            print(\"Finish %d episode: avg. return: %.2f (+-%.2f) \" % (len(returns),\n",
    "                np.average(returns), np.std(returns) / np.sqrt(len(returns))))  \n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b3d8f-5a0f-42eb-9b8f-cb79cf20c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, axarr = plt.subplots(1, 3, figsize=(6,6)) \n",
    "for k in range(3):\n",
    "    out = actor_net.core.layers[k].pos_b.detach().cpu().numpy()\n",
    "    ax = axarr[k]\n",
    "    ax.imshow(out, interpolation='nearest')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    im = ax.imshow(out)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "f.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66750c-3fcf-4ab3-96dc-d571a1c0aa90",
   "metadata": {},
   "source": [
    "<font size=\"5\">Misc.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scale(x, start, end, n):\n",
    "    return (end - start) * (np.clip(x, 0, n) / n) + start\n",
    "\n",
    "def square_scale(x, start, end, n):\n",
    "    return np.square((np.sqrt(end) - np.sqrt(start)) * (np.clip(x, 0, n) / n) + np.sqrt(start))\n",
    "\n",
    "def exp_scale(x, start, end, n, m):\n",
    "    a = (end - start) / (np.exp(m * n) - 1)\n",
    "    c = start - a\n",
    "    x = np.clip(x, 0, n)    \n",
    "    return a * np.exp(m * x) + c\n",
    "\n",
    "xs = np.arange(-50, 250, 1)\n",
    "y_min, y_max = 1e-7, 5e-3\n",
    "\n",
    "plt.plot(xs, linear_scale(xs, y_min, y_max, 200), label='linear')\n",
    "plt.plot(xs, square_scale(xs, y_min, y_max, 200), label='square')\n",
    "ys = exp_scale(xs, y_min, y_max, 200, 0.01)\n",
    "plt.plot(xs, ys, label='exp')\n",
    "plt.axhline(5e-4)\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "\n",
    "c = -9\n",
    "for x, y in zip(xs, ys):\n",
    "    if x % 5 == 0: print(x, y)\n",
    "    while (y > (10**c)): \n",
    "        print(\"%d exceed %d\" % (x, c))\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "322b0170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flags.perfect_model = True\n",
    "flags.reward_type = 1\n",
    "flags.rec_t = 2000\n",
    "flags.flex_t = True\n",
    "flags.flex_t_cost = 1e-5\n",
    "flags.flex_t_cost_m = 0\n",
    "flags.flex_t_cost_type = 0\n",
    "flags.reset_m = -1\n",
    "flags.tree_carry = True\n",
    "flags.tree_vb = 0.\n",
    "flags.thres_carry = True\n",
    "flags.thres_discounting = 1.\n",
    "\n",
    "raw_env = SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n         \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])    \n",
    "\n",
    "env = ModelWrapper(SokobanWrapper(gym.make(\"Sokoban-v0\"), noop=not flags.env_disable_noop), \n",
    "     model=model, flags=flags)\n",
    "env = Environment(env)\n",
    "obs = env.initial()\n",
    "plot_obs(env.gym_env.x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a544c489-1277-4e3e-9e7c-deb1c09aa63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': tensor([1, 0, 0, 0, 0]), 'r': tensor([0.]), 'v': tensor([1.1627]), 'child_logits': tensor([-1.1596, -0.5757, -1.7534,  1.0446, -2.5840]), 'child_rollout_qs_mean': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.1104]), 'child_rollout_qs_max': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.1104]), 'child_rollout_ns': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0005])}\n"
     ]
    }
   ],
   "source": [
    "env.gym_env.root_node.stat()\n",
    "print(env.gym_env.root_node.ret_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e7e543ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========0========\n",
      "a_tensor tensor([[[4, 4, 1, 1]]])\n",
      "eps_step tensor([[12]], dtype=torch.int32)\n",
      "eps_return tensor([[[-0.0400,  0.0000]]])\n",
      "reward tensor([[[-0.0100,  0.0000]]])\n",
      "cur_t tensor([[0]])\n",
      "thres tensor([1.3565])\n",
      "root_node qs [tensor([1.1551])]\n",
      "child_node qs []\n",
      "=========1========\n",
      "a_tensor tensor([[[4, 4, 1, 1]]])\n",
      "eps_step tensor([[13]], dtype=torch.int32)\n",
      "eps_return tensor([[[-0.0500,  0.0000]]])\n",
      "reward tensor([[[-0.0100,  0.0000]]])\n",
      "cur_t tensor([[0]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551])]\n",
      "child_node qs []\n",
      "=========2========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[14]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -1.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[1]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n",
      "=========3========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[15]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -2.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[2]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n",
      "=========4========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[16]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -3.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[3]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGgCAYAAAAKKQXsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAph0lEQVR4nO3df3RU9Z3/8VdikkkQMuFnQpYEaUsbrIIaNMyC/QHRHI7rgSXraqVbLFRWNlAg21MNp/6oxxLW/VZ+7AngD06wVTYtPQuteoTFqPFHA0JEq4uNWDmSCgm6p5mJgSRA7vcP16lj5g65yeQzM3eej3PmHPncO/f9+cxHwuvcfOZ+UizLsgQAAGBIaqw7AAAAkgvhAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABg1ZOGjpqZGl1xyiTIzM1VSUqLXXnttqEoBAIAEkjIUe7v86le/0ve+9z1t3bpVJSUl2rBhg3bu3Knm5maNGzcu4nt7e3t14sQJjRgxQikpKdHuGgAAGAKWZamjo0P5+flKTb3AvQ1rCFxzzTVWRUVF8M/nz5+38vPzrerq6gu+t6WlxZLEixcvXrx48UrAV0tLywX/rU9TlPX09KipqUlVVVXBttTUVJWWlqqxsbHP+d3d3eru7g7+2fq/GzGPXS0N62/vLp9jf+yt+n5eZIA1onV9agz++iZqJNLn5JYazHdy1WC+E7bG6XPSDw5KI0aMuOBlox4+Pv74Y50/f165ubkh7bm5ufrjH//Y5/zq6mr99Kc/7dM+LM1B+MiIcGK0RmhXI5qfIDUGd30TNRLpc3JLDeY7uWow3wlfoz9LJmL+bZeqqir5/f7gq6WlJdZdAgAAQyjqdz7GjBmjiy66SG1tbSHtbW1tysvL63O+x+ORx+OJdjcAAECcivqdj4yMDBUXF6u+/q+/D+rt7VV9fb18Pl+0ywEAgAQT9TsfklRZWalFixZp+vTpuuaaa7RhwwZ1dnbq+9///lCUAwAACWRIwsfNN9+sjz76SPfcc49aW1t1xRVXaM+ePX0WoQIAgOQzJA8ZG4xAICCv16sdG9dqWFZmrLsDAAD64fSZLt26co38fr+ys7Mjnhvzb7sAAIDkQvgAAABGET4AAIBRhA8AAGDUkHzbJSrq1vTt3bSy8Oe+uTd6dakxuOubqJFIn5NbajDfyVWD+U6uGtGa73P9P5U7HwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACj2NUWAAAMGrvaAgCAuEX4AAAARhE+AACAUYQPAABgVGLtamuHHRiTqwbznVw1mO/kqsF8J24NdrUFAADxivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwKj4fcgYEEX/70BG2PZZ6enh3/D6KzZXujg6HYpQ45Wz4fsaSSKN45WeHmfXfzmKD0yiRoh3/tnmQKT/Bafa1JjmqLS9dyKM4fLwzVM2h28fe/uIsO2djS+GbT/dFKFfNoYVe8K2X9z9+7DtH70c/jq7r3VeO5Fx5wMAABhF+AAAAEYRPgAAgFGEDwAAYBQLTpEU7BZkruvsNNyTC7vrYueLQRNpHI4XnGLoZNq050V4zyib9txB9uUzbRGOXeTsUh892hG2fcpr+c4uNADvXHNiyGskMu58AAAAowgfAADAKMfh46WXXtKNN96o/Px8paSkaPfu3SHHLcvSPffco/HjxysrK0ulpaU6evRotPoLAAASnOM1H52dnZo2bZoWL16sBQsW9Dn+4IMPatOmTXr88cc1adIk3X333SorK9ORI0eUmWn3C8YwblkrZTk4387UssFfI5bXp0Z0arx+d1QuPyvCMbvHecUju3Ek0hgQBZfZtI+N8J4XbNq/bdM+xqbd5mFbtn2SpI8iHAtj4tbwxT+2WQsSTXa1P7jj4/Bv+KeHolc8Vj9rz3RJjWv69XbH4WPu3LmaO3du2GOWZWnDhg36yU9+onnz5kmSfvGLXyg3N1e7d+/WLbfc4rQcAABwmaiu+Th27JhaW1tVWloabPN6vSopKVFjY2PY93R3dysQCIS8AACAe0U1fLS2tkqScnNDv3OVm5sbPPZF1dXV8nq9wVdBQUE0uwQAAOJMzL/tUlVVJb/fH3y1tLTEuksAAGAIRfUhY3l5nz6Zpq2tTePHjw+2t7W16Yorrgj7Ho/HI48nzK6AdWv69m6azSKaN6O4WyQ1Bnd9EzUGdH1nD+6yW5D5zBi71XPSyx3hF7H9XXe3o9rR5HQc8TgGxID9/+bSN2za6x1ey24X3Ei1bRac2i3uHHZV+O157dpNsOurfllp/6ZE+Xl+rv+nRvXOx6RJk5SXl6f6+r/+XxgIBHTgwAH5fL5olgIAAAnK8Z2PTz75RO+9917wz8eOHdMbb7yhUaNGqbCwUKtWrdIDDzygyZMnB79qm5+fr/nz50ez3wAAIEE5Dh+HDh3St7/91y90V1Z+eqto0aJF2r59u3784x+rs7NTS5cuVXt7u2bNmqU9e/Y4e8YHAABwLcfh41vf+pYsy7I9npKSovvvv1/333//oDoGxJLdw7bs1kRI0ro4XBfhdBzxOAbEmWhtIBdFsVzD4ZRtX580249Yi/m3XQAAQHIhfAAAAKMIHwAAwCjCBwAAMCqqDxmLKie72rp9R1ZqDP76UdrV1i0P23LLODBINhusqi3Ce961aZ/jsLbT3XHdbiC72sbbz3MHu9py5wMAABhF+AAAAEYRPgAAgFGEDwAAYFT8LjgNt6utnYTbYZUaQ3L9iDWc7WoLJIVWm/YTEd5jt7A00m604djtjmu3EDWCd24P3+Gxt48I2z6sOMxO6pJONzlfiO30Wh89avOU5Gsj7GprJ95+nsdqV1sAAIALIXwAAACjCB8AAMCo+F3zAUTRK2fPhm2/6+L4Wwti19dI3DIOGNZl0x7p+Y4fOWyPJrv+2rBbXzHW4fmRRPNayYQ7HwAAwCjCBwAAMIrwAQAAjCJ8AAAAo1hwOoTmv+zwDS9H8cEwUarxzj/bHMiI8KapNjWmOSpt750IY7g8fPMrL/eEb+8J3x6PbOdCkjJsxjF1SLoS6p3wzYtsFgdO2Tx0XTHJ8d+NGM6F3ULN2x8L39lZ6enR6U+U2S1inmXzmduOY0dv+PaBLNx2eC37hdiJ87MoGrjzAQAAjCJ8AAAAowgfAADAKMIHAAAwigWniMzuSYd5Ed4zyqY9d5B9+UxbhGMXRalGPIr01Em7+RjquZDs58PNcyE5/7sRh3NhtyBzXWdndPoTZU6f5BuP47AfAwtOAQAAhgzhAwAAGEX4AAAARsXvmo9b1kpZkX7J3U9TywZ/jYFe/+XKoa1twmU27XZbOUrSCzbt37ZpH2PTbveQNrs+SWZ21oyVSOO2m4+hngvJvl9ungvJ+d+NaM2F5PzvhoG5mGXT/srQl44auzFIBsbxTw9F71pD/e+eXY0zXVLjmn69nTsfAADAKMIHAAAwivABAACMInwAAACj4nfBad2avr2bZrOI5s0o7gZrooYbRFoM9w2b9nqH17LbBTdSbbcvcrRj95kM9VxEeg9zESpacyE5/7sRxbmwW5T5zJjwxV/u6Ajb/nfd3VHqkXNOxyAZGMcvI3xBYaj/XbK7vtMa5/p/Knc+AACAUYQPAABglKPwUV1drauvvlojRozQuHHjNH/+fDU3N4ec09XVpYqKCo0ePVrDhw9XeXm52toibcYBAACSiaM1Hw0NDaqoqNDVV1+tc+fOac2aNbr++ut15MgRXfx/m+WsXr1azzzzjHbu3Cmv16vly5drwYIFevXVV4dkAIhD0dwoC4PDXMQPl8yF3cO27NZErIvh2g47Tscgxec4Epmj8LFnz56QP2/fvl3jxo1TU1OTvvGNb8jv92vbtm3asWOHZs+eLUmqra3VlClTtH//fs2YMSN6PQcAAAlpUGs+/H6/JGnUqE/3im5qatLZs2dVWloaPKeoqEiFhYVqbGwMe43u7m4FAoGQFwAAcK8Bh4/e3l6tWrVKM2fO1GWXfbqhQGtrqzIyMpSTkxNybm5urlpbW8Nep7q6Wl6vN/gqKCgYaJcAAEACGHD4qKio0Ntvv626urpBdaCqqkp+vz/4amlpGdT1AABAfBvQQ8aWL1+up59+Wi+99JImTJgQbM/Ly1NPT4/a29tD7n60tbUpLy8v7LU8Ho88Hk/fA052tY3VDn4X4oZdbT+2aY/0BaZ3bdrnOKztdBdQt7ObC8l+PoZ6LiTm44uGei6kuPy7EcuHhkVLTMcwkF1t4+3fvqHa1dayLC1fvly7du3S888/r0mTJoUcLy4uVnp6uurr//rIvubmZh0/flw+n89JKQAA4FKO7nxUVFRox44d+u1vf6sRI0YE13F4vV5lZWXJ6/VqyZIlqqys1KhRo5Sdna0VK1bI5/PxTRcAACDJYfjYsmWLJOlb3/pWSHttba1uu+02SdL69euVmpqq8vJydXd3q6ysTJs3b45KZwEAQOJzFD4sy7rgOZmZmaqpqVFNTc2AOwUAANwrsXa1tROtHfkGUsPtu92G/4a0dCLCe+wW0EXapTMcu11AIy1+dDO7uZDs52Oo50JiPr5oqOdC4u+GG0Xa1dZOvO30zq62AAAgXhE+AACAUYQPAABgVPyu+UB86LJpj/T8t48ctkeTXX/dINLY7OaDuRg6Tv9uxOFcvHL2bNj2u/5vl/J4Y9dfO/E4DrsxJNvDKLjzAQAAjCJ8AAAAowgfAADAKMIHAAAwigWniGjKw7HuAT7DXMQXd8xHT9jWV3rCtyeaRBrHj2LdAcO48wEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwKn4fMnbLWikr0tap/TS1bPDXGOj1X64c2toAAHf4p4eid62h/nfPrsaZLqlxTb/ezp0PAABgFOEDAAAYRfgAAABGET4AAIBR8bvgtG5N395Ns1lE8+be6NU1UQMAgM/7ZYQvKAz1v0t213da41z/T+XOBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMCo+H3ImJNdbWO1g9+FsKstAKA/BrKrbbz928eutgAAIF4RPgAAgFGEDwAAYJSj8LFlyxZNnTpV2dnZys7Ols/n07PPPhs83tXVpYqKCo0ePVrDhw9XeXm52traot5pAACQuBwtOJ0wYYLWrVunyZMny7IsPf7445o3b54OHz6sr3/961q9erWeeeYZ7dy5U16vV8uXL9eCBQv06quvOu9ZuF1t7URrR76B1GC3WwDAYEXa1dZOvO307mBXW0fh48Ybbwz5889+9jNt2bJF+/fv14QJE7Rt2zbt2LFDs2fPliTV1tZqypQp2r9/v2bMmOGkFAAAcKkBr/k4f/686urq1NnZKZ/Pp6amJp09e1alpaXBc4qKilRYWKjGxkbb63R3dysQCIS8AACAezkOH2+99ZaGDx8uj8ejO+64Q7t27dKll16q1tZWZWRkKCcnJ+T83Nxctba22l6vurpaXq83+CooKHA8CAAAkDgch4+vfe1reuONN3TgwAEtW7ZMixYt0pEjRwbcgaqqKvn9/uCrpaVlwNcCAADxz/ETTjMyMvSVr3xFklRcXKyDBw9q48aNuvnmm9XT06P29vaQux9tbW3Ky8uzvZ7H45HH43HecwAAkJAG/ZyP3t5edXd3q7i4WOnp6aqvrw8ea25u1vHjx+Xz+QZbBgAAuISjOx9VVVWaO3euCgsL1dHRoR07dujFF1/U3r175fV6tWTJElVWVmrUqFHKzs7WihUr5PP5+KYLAAAIchQ+Tp06pe9973s6efKkvF6vpk6dqr179+q6666TJK1fv16pqakqLy9Xd3e3ysrKtHnz5iHpOAAASEyOwse2bdsiHs/MzFRNTY1qamoG1Sm32H2twzfE2wNj4rWGWx4qR43BXd9EjUT6nNxSYwDzPf/l6JSGOeztAgAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADAqxbIsK9ad+LxAICCv16sdG9dqWFZmrLsDAIhz85dWxroLg7b7kYdi3YVBO32mS7euXCO/36/s7OyI53LnAwAAGEX4AAAARhE+AACAUYQPAABglKNdbY2qW9O3d27YsdEtNdhpNLlqMN/JVcMt851Ifhlh0WyizPe5/p/KnQ8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUexqCwBIaOxqGx/Y1RYAAMQtwgcAADCK8AEAAIwifAAAAKMSa1dbO27ZgZEag7u+iRqJ9Dm5pQbznVw1TMx3PIq0q62deJtvdrUFAADxivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMGFT7WrVunlJQUrVq1KtjW1dWliooKjR49WsOHD1d5ebna2toG208AAOASAw4fBw8e1MMPP6ypU6eGtK9evVpPPfWUdu7cqYaGBp04cUILFiwYdEcBAIA7DCh8fPLJJ1q4cKEeffRRjRw5Mtju9/u1bds2PfTQQ5o9e7aKi4tVW1ur3//+99q/f3/UOg0AABLXgMJHRUWFbrjhBpWWloa0NzU16ezZsyHtRUVFKiwsVGNjY9hrdXd3KxAIhLwAAIB7Od7bpa6uTq+//roOHjzY51hra6syMjKUk5MT0p6bm6vW1taw16uurtZPf/pTp90AAAAJytGdj5aWFq1cuVJPPvmkMjMzo9KBqqoq+f3+4KulpSUq1wUAAPHJUfhoamrSqVOndNVVVyktLU1paWlqaGjQpk2blJaWptzcXPX09Ki9vT3kfW1tbcrLywt7TY/Ho+zs7JAXAABwL0e/dpkzZ47eeuutkLbvf//7Kioq0p133qmCggKlp6ervr5e5eXlkqTm5mYdP35cPp8ver0GAAAJy1H4GDFihC677LKQtosvvlijR48Oti9ZskSVlZUaNWqUsrOztWLFCvl8Ps2YMSN6vQYAAAnL8YLTC1m/fr1SU1NVXl6u7u5ulZWVafPmzdEuAwAAElSKZVlWrDvxeYFAQF6vVzs2rtWwrOgsagUAuNf8pZWx7sKg7X7koVh3YdBOn+nSrSvXyO/3X3D9Jnu7AAAAowgfAADAKMIHAAAwivABAACMivq3XaKmbk3f3k0rC3/um3ujV5cag7u+iRqJ9Dm5pQbznVw13DLfieSXERbNJsp8n+v/qdz5AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABjFrrYAgITGrrbxgV1tAQBA3CJ8AAAAowgfAADAKMIHAAAwKrF2tbXjlh0YqTG465uokUifk1tqMN/JVcPEfMejSLva2om3+WZXWwAAEK8IHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMit+HjAEA0A+7r3X4hnh7OFcS4s4HAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMchY/77rtPKSkpIa+ioqLg8a6uLlVUVGj06NEaPny4ysvL1dbWFvVOAwCAxJViWZbV35Pvu+8+/eY3v9Fzzz0XbEtLS9OYMWMkScuWLdMzzzyj7du3y+v1avny5UpNTdWrr77a7w4FAgF5vV7t2LhWw7IyHQwFAADEyukzXbp15Rr5/X5lZ2dHPNfxE07T0tKUl5fXp93v92vbtm3asWOHZs+eLUmqra3VlClTtH//fs2YMcNpKQAA4EKO13wcPXpU+fn5+tKXvqSFCxfq+PHjkqSmpiadPXtWpaWlwXOLiopUWFioxsZG2+t1d3crEAiEvAAAgHs5Ch8lJSXavn279uzZoy1btujYsWO69tpr1dHRodbWVmVkZCgnJyfkPbm5uWptbbW9ZnV1tbxeb/BVUFAwoIEAAIDE4OjXLnPnzg3+99SpU1VSUqKJEyfq17/+tbKysgbUgaqqKlVWVgb/HAgECCAAALjYoHa1zcnJ0Ve/+lW99957uu6669TT06P29vaQux9tbW1h14h8xuPxyOPx9D1Qt6Zv79yyE6Ebathd30SNRPqc3FKD+U6uGsx3ctWI1nyf6/+pg3rOxyeffKI//elPGj9+vIqLi5Wenq76+vrg8ebmZh0/flw+n28wZQAAgIs4uvPxox/9SDfeeKMmTpyoEydO6N5779VFF12k73znO/J6vVqyZIkqKys1atQoZWdna8WKFfL5fHzTBQAABDkKH3/+85/1ne98R//7v/+rsWPHatasWdq/f7/Gjh0rSVq/fr1SU1NVXl6u7u5ulZWVafPmzUPScQAAkJgchY+6urqIxzMzM1VTU6OamppBdQoAALgXe7sAAACjCB8AAMAowgcAADCK8AEAAIxytKutCexqCwBA4nGyqy13PgAAgFGEDwAAYBThAwAAGEX4AAAARg1qV9shFW5XWzvswJhcNZjv5KrBfCdXDeY7cWuY2tUWAADAKcIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMCoFMuyrFh34vMCgYC8Xq92bFyrYVmZse4OAADoh9NnunTryjXy+/3Kzs6OeC53PgAAgFGEDwAAYBThAwAAGEX4AAAARqXFugO26tb07d20svDnvrk3enWpMbjrm6iRSJ+TW2ow38lVg/lOrhrRmu9z/T+VOx8AAMAowgcAADDKcfj48MMP9d3vflejR49WVlaWLr/8ch06dCh43LIs3XPPPRo/fryysrJUWlqqo0ePRrXTAAAgcTkKH3/5y180c+ZMpaen69lnn9WRI0f085//XCNHjgye8+CDD2rTpk3aunWrDhw4oIsvvlhlZWXq6uqKeucBAEDicbTg9N/+7d9UUFCg2traYNukSZOC/21ZljZs2KCf/OQnmjdvniTpF7/4hXJzc7V7927dcsstUeo2AABIVI7ufPzud7/T9OnTddNNN2ncuHG68sor9eijjwaPHzt2TK2trSotLQ22eb1elZSUqLGxMew1u7u7FQgEQl4AAMC9HIWP999/X1u2bNHkyZO1d+9eLVu2TD/84Q/1+OOPS5JaW1slSbm5uSHvy83NDR77ourqanm93uCroKBgIOMAAAAJwlH46O3t1VVXXaW1a9fqyiuv1NKlS3X77bdr69atA+5AVVWV/H5/8NXS0jLgawEAgPjnaFfbiRMn6rrrrtNjjz0WbNuyZYseeOABffjhh3r//ff15S9/WYcPH9YVV1wRPOeb3/ymrrjiCm3cuPGCNdjVFgCAxDNku9rOnDlTzc3NIW3vvvuuJk6cKOnTxad5eXmqr68PHg8EAjpw4IB8Pp+TUgAAwKUcfdtl9erV+tu//VutXbtW//iP/6jXXntNjzzyiB555BFJUkpKilatWqUHHnhAkydP1qRJk3T33XcrPz9f8+fPH4r+AwCABOMofFx99dXatWuXqqqqdP/992vSpEnasGGDFi5cGDznxz/+sTo7O7V06VK1t7dr1qxZ2rNnjzIz+RUKAABwuObDBNZ8AACQeJys+UisXW3tsANjctVgvpOrBvOdXDWY78Stwa62AAAgXhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGpViWZcW6E58XCATk9Xq1Y+NaDcvKjHV3AABAP5w+06VbV66R3+9XdnZ2xHO58wEAAIwifAAAAKMIHwAAwCjCBwAAMCot1h2wVbemb++mlYU/98290atLjcFd30SNRPqc3FKD+U6uGsx3ctWI1nyf6/+p3PkAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGMWutgAAYNDY1RYAAMQtwgcAADDKUfi45JJLlJKS0udVUVEhSerq6lJFRYVGjx6t4cOHq7y8XG1tbUPScQAAkJgchY+DBw/q5MmTwde+ffskSTfddJMkafXq1Xrqqae0c+dONTQ06MSJE1qwYEH0ew0AABLWoBacrlq1Sk8//bSOHj2qQCCgsWPHaseOHfqHf/gHSdIf//hHTZkyRY2NjZoxY0a/rhlccOqThvV3z112YEyuGsx3ctVgvpOrBvOdsDVOn5NubdTQLjjt6enRE088ocWLFyslJUVNTU06e/asSktLg+cUFRWpsLBQjY2Nttfp7u5WIBAIeQEAAPcacPjYvXu32tvbddttt0mSWltblZGRoZycnJDzcnNz1draanud6upqeb3e4KugoGCgXQIAAAlgwOFj27Ztmjt3rvLz8wfVgaqqKvn9/uCrpaVlUNcDAADxrb+rKkJ88MEHeu655/Rf//Vfwba8vDz19PSovb095O5HW1ub8vLybK/l8Xjk8XgG0g0AAJCABnTno7a2VuPGjdMNN9wQbCsuLlZ6errq6+uDbc3NzTp+/Lh8Pt/gewoAAFzB8Z2P3t5e1dbWatGiRUpL++vbvV6vlixZosrKSo0aNUrZ2dlasWKFfD5fv7/pAgAA3M9x+Hjuued0/PhxLV68uM+x9evXKzU1VeXl5eru7lZZWZk2b94clY4CAAB3cBw+rr/+etk9GiQzM1M1NTWqqakZdMcAAIA7sbcLAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMCrFsntcaYwEAgF5vV7t2LhWw7IyY90dAADQD6fPdOnWlWvk9/uVnZ0d8VzufAAAAKMIHwAAwCjCBwAAMIrwAQAAjEqLdQds1a3p27tpZeHPfXNv9OpSY3DXN1EjkT4nt9RgvpOrBvOdXDWiNd/n+n8qdz4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARrGrLQAAGDR2tQUAAHGL8AEAAIwifAAAAKMIHwAAwKjE2tXWDjswJlcN5ju5ajDfyVWD+U7cGuxqCwAA4hXhAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGxd1zPj7b5+60g+8LqyfCyU6uM5Aa0bo+NQZ/fRM1EulzcksN5ju5ajDfCVvjs3+3+7NfbdztavvnP/9ZBQUFse4GAAAYgJaWFk2YMCHiOXEXPnp7e3XixAmNGDFCHR0dKigoUEtLywW353WTQCDAuBm36zFuxp0MkmnclmWpo6ND+fn5Sk2NvKoj7n7tkpqaGkxMKSkpkqTs7GzXT1o4jDu5MO7kwriTS7KM2+v19us8FpwCAACjCB8AAMCouA4fHo9H9957rzweT6y7YhTjZtzJgHEz7mSQrOO+kLhbcAoAANwtru98AAAA9yF8AAAAowgfAADAKMIHAAAwivABAACMiuvwUVNTo0suuUSZmZkqKSnRa6+9FusuRdVLL72kG2+8Ufn5+UpJSdHu3btDjluWpXvuuUfjx49XVlaWSktLdfTo0dh0Noqqq6t19dVXa8SIERo3bpzmz5+v5ubmkHO6urpUUVGh0aNHa/jw4SovL1dbW1uMehwdW7Zs0dSpU4NPOvT5fHr22WeDx9045i9at26dUlJStGrVqmCbW8d93333KSUlJeRVVFQUPO7WcUvShx9+qO9+97saPXq0srKydPnll+vQoUPB42782XbJJZf0me+UlBRVVFRIcvd8D0Tcho9f/epXqqys1L333qvXX39d06ZNU1lZmU6dOhXrrkVNZ2enpk2bppqamrDHH3zwQW3atElbt27VgQMHdPHFF6usrExdXV2GexpdDQ0Nqqio0P79+7Vv3z6dPXtW119/vTo7O4PnrF69Wk899ZR27typhoYGnThxQgsWLIhhrwdvwoQJWrdunZqamnTo0CHNnj1b8+bN0//8z/9IcueYP+/gwYN6+OGHNXXq1JB2N4/761//uk6ePBl8vfLKK8Fjbh33X/7yF82cOVPp6el69tlndeTIEf385z/XyJEjg+e48WfbwYMHQ+Z63759kqSbbrpJknvne8CsOHXNNddYFRUVwT+fP3/eys/Pt6qrq2PYq6Ejydq1a1fwz729vVZeXp717//+78G29vZ2y+PxWP/5n/8Zgx4OnVOnTlmSrIaGBsuyPh1nenq6tXPnzuA577zzjiXJamxsjFU3h8TIkSOtxx57zPVj7ujosCZPnmzt27fP+uY3v2mtXLnSsix3z/W9995rTZs2LewxN4/7zjvvtGbNmmV7PFl+tq1cudL68pe/bPX29rp6vgcqLu989PT0qKmpSaWlpcG21NRUlZaWqrGxMYY9M+fYsWNqbW0N+Qy8Xq9KSkpc9xn4/X5J0qhRoyRJTU1NOnv2bMjYi4qKVFhY6Jqxnz9/XnV1ders7JTP53P9mCsqKnTDDTeEjE9y/1wfPXpU+fn5+tKXvqSFCxfq+PHjktw97t/97neaPn26brrpJo0bN05XXnmlHn300eDxZPjZ1tPToyeeeEKLFy9WSkqKq+d7oOIyfHz88cc6f/68cnNzQ9pzc3PV2toao16Z9dk43f4Z9Pb2atWqVZo5c6Yuu+wySZ+OPSMjQzk5OSHnumHsb731loYPHy6Px6M77rhDu3bt0qWXXurqMdfV1en1119XdXV1n2NuHndJSYm2b9+uPXv2aMuWLTp27JiuvfZadXR0uHrc77//vrZs2aLJkydr7969WrZsmX74wx/q8ccfl5QcP9t2796t9vZ23XbbbZLc/f/5QKXFugNIbhUVFXr77bdDfhfuZl/72tf0xhtvyO/36ze/+Y0WLVqkhoaGWHdryLS0tGjlypXat2+fMjMzY90do+bOnRv876lTp6qkpEQTJ07Ur3/9a2VlZcWwZ0Ort7dX06dP19q1ayVJV155pd5++21t3bpVixYtinHvzNi2bZvmzp2r/Pz8WHclbsXlnY8xY8booosu6rMSuK2tTXl5eTHqlVmfjdPNn8Hy5cv19NNP64UXXtCECROC7Xl5eerp6VF7e3vI+W4Ye0ZGhr7yla+ouLhY1dXVmjZtmjZu3OjaMTc1NenUqVO66qqrlJaWprS0NDU0NGjTpk1KS0tTbm6uK8cdTk5Ojr761a/qvffec+18S9L48eN16aWXhrRNmTIl+Csnt/9s++CDD/Tcc8/pBz/4QbDNzfM9UHEZPjIyMlRcXKz6+vpgW29vr+rr6+Xz+WLYM3MmTZqkvLy8kM8gEAjowIEDCf8ZWJal5cuXa9euXXr++ec1adKkkOPFxcVKT08PGXtzc7OOHz+e8GP/ot7eXnV3d7t2zHPmzNFbb72lN954I/iaPn26Fi5cGPxvN447nE8++UR/+tOfNH78eNfOtyTNnDmzz1fn3333XU2cOFGSu3+2SVJtba3GjRunG264Idjm5vkesFiveLVTV1dneTwea/v27daRI0espUuXWjk5OVZra2usuxY1HR0d1uHDh63Dhw9bkqyHHnrIOnz4sPXBBx9YlmVZ69ats3Jycqzf/va31h/+8Adr3rx51qRJk6wzZ87EuOeDs2zZMsvr9VovvviidfLkyeDr9OnTwXPuuOMOq7Cw0Hr++eetQ4cOWT6fz/L5fDHs9eDdddddVkNDg3Xs2DHrD3/4g3XXXXdZKSkp1n//939bluXOMYfz+W+7WJZ7x/2v//qv1osvvmgdO3bMevXVV63S0lJrzJgx1qlTpyzLcu+4X3vtNSstLc362c9+Zh09etR68sknrWHDhllPPPFE8By3/mw7f/68VVhYaN155519jrl1vgcqbsOHZVnWf/zHf1iFhYVWRkaGdc0111j79++PdZei6oUXXrAk9XktWrTIsqxPv5J29913W7m5uZbH47HmzJljNTc3x7bTURBuzJKs2tra4Dlnzpyx/uVf/sUaOXKkNWzYMOvv//7vrZMnT8au01GwePFia+LEiVZGRoY1duxYa86cOcHgYVnuHHM4Xwwfbh33zTffbI0fP97KyMiw/uZv/sa6+eabrffeey943K3jtizLeuqpp6zLLrvM8ng8VlFRkfXII4+EHHfrz7a9e/daksKOxc3zPRAplmVZMbnlAgAAklJcrvkAAADuRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUf8fkjxVINWabPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 4\n",
    "a_seqs = ([a,a,1,1],[a,a,1,1],[a,a,1,0],[a,a,1,0],[a,a,1,0])\n",
    "\n",
    "#a_seqs = ([2,4,0],[2,2,0],[2,2,0],[2,2,0],[2,3,0])\n",
    "\n",
    "for n, act in enumerate(a_seqs):\n",
    "    print(\"=========%d========\"%n)\n",
    "    a_tensor = torch.tensor([[act]]).long()\n",
    "    print(\"a_tensor\", a_tensor)\n",
    "    obs = env.step(a_tensor)\n",
    "    print(\"eps_step\", obs['episode_step'])\n",
    "    print(\"eps_return\", obs['episode_return'])\n",
    "    print(\"reward\", obs['reward'])\n",
    "    print(\"cur_t\", obs['cur_t'])\n",
    "    print(\"thres\", env.gym_env.thres)\n",
    "    print(\"root_node qs\", [x / 0.97 for x in env.gym_env.root_node.rollout_qs])\n",
    "    print(\"child_node qs\", env.gym_env.root_node.children[a].rollout_qs)\n",
    "    plot_obs(env.gym_env.x_/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_seqs = [[0,0,0]]\n",
    "\n",
    "for n, a in enumerate(a_seqs):\n",
    "    print(\"=========%d========\"%n)\n",
    "    a_tensor = torch.tensor([[a]]).long()\n",
    "    print(\"a_tensor\", a_tensor)\n",
    "    obs = env.step(a_tensor)\n",
    "    print(\"eps_step\", obs['episode_step'])\n",
    "    print(\"eps_return\", obs['episode_return'])\n",
    "    print(\"reward\", obs['reward'])\n",
    "    print(\"cur_t\", obs['cur_t'])\n",
    "    plot_obs(env.gym_env.x_/255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
