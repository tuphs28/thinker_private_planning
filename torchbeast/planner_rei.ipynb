{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d1c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import pprint\n",
    "import threading\n",
    "import time\n",
    "import timeit\n",
    "import traceback\n",
    "import typing\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Necessary for multithreading.\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing as mp\n",
    "from torch.multiprocessing import Process, Manager\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchbeast.core import file_writer\n",
    "from torchbeast.core import prof\n",
    "from torchbeast.core import vtrace\n",
    "from torchbeast.atari_wrappers import *\n",
    "from torchbeast.transformer_rnn import *\n",
    "from torchbeast.train import *\n",
    "from torchbeast.model import Model\n",
    "\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import gym_csokoban\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from collections import deque\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# util functions\n",
    "\n",
    "def get_git_revision_hash():\n",
    "    return subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()\n",
    "\n",
    "def exp_scale(x, start, end, n, m):\n",
    "    a = (end - start) / (np.exp(m * n) - 1)\n",
    "    c = start - a\n",
    "    x = np.clip(x, 0, n)    \n",
    "    return a * np.exp(m * x) + c\n",
    "\n",
    "class DataParallelWrapper(object):\n",
    "    def __init__(self, module):\n",
    "        self.module = module\n",
    "              \n",
    "    def __getattr__(self, name):        \n",
    "        if name in self.module.__dict__.keys(): \n",
    "            return getattr(self.module, name)\n",
    "        else:\n",
    "            return getattr(self.module.module, name)\n",
    "    \n",
    "# Update to original core funct\n",
    "\n",
    "def create_buffers(flags, obs_shape, num_actions, num_rewards) -> Buffers:\n",
    "    T = flags.unroll_length\n",
    "    specs = dict(\n",
    "        frame=dict(size=(T + 1, *obs_shape), dtype=torch.float32),\n",
    "        reward=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        done=dict(size=(T + 1,), dtype=torch.bool),\n",
    "        truncated_done=dict(size=(T + 1,), dtype=torch.bool),\n",
    "        episode_return=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        episode_step=dict(size=(T + 1,), dtype=torch.int32),\n",
    "        policy_logits=dict(size=(T + 1, num_actions), dtype=torch.float32),\n",
    "        im_policy_logits=dict(size=(T + 1, num_actions), dtype=torch.float32),        \n",
    "        reset_policy_logits=dict(size=(T + 1, 2), dtype=torch.float32),\n",
    "        baseline=dict(size=(T + 1, num_rewards), dtype=torch.float32),\n",
    "        last_action=dict(size=(T + 1, 3 if not flags.flex_t else 4), dtype=torch.int64),\n",
    "        action=dict(size=(T + 1,), dtype=torch.int64),\n",
    "        im_action=dict(size=(T + 1,), dtype=torch.int64),        \n",
    "        reset_action=dict(size=(T + 1,), dtype=torch.int64), \n",
    "        reg_loss=dict(size=(T + 1,), dtype=torch.float32),  \n",
    "        cur_t=dict(size=(T + 1,), dtype=torch.int64),             \n",
    "        max_rollout_depth=dict(size=(T + 1,), dtype=torch.float32),  \n",
    "    )\n",
    "    if flags.flex_t:\n",
    "        specs.update(dict(\n",
    "            term_policy_logits=dict(size=(T + 1, 2), dtype=torch.float32),\n",
    "            term_action=dict(size=(T + 1,), dtype=torch.int64),)\n",
    "                     )\n",
    "    \n",
    "    buffers: Buffers = {key: [] for key in specs}\n",
    "    for _ in range(flags.num_buffers):\n",
    "        for key in buffers:\n",
    "            buffers[key].append(torch.empty(**specs[key]).share_memory_())\n",
    "    return buffers  \n",
    "\n",
    "def act(\n",
    "    flags,\n",
    "    actor_index: int,\n",
    "    free_queue: mp.SimpleQueue,\n",
    "    full_queue: mp.SimpleQueue,\n",
    "    actor_net: torch.nn.Module,\n",
    "    model: torch.nn.Module,\n",
    "    buffers: Buffers,\n",
    "    initial_agent_state_buffers,\n",
    "):\n",
    "    try:\n",
    "        logging.info(\"Actor %i started.\", actor_index)\n",
    "        timings = prof.Timings()  # Keep track of how fast things are.\n",
    "\n",
    "        gym_env = ModelWrapper(EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env), \n",
    "                               model=model, flags=flags)\n",
    "        seed = actor_index ^ int.from_bytes(os.urandom(4), byteorder=\"little\")\n",
    "        gym_env.seed(seed)\n",
    "        env = Environment(gym_env)\n",
    "        env_output = env.initial()\n",
    "        agent_state = actor_net.initial_state(batch_size=1)\n",
    "        agent_output, unused_state = actor_net(env_output, agent_state)\n",
    "        while True:\n",
    "            index = free_queue.get()\n",
    "            if index is None:\n",
    "                break\n",
    "\n",
    "            # Write old rollout end.\n",
    "            for key in env_output:           \n",
    "                if key in buffers: buffers[key][index][0, ...] = env_output[key]\n",
    "            for key in agent_output:\n",
    "                if key in buffers: buffers[key][index][0, ...] = agent_output[key]                    \n",
    "            for i, tensor in enumerate(agent_state):\n",
    "                initial_agent_state_buffers[index][i][...] = tensor\n",
    "\n",
    "            # Do new rollout.\n",
    "            for t in range(flags.unroll_length):\n",
    "                timings.reset()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    agent_output, agent_state = actor_net(env_output, agent_state)                    \n",
    "\n",
    "                timings.time(\"actor_net\")\n",
    "                \n",
    "                action = [agent_output['action'], agent_output['im_action'], agent_output['reset_action']]\n",
    "                if 'term_action' in agent_output: action.append(agent_output['term_action'])\n",
    "                action = torch.cat(action, dim=-1)\n",
    "                env_output = env.step(action.unsqueeze(0))\n",
    "\n",
    "                if flags.trun_bs:\n",
    "                    if env_output['truncated_done']: \n",
    "                        env_output['reward'] = env_output['reward'] + flags.im_discounting * agent_output['baseline']\n",
    "\n",
    "                timings.time(\"step\")\n",
    "\n",
    "                for key in env_output:\n",
    "                    if key in buffers:\n",
    "                        buffers[key][index][t + 1, ...] = env_output[key]\n",
    "                for key in agent_output:\n",
    "                    if key in buffers:\n",
    "                        buffers[key][index][t + 1, ...] = agent_output[key]\n",
    "\n",
    "                timings.time(\"write\")\n",
    "            full_queue.put(index)\n",
    "\n",
    "        if actor_index == 0:\n",
    "            logging.info(\"Actor %i: %s\", actor_index, timings.summary())\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass  # Return silently.\n",
    "    except Exception as e:\n",
    "        logging.error(\"Exception in worker process %i\", actor_index)\n",
    "        traceback.print_exc()\n",
    "        print()\n",
    "        raise e\n",
    "\n",
    "def compute_baseline_loss(advantages, masks_ls, c_ls):\n",
    "    assert len(masks_ls) == len(c_ls)\n",
    "    loss = 0.  \n",
    "    for mask, c in zip(masks_ls, c_ls):\n",
    "        loss = loss + 0.5 * torch.sum((advantages * (1 - mask)) ** 2) * c        \n",
    "    return loss\n",
    "    \n",
    "def compute_policy_gradient_loss(logits_ls, actions_ls, masks_ls, c_ls, advantages):\n",
    "    assert len(logits_ls) == len(actions_ls) == len(masks_ls) == len(c_ls)\n",
    "    loss = 0.    \n",
    "    for logits, actions, masks, c in zip(logits_ls, actions_ls, masks_ls, c_ls):\n",
    "        cross_entropy = F.nll_loss(\n",
    "            F.log_softmax(torch.flatten(logits, 0, 1), dim=-1),\n",
    "            target=torch.flatten(actions, 0, 1),\n",
    "            reduction=\"none\",)\n",
    "        cross_entropy = cross_entropy.view_as(advantages)\n",
    "        adv_cross_entropy = cross_entropy * advantages.detach()\n",
    "        loss = loss + torch.sum(adv_cross_entropy * (1-masks)) * c\n",
    "    return loss  \n",
    "\n",
    "def compute_entropy_loss(logits_ls, masks_ls, c_ls):\n",
    "    \"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"\n",
    "    loss = 0.\n",
    "    assert(len(logits_ls) == len(masks_ls) == len(c_ls))\n",
    "    for logits, masks, c in zip(logits_ls, masks_ls, c_ls):\n",
    "        policy = F.softmax(logits, dim=-1)\n",
    "        log_policy = F.log_softmax(logits, dim=-1)\n",
    "        ent = torch.sum(policy * log_policy, dim=-1) #* (1-masks)\n",
    "        loss = loss + torch.sum(ent) * c \n",
    "    return loss\n",
    "\n",
    "def action_log_probs(policy_logits, actions):\n",
    "    return -F.nll_loss(\n",
    "        F.log_softmax(torch.flatten(policy_logits, 0, -2), dim=-1),\n",
    "        torch.flatten(actions),\n",
    "        reduction=\"none\",\n",
    "    ).view_as(actions) \n",
    "  \n",
    "def from_logits(\n",
    "    behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "    discounts, rewards, values, bootstrap_value, clip_rho_threshold=1.0,\n",
    "    clip_pg_rho_threshold=1.0, lamb=1.0,):\n",
    "    \"\"\"V-trace for softmax policies.\"\"\"\n",
    "    assert(len(behavior_logits_ls) == len(target_logits_ls) == len(actions_ls) == len(masks_ls))\n",
    "    log_rhos = 0.       \n",
    "    for behavior_logits, target_logits, actions, masks in zip(behavior_logits_ls, \n",
    "             target_logits_ls, actions_ls, masks_ls):\n",
    "        behavior_log_probs = action_log_probs(behavior_logits, actions)        \n",
    "        target_log_probs = action_log_probs(target_logits, actions)\n",
    "        log_rho = target_log_probs - behavior_log_probs\n",
    "        log_rhos = log_rhos + log_rho * (1-masks)\n",
    "    \n",
    "    vtrace_returns = vtrace.from_importance_weights(\n",
    "        log_rhos=log_rhos,\n",
    "        discounts=discounts,\n",
    "        rewards=rewards,\n",
    "        values=values,\n",
    "        bootstrap_value=bootstrap_value,\n",
    "        clip_rho_threshold=clip_rho_threshold,\n",
    "        clip_pg_rho_threshold=clip_pg_rho_threshold,\n",
    "        lamb=lamb\n",
    "    )\n",
    "    return vtrace.VTraceFromLogitsReturns(\n",
    "        log_rhos=log_rhos,\n",
    "        behavior_action_log_probs=None,\n",
    "        target_action_log_probs=None,\n",
    "        **vtrace_returns._asdict(),\n",
    "    )  \n",
    "\n",
    "def learn(\n",
    "    flags,\n",
    "    actor_model,\n",
    "    model,\n",
    "    batch,\n",
    "    initial_agent_state,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    real_step,\n",
    "    lock=threading.Lock(),  # noqa: B008\n",
    "):\n",
    "    \"\"\"Performs a learning (optimization) step.\"\"\"\n",
    "    \n",
    "    with lock:                \n",
    "        learner_outputs, unused_state = model(batch, initial_agent_state)\n",
    "        #learner_outputs[\"im_policy_logits\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        #learner_outputs[\"reset_policy_logits\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        #learner_outputs[\"baseline\"].register_hook(lambda grad: grad / (flags.rec_t - 1))\n",
    "        \n",
    "        # Take final value function slice for bootstrapping.\n",
    "        bootstrap_value = learner_outputs[\"baseline\"][-1]        \n",
    "\n",
    "        # Move from obs[t] -> action[t] to action[t] -> obs[t].\n",
    "        batch = {key: tensor[1:] for key, tensor in batch.items()}\n",
    "        learner_outputs = {key: tensor[:-1] for key, tensor in learner_outputs.items()}\n",
    "        \n",
    "        T, B = batch[\"done\"].shape\n",
    "\n",
    "        rewards = batch[\"reward\"]\n",
    "        if flags.reward_clipping > 0:\n",
    "            clipped_rewards = torch.clamp(rewards, -flags.reward_clipping, flags.reward_clipping)\n",
    "        else:\n",
    "            clipped_rewards = rewards\n",
    "        \n",
    "        # compute advantage w.r.t real rewards\n",
    "        \n",
    "        discounts = (~batch[\"done\"]).float() * flags.im_discounting        \n",
    "        #discounts = (~batch[\"done\"]).float()\n",
    "        #discounts[batch[\"cur_t\"] == 0] = flags.discounting\n",
    "        \n",
    "        behavior_logits_ls = [batch[\"policy_logits\"], batch[\"im_policy_logits\"], batch[\"reset_policy_logits\"]]\n",
    "        target_logits_ls = [learner_outputs[\"policy_logits\"], learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "        actions_ls = [batch[\"action\"], batch[\"im_action\"], batch[\"reset_action\"]]        \n",
    "        im_mask = (batch[\"cur_t\"] == 0).float()\n",
    "        real_mask = 1 - im_mask\n",
    "        zero_mask = torch.zeros_like(im_mask)\n",
    "        masks_ls = [real_mask, im_mask, im_mask]                \n",
    "        c_ls = [flags.real_cost, flags.real_im_cost, flags.real_im_cost]\n",
    "           \n",
    "        if flags.flex_t:\n",
    "            behavior_logits_ls.append(batch[\"term_policy_logits\"])\n",
    "            target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "            actions_ls.append(batch[\"term_action\"])\n",
    "            masks_ls.append(zero_mask)\n",
    "            c_ls.append(flags.real_im_cost)\n",
    "\n",
    "        vtrace_returns = from_logits(\n",
    "            behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "            discounts=discounts,\n",
    "            rewards=clipped_rewards[:, :, 0],\n",
    "            values=learner_outputs[\"baseline\"][:, :, 0],\n",
    "            bootstrap_value=bootstrap_value[:, 0],\n",
    "            lamb=flags.lamb\n",
    "        )        \n",
    "        \n",
    "        pg_loss = compute_policy_gradient_loss(target_logits_ls, actions_ls, masks_ls, c_ls, vtrace_returns.pg_advantages, )  \n",
    "        \n",
    "        baseline_loss = flags.baseline_cost * compute_baseline_loss(\n",
    "            vtrace_returns.vs - learner_outputs[\"baseline\"][:, :, 0], \n",
    "            masks_ls = [real_mask, im_mask], c_ls = [flags.real_cost, flags.real_im_cost])\n",
    "       \n",
    "        # compute advantage w.r.t imagainary rewards\n",
    "\n",
    "        if flags.reward_type == 1:\n",
    "            if flags.reward_carry:                \n",
    "                discounts = (~batch[\"done\"]).float() * flags.im_discounting \n",
    "            else:\n",
    "                discounts = (~(batch[\"cur_t\"] == 0)).float() * flags.im_discounting        \n",
    "            behavior_logits_ls = [batch[\"im_policy_logits\"], batch[\"reset_policy_logits\"]]\n",
    "            target_logits_ls = [learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "            actions_ls = [batch[\"im_action\"], batch[\"reset_action\"]] \n",
    "            masks_ls = [im_mask, im_mask]  \n",
    "            c_ls = [flags.im_cost, flags.im_cost]\n",
    "            \n",
    "            if flags.flex_t:\n",
    "                behavior_logits_ls.append(batch[\"term_policy_logits\"])\n",
    "                target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "                actions_ls.append(batch[\"term_action\"])\n",
    "                masks_ls.append(zero_mask)\n",
    "                c_ls.append(flags.im_cost)\n",
    "            \n",
    "            vtrace_returns = from_logits(\n",
    "                behavior_logits_ls, target_logits_ls, actions_ls, masks_ls,\n",
    "                discounts=discounts,\n",
    "                rewards=clipped_rewards[:, :, 1],\n",
    "                values=learner_outputs[\"baseline\"][:, :, 1],\n",
    "                bootstrap_value=bootstrap_value[:, 1],\n",
    "                lamb=flags.lamb\n",
    "            )\n",
    "            im_pg_loss = compute_policy_gradient_loss(target_logits_ls, actions_ls, masks_ls, c_ls, vtrace_returns.pg_advantages, )   \n",
    "            im_baseline_loss = flags.baseline_cost * compute_baseline_loss(\n",
    "                vtrace_returns.vs - learner_outputs[\"baseline\"][:, :, 1], masks_ls = [zero_mask], c_ls = [flags.im_cost])     \n",
    "            \n",
    "        target_logits_ls = [learner_outputs[\"policy_logits\"], learner_outputs[\"im_policy_logits\"], learner_outputs[\"reset_policy_logits\"]]\n",
    "        masks_ls = [real_mask, im_mask, im_mask]    \n",
    "        im_ent_c = flags.im_entropy_cost * (flags.real_im_cost + (flags.im_cost if flags.reward_type == 1 else 0))\n",
    "        c_ls = [flags.entropy_cost * flags.real_cost, im_ent_c, im_ent_c]\n",
    "        if flags.flex_t:\n",
    "            target_logits_ls.append(learner_outputs[\"term_policy_logits\"])\n",
    "            masks_ls.append(zero_mask)\n",
    "            c_ls.append(im_ent_c)        \n",
    "        entropy_loss = compute_entropy_loss(target_logits_ls, masks_ls, c_ls)       \n",
    "            \n",
    "\n",
    "        reg_loss = flags.reg_cost * torch.sum(learner_outputs[\"reg_loss\"])\n",
    "        total_loss = pg_loss + baseline_loss + entropy_loss + reg_loss         \n",
    "              \n",
    "        if flags.reward_type == 1:\n",
    "            total_loss = total_loss + im_pg_loss + im_baseline_loss\n",
    "        \n",
    "        episode_returns = batch[\"episode_return\"][batch[\"done\"]][:, 0]  \n",
    "        max_rollout_depth = (batch[\"max_rollout_depth\"][batch[\"cur_t\"] == 0]).detach().cpu().numpy()\n",
    "        max_rollout_depth = np.average(max_rollout_depth) if len (max_rollout_depth) > 0 else 0.        \n",
    "        real_step = torch.sum(batch[\"cur_t\"]==0).item()\n",
    "        stats = {\n",
    "            \"episode_returns\": tuple(episode_returns.detach().cpu().numpy()),\n",
    "            \"mean_episode_return\": torch.mean(episode_returns).item(),\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"pg_loss\": pg_loss.item(),\n",
    "            \"baseline_loss\": baseline_loss.item(),\n",
    "            \"entropy_loss\": entropy_loss.item(),\n",
    "            \"reg_loss\": reg_loss.item(),\n",
    "            \"max_rollout_depth\": max_rollout_depth,\n",
    "            \"real_step\": real_step,\n",
    "            \"mean_plan_step\": T * B / max(real_step, 1),\n",
    "        }\n",
    "        \n",
    "        if flags.reward_type == 1:            \n",
    "            im_episode_returns = batch[\"episode_return\"][batch[\"cur_t\"] == 0][:, 1]\n",
    "            stats[\"im_episode_returns\"] = tuple(im_episode_returns.detach().cpu().numpy())\n",
    "            stats[\"im_pg_loss\"] = im_pg_loss.item()\n",
    "            stats[\"im_baseline_loss\"] = im_baseline_loss.item()   \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimize_params = optimizer.param_groups[0]['params']\n",
    "        if flags.grad_norm_clipping > 0:\n",
    "            total_norm = nn.utils.clip_grad_norm_(optimize_params, flags.grad_norm_clipping)\n",
    "        else:\n",
    "            total_norm = 0.\n",
    "            parameters = [p for p in optimize_params if p.grad is not None and p.requires_grad]\n",
    "            for p in parameters:\n",
    "                param_norm = p.grad.detach().data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** 0.5\n",
    "        stats[\"total_norm\"] = total_norm\n",
    "        \n",
    "        optimizer.step()\n",
    "        if not flags.flex_t:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.last_epoch = real_step - 1  # scheduler does not support setting epoch directly\n",
    "            scheduler.step() \n",
    "\n",
    "        actor_model.load_state_dict(model.state_dict())\n",
    "        return stats  \n",
    "\n",
    "# Wrap the environment with a model\n",
    "\n",
    "def _format_frame(frame, bsz=None):\n",
    "    if type(frame) == np.ndarray:\n",
    "        frame = torch.from_numpy(frame).float()\n",
    "    if bsz is not None:\n",
    "        return frame.view((1,) + frame.shape)\n",
    "    else:\n",
    "        return frame.view((1, 1) + frame.shape)\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, gym_env):\n",
    "        self.gym_env = gym_env\n",
    "        self.episode_return = None\n",
    "        self.episode_step = None\n",
    "\n",
    "    def initial(self):\n",
    "        initial_reward = torch.zeros(1, 1)\n",
    "        # This supports only single-tensor actions ATM.\n",
    "        initial_last_action = torch.zeros(1, 1, dtype=torch.int64)\n",
    "        self.episode_return = torch.zeros(1, 1, 1)\n",
    "        self.episode_step = torch.zeros(1, 1, dtype=torch.int32)\n",
    "        initial_done = torch.ones(1, 1, dtype=torch.bool)\n",
    "        initial_frame = _format_frame(self.gym_env.reset())\n",
    "        return dict(\n",
    "            frame=initial_frame,\n",
    "            reward=initial_reward,\n",
    "            done=initial_done,\n",
    "            truncated_done=torch.tensor(0).view(1, 1).bool(),\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=torch.tensor(0).view(1, 1),\n",
    "            last_action=initial_last_action,\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        frame, reward, done, unused_info = self.gym_env.step(action[0,0].cpu().detach().numpy())     \n",
    "        self.episode_step += 1\n",
    "        self.episode_return = self.episode_return + torch.tensor(reward).unsqueeze(0).unsqueeze(0)\n",
    "        episode_step = self.episode_step\n",
    "        episode_return = self.episode_return.clone()\n",
    "        if done:\n",
    "            frame = self.gym_env.reset()\n",
    "            self.episode_return = torch.zeros(1, 1, 1)\n",
    "            self.episode_step = torch.zeros(1, 1, dtype=torch.int32)        \n",
    "        frame = _format_frame(frame)\n",
    "        reward = torch.tensor(reward).view(1, 1, -1)\n",
    "        done = torch.tensor(done).view(1, 1)\n",
    "        truncated_done = 'TimeLimit.truncated' in unused_info and unused_info['TimeLimit.truncated']\n",
    "        truncated_done = torch.tensor(truncated_done).view(1, 1)\n",
    "        cur_t = torch.tensor(unused_info[\"cur_t\"]).view(1, 1)\n",
    "        if cur_t == 0 and self.episode_return.shape[2] > 1:\n",
    "            self.episode_return[:, :, 1] = 0.\n",
    "        if 'max_rollout_depth' in unused_info:\n",
    "            max_rollout_depth = torch.tensor(unused_info[\"max_rollout_depth\"]).view(1, 1)\n",
    "        else:\n",
    "            max_rollout_depth = torch.tensor(0.).view(1, 1)\n",
    "        \n",
    "        return dict(\n",
    "            frame=frame,\n",
    "            reward=reward,\n",
    "            done=done,\n",
    "            truncated_done=truncated_done,          \n",
    "            episode_return=episode_return,\n",
    "            episode_step=episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=action,\n",
    "            max_rollout_depth=max_rollout_depth\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        self.gym_env.close()\n",
    "\n",
    "    def clone_state(self):\n",
    "        state = self.gym_env.clone_state()\n",
    "        state[\"env_episode_return\"] = self.episode_return.clone()\n",
    "        state[\"env_episode_step\"] = self.episode_step.clone()\n",
    "        return state\n",
    "        \n",
    "    def restore_state(self, state):\n",
    "        self.episode_return = state[\"env_episode_return\"].clone()\n",
    "        self.episode_step = state[\"env_episode_step\"].clone()\n",
    "        self.gym_env.restore_state(state)\n",
    "        \n",
    "class Vec_Environment:\n",
    "    # deprecated\n",
    "    def __init__(self, gym_env, bsz):\n",
    "        self.gym_env = gym_env\n",
    "        self.bsz = bsz\n",
    "        self.episode_return = torch.zeros(1, self.bsz)\n",
    "        self.episode_step = torch.zeros(1, self.bsz)        \n",
    "\n",
    "    def initial(self):\n",
    "        initial_reward = torch.zeros(1, self.bsz, 1)\n",
    "        # This supports only single-tensor actions ATM.\n",
    "        initial_last_action = torch.zeros(1, self.bsz, dtype=torch.int64)\n",
    "        self.episode_return = torch.zeros(1, self.bsz)\n",
    "        self.episode_step = torch.zeros(1, self.bsz, dtype=torch.int32)\n",
    "        initial_done = torch.ones(1, self.bsz, dtype=torch.uint8)\n",
    "        initial_frame = _format_frame(self.gym_env.reset(), self.bsz)\n",
    "        cur_t = torch.zeros(1, self.bsz)\n",
    "        \n",
    "        return dict(\n",
    "            frame=initial_frame,\n",
    "            reward=initial_reward,\n",
    "            done=initial_done,\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=initial_last_action,\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        frame, reward, done, unused_info = self.gym_env.step(action.detach().cpu().numpy())   \n",
    "        \n",
    "        self.episode_step += 1\n",
    "        self.episode_return += torch.Tensor(reward).unsqueeze(0)\n",
    "        \n",
    "        done = torch.tensor(done).view(1, self.bsz)\n",
    "        truncated_done = ['TimeLimit.truncated' in x and x['TimeLimit.truncated'] for x in unused_info]\n",
    "        truncated_done = torch.tensor(truncated_done).view(1, self.bsz)\n",
    "        \n",
    "        self.episode_return = (~done).float().unsqueeze(-1) * self.episode_return\n",
    "        self.episode_step = (~done).float() * self.episode_step\n",
    "        \n",
    "        frame = _format_frame(frame, self.bsz)\n",
    "        reward = torch.tensor(reward).view(1, self.bsz).float()\n",
    "        \n",
    "        cur_t = [x[\"cur_t\"] for x in unused_info]  \n",
    "        cur_t = torch.tensor(cur_t).view(1, self.bsz)\n",
    "        \n",
    "        return dict(\n",
    "            frame=frame,\n",
    "            reward=reward,\n",
    "            done=done,\n",
    "            truncated_done=truncated_done,\n",
    "            episode_return=self.episode_return,\n",
    "            episode_step=self.episode_step,\n",
    "            cur_t=cur_t,\n",
    "            last_action=action.unsqueeze(0),\n",
    "        )\n",
    "    \n",
    "    def clone_state(self):        \n",
    "        state = {}\n",
    "        state[\"env_episode_return\"] = self.episode_return.clone()\n",
    "        state[\"env_episode_step\"] = self.episode_step.clone()\n",
    "        for n, k in enumerate(self.gym_env.envs): \n",
    "            state[\"env_%d\"%n] = k.clone_state()\n",
    "        return state\n",
    "        \n",
    "    def restore_state(self, state):\n",
    "        self.episode_return = state[\"env_episode_return\"].clone()\n",
    "        self.episode_step = state[\"env_episode_step\"].clone()\n",
    "        for n, k in enumerate(self.gym_env.envs): \n",
    "            k.restore_state(state[\"env_%d\"%n])\n",
    "\n",
    "    def close(self):\n",
    "        self.gym_env.close()  \n",
    "\n",
    "class Actor_net(nn.Module):    \n",
    "    def __init__(self, obs_shape, num_actions, flags):\n",
    "\n",
    "        super(Actor_net, self).__init__()\n",
    "        self.obs_shape = obs_shape\n",
    "        self.num_actions = num_actions  \n",
    "        \n",
    "        self.tran_t = flags.tran_t                   # number of recurrence of RNN        \n",
    "        self.tran_mem_n = flags.tran_mem_n           # size of memory for the attn modules\n",
    "        self.tran_layer_n = flags.tran_layer_n       # number of layers\n",
    "        self.tran_lstm = flags.tran_lstm             # to use lstm or not\n",
    "        self.tran_lstm_no_attn = flags.tran_lstm_no_attn  # to use attention in lstm or not\n",
    "        self.tran_lstm_new = flags.tran_lstm_new\n",
    "        self.attn_mask_b = flags.tran_attn_b         # atention bias for current position\n",
    "        self.tran_norm_first = flags.tran_norm_first # to use norm first in transformer (not on LSTM)\n",
    "        self.tran_ff_n = flags.tran_ff_n             # number of dim of ff in transformer (not on LSTM)        \n",
    "        self.tran_skip = flags.tran_skip             # whether to add skip connection\n",
    "        self.conv_out = flags.tran_dim               # size of transformer / LSTM embedding dim        \n",
    "        self.no_mem = flags.no_mem                   # whether to earse real memory at the end of planning stage\n",
    "        self.num_rewards = flags.num_rewards         # dim of rewards (1 for vanilla; 2 for planning rewards)\n",
    "        self.flex_t = flags.flex_t                   # whether to output the terminate action\n",
    "        self.flex_t_term_b = flags.flex_t_term_b     # bias added to the logit of terminating\n",
    "        \n",
    "        self.conv_out_hw = 1   \n",
    "        self.d_model = self.conv_out\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=self.obs_shape[0], out_channels=self.conv_out//2, kernel_size=1, stride=1)        \n",
    "        self.conv2 = nn.Conv2d(in_channels=self.conv_out//2, out_channels=self.conv_out, kernel_size=1, stride=1)        \n",
    "        self.frame_conv = torch.nn.Sequential(self.conv1, nn.ReLU(), self.conv2, nn.ReLU())\n",
    "        self.env_input_size = self.conv_out\n",
    "        d_in = self.env_input_size + self.d_model \n",
    "        \n",
    "        if self.tran_lstm:\n",
    "            self.core = ConvAttnLSTM(h=self.conv_out_hw, w=self.conv_out_hw,\n",
    "                                 input_dim=d_in-self.d_model, hidden_dim=self.d_model,\n",
    "                                 kernel_size=1, num_layers=self.tran_layer_n,\n",
    "                                 num_heads=8, mem_n=self.tran_mem_n, attn=not self.tran_lstm_no_attn,\n",
    "                                 attn_mask_b=self.attn_mask_b, legacy= not self.tran_lstm_new)\n",
    "        else:            \n",
    "            self.core = ConvTransformerRNN(d_in=d_in,\n",
    "                                       h=self.conv_out_hw, w=self.conv_out_hw, d_model=self.d_model, \n",
    "                                       num_heads=8, dim_feedforward=self.tran_ff_n, \n",
    "                                       mem_n=self.tran_mem_n, norm_first=self.tran_norm_first,\n",
    "                                       num_layers=self.tran_layer_n, rpos=True, conv=False)   \n",
    "                         \n",
    "        \n",
    "        if self.tran_skip:\n",
    "            rnn_out_size = self.conv_out_hw * self.conv_out_hw * (self.d_model + self.env_input_size)\n",
    "        else:\n",
    "            rnn_out_size = self.conv_out_hw * self.conv_out_hw * self.d_model\n",
    "                \n",
    "        self.fc = nn.Linear(rnn_out_size, 256)        \n",
    "        \n",
    "        self.im_policy = nn.Linear(256, self.num_actions)        \n",
    "        self.policy = nn.Linear(256, self.num_actions)        \n",
    "        self.baseline = nn.Linear(256, self.num_rewards)        \n",
    "        self.reset = nn.Linear(256, 2)        \n",
    "        \n",
    "        if self.flex_t: self.term = nn.Linear(256, 2)        \n",
    "        \n",
    "        print(\"actor size: \", sum(p.numel() for p in self.parameters()))\n",
    "        #for k, v in self.named_parameters(): print(k, v.numel())   \n",
    "\n",
    "    def initial_state(self, batch_size):\n",
    "        state = self.core.init_state(batch_size) + (torch.zeros(1, batch_size, \n",
    "               self.env_input_size, self.conv_out_hw, self.conv_out_hw),)\n",
    "        return state\n",
    "\n",
    "    def forward(self, obs, core_state=(), debug=False):\n",
    "        # one-step forward for the actor\n",
    "        # input / done shape x: T x B x C x 1 x 1 / B x C x 1 x 1\n",
    "        # only supports T = 1 at the moment; all output does not have T dim.        \n",
    "        \n",
    "        x = obs[\"frame\"]\n",
    "        done = obs[\"done\"]\n",
    "        \n",
    "        if len(x.shape) == 4: x = x.unsqueeze(0)\n",
    "        if len(done.shape) == 1: done = done.unsqueeze(0)  \n",
    "            \n",
    "        T, B, *_ = x.shape\n",
    "        x = torch.flatten(x, 0, 1)  # Merge time and batch.  \n",
    "        env_input = self.frame_conv(x)                \n",
    "        core_input = env_input.view(T, B, -1, self.conv_out_hw, self.conv_out_hw)\n",
    "        core_output_list = []\n",
    "        notdone = ~(done.bool())\n",
    "        \n",
    "        for n, (input, nd) in enumerate(zip(core_input.unbind(), notdone.unbind())):       \n",
    "            if self.no_mem and obs[\"cur_t\"][n, 0] == 0:\n",
    "                core_state = self.initial_state(B)\n",
    "                core_state = tuple(v.to(x.device) for v in core_state)\n",
    "                \n",
    "            # Input shape: B, self.conv_out + self.num_actions + 1, H, W\n",
    "            for t in range(self.tran_t):                \n",
    "                if t > 0: nd = torch.ones(B).to(x.device).bool()                    \n",
    "                nd = nd.view(-1)      \n",
    "                output, core_state = self.core(input, core_state, nd, nd) # output shape: 1, B, core_output_size \n",
    "                \n",
    "            last_input = input   \n",
    "            core_output_list.append(output)\n",
    "                                   \n",
    "        core_output = torch.cat(core_output_list)  \n",
    "        if self.tran_skip: core_output = torch.concat([core_output, core_input], dim=-3)\n",
    "        core_output = torch.flatten(core_output, 0, 1)        \n",
    "        core_output = F.relu(self.fc(torch.flatten(core_output, start_dim=1)))   \n",
    "        \n",
    "        policy_logits = self.policy(core_output)\n",
    "        im_policy_logits = self.im_policy(core_output)\n",
    "        reset_policy_logits = self.reset(core_output)\n",
    "        \n",
    "        if self.flex_t: \n",
    "            term_policy_logits = self.term(core_output)            \n",
    "            term_policy_logits[:, 1] += self.flex_t_term_b\n",
    "        \n",
    "        action = torch.multinomial(F.softmax(policy_logits, dim=1), num_samples=1)\n",
    "        im_action = torch.multinomial(F.softmax(im_policy_logits, dim=1), num_samples=1)\n",
    "        reset_action = torch.multinomial(F.softmax(reset_policy_logits, dim=1), num_samples=1)\n",
    "        if self.flex_t: term_action = torch.multinomial(F.softmax(term_policy_logits, dim=1), num_samples=1)\n",
    "                \n",
    "        baseline = self.baseline(core_output)\n",
    "                   \n",
    "        reg_loss = (1e-3 * torch.sum(policy_logits**2, dim=-1) / 2 + \n",
    "                    1e-5 * torch.sum(core_output**2, dim=-1) / 2)\n",
    "        reg_loss = reg_loss.view(T, B)\n",
    "        \n",
    "        policy_logits = policy_logits.view(T, B, self.num_actions)\n",
    "        im_policy_logits = im_policy_logits.view(T, B, self.num_actions)\n",
    "        reset_policy_logits = reset_policy_logits.view(T, B, 2)\n",
    "        if self.flex_t: term_policy_logits = term_policy_logits.view(T, B, 2)\n",
    "            \n",
    "        \n",
    "        action = action.view(T, B)      \n",
    "        im_action = im_action.view(T, B)      \n",
    "        reset_action = reset_action.view(T, B)             \n",
    "        if self.flex_t: term_action = term_action.view(T, B)\n",
    "        baseline = baseline.view(T, B, self.num_rewards)\n",
    "        \n",
    "        ret_dict = dict(policy_logits=policy_logits,                         \n",
    "                        im_policy_logits=im_policy_logits,                         \n",
    "                        reset_policy_logits=reset_policy_logits,     \n",
    "                        action=action,     \n",
    "                        im_action=im_action,\n",
    "                        reset_action=reset_action,\n",
    "                        baseline=baseline, \n",
    "                        reg_loss=reg_loss, )\n",
    "        \n",
    "        if self.flex_t: ret_dict.update(dict(term_policy_logits=term_policy_logits,    \n",
    "                                             term_action=term_action))\n",
    "        return (ret_dict, core_state) \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, max_len=200):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2) * (-math.log(10000.0) / dim))\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, step) :\n",
    "        # step: int Tensor, shape [batch_size]\n",
    "        step = torch.clamp(step, 0, self.max_len-1)\n",
    "        return self.pe[step, :]    \n",
    "        \n",
    "class ModelWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, model, flags):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        \n",
    "        self.env = env\n",
    "        self.model = model                \n",
    "        self.rec_t = flags.rec_t        \n",
    "        self.flex_t = flags.flex_t \n",
    "        self.flex_t_cost = flags.flex_t_cost         \n",
    "        self.flex_t_cost_m = flags.flex_t_cost_m\n",
    "        self.flex_t_cost_type = flags.flex_t_cost_type\n",
    "        self.discounting = flags.discounting\n",
    "        self.stat_pos_encode = flags.stat_pos_encode\n",
    "        self.stat_pos_encode_dim = flags.stat_pos_encode_dim\n",
    "        self.reward_type = flags.reward_type    \n",
    "        self.no_mem = flags.no_mem\n",
    "        self.perfect_model = flags.perfect_model\n",
    "        self.reset_m = flags.reset_m\n",
    "        self.tree_carry = flags.tree_carry\n",
    "        self.tree_vb = flags.tree_vb\n",
    "        self.thres_carry = flags.thres_carry        \n",
    "        self.thres_discounting = flags.thres_discounting\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.root_node = None\n",
    "            \n",
    "        if not self.flex_t:\n",
    "            obs_n = 9 + num_actions * 10 + (self.rec_t if not self.stat_pos_encode else (2 * self.stat_pos_encode_dim))\n",
    "        else:\n",
    "            obs_n = 10 + num_actions * 10  + (1 if not self.stat_pos_encode else (2 * self.stat_pos_encode_dim))          \n",
    "        if self.stat_pos_encode:\n",
    "            obs_n = obs_n - num_actions * 2 + self.stat_pos_encode_dim * num_actions * 2\n",
    "        \n",
    "        self.observation_space = gym.spaces.Box(\n",
    "          low=-np.inf, high=np.inf, shape=(obs_n, 1, 1), dtype=float)\n",
    "        self.model.train(False)        \n",
    "        \n",
    "        self.max_rollout_depth = 0.\n",
    "        self.thres = None\n",
    "        self.root_max_q = None\n",
    "        \n",
    "        if self.stat_pos_encode:\n",
    "            self.pos = PositionalEncoding(dim=self.stat_pos_encode_dim, max_len=self.rec_t)\n",
    "        else:\n",
    "            self.pos = None\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        x = self.env.reset()\n",
    "        self.cur_t = 0        \n",
    "        out = self.use_model(x, 0., 0, self.cur_t, reset=1., term=0., done=False)\n",
    "        if self.reward_type == 1:\n",
    "            self.last_root_max_q = self.root_max_q\n",
    "        return out.unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    def step(self, action):  \n",
    "        if not self.flex_t:\n",
    "            re_action, im_action, reset = action\n",
    "            term = None\n",
    "        else:\n",
    "            re_action, im_action, reset, term = action\n",
    "        info = {}\n",
    "        info[\"max_rollout_depth\"] = self.max_rollout_depth\n",
    "        if (not self.flex_t and self.cur_t < self.rec_t - 1) or (\n",
    "            self.flex_t and self.cur_t < self.rec_t - 1 and not term):\n",
    "          self.cur_t += 1\n",
    "          out = self.use_model(None, None, im_action, self.cur_t, reset=reset, term=term, done=False)          \n",
    "          if self.reward_type == 0:\n",
    "            r = np.array([0.])\n",
    "          else:\n",
    "            if self.flex_t:\n",
    "                if self.flex_t_cost_type == 0:\n",
    "                    flex_t_cost = self.flex_t_cost\n",
    "                elif self.flex_t_cost_type == 1:\n",
    "                    flex_t_cost = exp_scale(self.cur_t, 1e-7, self.flex_t_cost, self.rec_t, self.flex_t_cost_m)\n",
    "            else:                \n",
    "                flex_t_cost = 0.\n",
    "            r = np.array([0., (self.root_max_q - self.last_root_max_q - flex_t_cost).item()], dtype=np.float32)\n",
    "          done = False\n",
    "          info['cur_t'] = self.cur_t   \n",
    "        else:\n",
    "          self.cur_t = 0\n",
    "          if self.perfect_model: self.env.restore_state(self.root_node.encoded)\n",
    "          x, r, done, info_ = self.env.step(re_action)                    \n",
    "          out = self.use_model(x, r, re_action, self.cur_t, reset=1., term=term, done=done) \n",
    "          info.update(info_)\n",
    "          info['cur_t'] = self.cur_t\n",
    "          if self.reward_type == 0:\n",
    "            r = np.array([r])\n",
    "          else:\n",
    "            r = np.array([r, 0.], dtype=np.float32)   \n",
    "        if self.reward_type == 1:\n",
    "            self.last_root_max_q = self.root_max_q   \n",
    "        \n",
    "        return out.unsqueeze(-1).unsqueeze(-1), r, done, info        \n",
    "        \n",
    "    def use_model(self, x, r, a, cur_t, reset, term, done=False):\n",
    "        with torch.no_grad():\n",
    "            if cur_t == 0:\n",
    "                self.rollout_depth = 0.\n",
    "                self.unexpand_rollout_depth = 0.\n",
    "                self.pass_unexpand = False\n",
    "                self.max_rollout_depth = 0.\n",
    "                \n",
    "                if self.root_max_q is not None:\n",
    "                    self.thres = (self.root_max_q - r) / self.discounting\n",
    "                if done:\n",
    "                    self.thres = None\n",
    "                \n",
    "                if self.no_mem:\n",
    "                    re_action = 0\n",
    "                    re_reward = torch.tensor([0.], dtype=torch.float32)                \n",
    "                else:\n",
    "                    re_action = a                \n",
    "                    re_reward = torch.tensor([r], dtype=torch.float32)                \n",
    "                \n",
    "                x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "                self.x = self.x_ = x_tensor\n",
    "                a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions)                \n",
    "                _, vs, logits, encodeds = self.model(x_tensor, a_tensor.unsqueeze(0), one_hot=True) \n",
    "                \n",
    "                if self.perfect_model: \n",
    "                    encoded = self.clone_state()\n",
    "                else:\n",
    "                    encoded=encodeds[-1]\n",
    "                \n",
    "                if (not self.tree_carry or self.root_node is None or \n",
    "                    not self.root_node.children[a].expanded() or done):\n",
    "                \n",
    "                    self.root_node = Node(parent=None, action=re_action, logit=None, \n",
    "                                          num_actions=self.num_actions,\n",
    "                                          discounting=self.discounting,\n",
    "                                          rec_t=self.rec_t)\n",
    "                    self.root_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                          v=vs[-1, 0].unsqueeze(-1), logits=logits[-1, 0],\n",
    "                                          encoded=encoded)\n",
    "                else:\n",
    "                    self.root_node = self.root_node.children[a]\n",
    "                    self.root_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                          v=vs[-1, 0].unsqueeze(-1), logits=logits[-1, 0],\n",
    "                                          encoded=encoded, override=True)\n",
    "                    self.parent = None\n",
    "                \n",
    "                if self.thres is not None:\n",
    "                    self.thres = self.thres_discounting * self.thres + (1 - self.thres_discounting) * vs[-1, 0].item()\n",
    "                \n",
    "                self.root_node.visit()\n",
    "                self.cur_node = self.root_node\n",
    "                \n",
    "            else:\n",
    "                self.rollout_depth += 1                    \n",
    "                self.max_rollout_depth = max(self.max_rollout_depth, self.rollout_depth)\n",
    "                next_node = self.cur_node.children[a]\n",
    "                \n",
    "                if not next_node.expanded():\n",
    "                    self.pass_unexpand = True\n",
    "                    a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions) \n",
    "                    if not self.perfect_model:\n",
    "                        rs, vs, logits, encodeds = self.model.forward_encoded(self.cur_node.encoded, \n",
    "                            a_tensor.unsqueeze(0), one_hot=True)\n",
    "                        next_node.expand(r=rs[-1, 0].unsqueeze(-1), v=vs[-1, 0].unsqueeze(-1), \n",
    "                                     logits=logits[-1, 0], encoded=encodeds[-1])\n",
    "                    else:                        \n",
    "                        if \"done\" not in self.cur_node.encoded:                            \n",
    "                            self.env.restore_state(self.cur_node.encoded)                        \n",
    "                            x, r, done, info = self.env.step(a)                        \n",
    "                            encoded = self.env.clone_state()\n",
    "                            if done: encoded[\"done\"] = True                        \n",
    "                            x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "                            self.x_ = x_tensor\n",
    "                            a_tensor = F.one_hot(torch.tensor(a, dtype=torch.long).unsqueeze(0), self.num_actions) \n",
    "                            _, vs, logits, _ = self.model(x_tensor, a_tensor.unsqueeze(0), one_hot=True)                        \n",
    "\n",
    "                            if done:\n",
    "                                v = torch.tensor([0.], dtype=torch.float32)\n",
    "                            else:\n",
    "                                v = vs[-1, 0].unsqueeze(-1)\n",
    "\n",
    "                            next_node.expand(r=torch.tensor([r], dtype=torch.float32), \n",
    "                                             v=v, \n",
    "                                             logits=logits[-1, 0], \n",
    "                                             encoded=encoded)\n",
    "                        else:\n",
    "                            logits = torch.concat([x.logit for x in self.cur_node.children])  \n",
    "                            next_node.expand(r=torch.tensor([0.], dtype=torch.float32), \n",
    "                                             v=torch.tensor([0.], dtype=torch.float32),\n",
    "                                             logits=logits, \n",
    "                                             encoded=self.cur_node.encoded)                            \n",
    "                            \n",
    "                next_node.visit()\n",
    "                self.cur_node = next_node\n",
    "            \n",
    "            if self.pass_unexpand:                 \n",
    "                self.unexpand_rollout_depth += 1    \n",
    "                if self.reset_m >= 0 and self.unexpand_rollout_depth > self.reset_m:\n",
    "                    reset = True\n",
    "            \n",
    "            root_node_stat = self.root_node.stat(pos=self.pos)\n",
    "            cur_node_stat = self.cur_node.stat(pos=self.pos)                        \n",
    "            reset = torch.tensor([reset], dtype=torch.float32)            \n",
    "            depc = torch.tensor([self.discounting ** (self.rollout_depth-1)])\n",
    "            \n",
    "            root_trail_r = self.root_node.trail_r / self.discounting\n",
    "            root_rollout_q = self.root_node.rollout_q / self.discounting\n",
    "            if self.tree_vb != 0:\n",
    "                rollout_qs = [x + (self.tree_vb if n == 0 else 0.) for n, x in enumerate(self.root_node.rollout_qs)]\n",
    "            else:\n",
    "                rollout_qs = self.root_node.rollout_qs\n",
    "            root_max_q = torch.max(torch.concat(rollout_qs)).unsqueeze(-1) / self.discounting\n",
    "            if self.thres_carry and self.thres is not None:\n",
    "                root_max_q = torch.max(root_max_q, self.thres)\n",
    "                \n",
    "            if self.stat_pos_encode:\n",
    "                time = torch.concat([self.pos(torch.tensor([cur_t]).long()), self.pos(torch.tensor([self.rollout_depth]).long())], dim=-1)\n",
    "                time = time[0]\n",
    "            else:\n",
    "                if not self.flex_t:\n",
    "                    time = F.one_hot(torch.tensor(cur_t).long(), self.rec_t)\n",
    "                else:\n",
    "                    time = torch.tensor([self.discounting ** (self.cur_t)])                    \n",
    "                \n",
    "            if not self.flex_t:\n",
    "                ret_list = [root_node_stat, cur_node_stat, reset, time, depc, root_trail_r, root_rollout_q, root_max_q]\n",
    "            else:\n",
    "                term = torch.tensor([term], dtype=torch.float32)                            \n",
    "                ret_list = [root_node_stat, cur_node_stat, root_trail_r, root_rollout_q, root_max_q, reset, depc, term, time]\n",
    "                \n",
    "            out = torch.concat(ret_list, dim=-1)  \n",
    "            self.last_node = self.cur_node     \n",
    "            \n",
    "            self.root_max_q = root_max_q\n",
    "            self.ret_dict = {\"v0\": self.root_node.ret_dict[\"v\"].unsqueeze(0),\n",
    "                             \"q_s_a\": self.root_node.ret_dict[\"child_rollout_qs_mean\"].unsqueeze(0),\n",
    "                             \"max_q_s_a\": self.root_node.ret_dict[\"child_rollout_qs_max\"].unsqueeze(0),\n",
    "                             \"n_s_a\": self.root_node.child_rollout_ns.unsqueeze(0),\n",
    "                             \"logit0\": self.root_node.ret_dict[\"child_logits\"].unsqueeze(0),\n",
    "                             \"logit\": self.cur_node.ret_dict[\"child_logits\"].unsqueeze(0),\n",
    "                             \"reset\": reset,\n",
    "                             \"term\": term}\n",
    "            \n",
    "            if self.thres is not None:\n",
    "                self.ret_dict[\"thres\"] = self.thres\n",
    "            \n",
    "            if reset:\n",
    "                self.rollout_depth = 0\n",
    "                self.unexpand_rollout_depth = 0.\n",
    "                self.cur_node = self.root_node\n",
    "                self.cur_node.visit()\n",
    "                self.pass_unexpand = False\n",
    "                \n",
    "            return out\n",
    "                \n",
    "class Node:\n",
    "    def __init__(self, parent, action, logit, num_actions, discounting, rec_t):        \n",
    "        \n",
    "        self.action = F.one_hot(torch.tensor(action).long(), num_actions) # shape (1, num_actions)        \n",
    "        self.r = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.v = torch.tensor([0.], dtype=torch.float32)            \n",
    "        self.logit = logit # shape (1,)        \n",
    "        \n",
    "        self.rollout_qs = []  # list of tensors of shape (1,)\n",
    "        self.rollout_n = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.encoded = None \n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.discounting = discounting\n",
    "        self.rec_t = rec_t        \n",
    "        \n",
    "        self.visited = False\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def expand(self, r, v, logits, encoded, override=False):\n",
    "        \"\"\"\n",
    "        First time arriving a node and so we expand it\n",
    "        r, v: tensor of shape (1,)\n",
    "        logits: tensor of shape (num_actions,)\n",
    "        \"\"\"\n",
    "        if not override: assert not self.expanded()\n",
    "        if override:\n",
    "            self.rollout_qs = [x - self.r + r for x in self.rollout_qs]\n",
    "            self.rollout_qs[0] = v * self.discounting\n",
    "        self.r = r\n",
    "        self.v = v\n",
    "        self.encoded = encoded\n",
    "        for a in range(self.num_actions):\n",
    "            if not override:\n",
    "                child = self.children.append(Node(self, a, logits[[a]], \n",
    "                   self.num_actions, self.discounting, self.rec_t))\n",
    "            else:\n",
    "                self.children[a].logit = logits[[a]]        \n",
    "            \n",
    "    def visit(self):\n",
    "        self.trail_r = torch.tensor([0.], dtype=torch.float32)    \n",
    "        self.trail_discount = 1.\n",
    "        self.propagate(self.r, self.v, not self.visited)        \n",
    "        self.visited = True\n",
    "        \n",
    "    def propagate(self, r, v, new_rollout):\n",
    "        self.trail_r = self.trail_r + self.trail_discount * r\n",
    "        self.trail_discount = self.trail_discount * self.discounting\n",
    "        self.rollout_q = self.trail_r + self.trail_discount * v\n",
    "        if new_rollout:\n",
    "            self.rollout_qs.append(self.rollout_q)\n",
    "            self.rollout_n = self.rollout_n + 1\n",
    "        if self.parent is not None: self.parent.propagate(r, v, new_rollout)\n",
    "            \n",
    "    def stat(self, pos=None):\n",
    "        assert self.expanded()\n",
    "        self.child_logits = torch.concat([x.logit for x in self.children])        \n",
    "        child_rollout_qs_mean = []\n",
    "        child_rollout_qs_max = []\n",
    "        for x in self.children:\n",
    "            if len(x.rollout_qs) > 0:                \n",
    "                q_mean = torch.mean(torch.cat(x.rollout_qs), dim=-1, keepdim=True)\n",
    "                q_max = torch.max(torch.cat(x.rollout_qs), dim=-1, keepdim=True)[0]\n",
    "            else:\n",
    "                q_mean = torch.tensor([0.], dtype=torch.float32)    \n",
    "                q_max = torch.tensor([0.], dtype=torch.float32)    \n",
    "            child_rollout_qs_mean.append(q_mean)\n",
    "            child_rollout_qs_max.append(q_max)\n",
    "        self.child_rollout_qs_mean = torch.concat(child_rollout_qs_mean)\n",
    "        self.child_rollout_qs_max = torch.concat(child_rollout_qs_max)\n",
    "        \n",
    "        self.child_rollout_ns = torch.tensor([x.rollout_n for x in self.children]).long()\n",
    "        if pos is None:\n",
    "            self.child_rollout_ns_enc = self.child_rollout_ns / self.rec_t       \n",
    "        else:\n",
    "            self.child_rollout_ns_enc = torch.flatten(pos(self.child_rollout_ns))\n",
    "            \n",
    "        ret_list = [\"action\", \"r\", \"v\", \"child_logits\", \"child_rollout_qs_mean\",\n",
    "                    \"child_rollout_qs_max\", \"child_rollout_ns_enc\"]\n",
    "        self.ret_dict = {x: getattr(self, x) for x in ret_list}\n",
    "        out = torch.concat(list(self.ret_dict.values()))        \n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5f1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parser():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch Scalable Agent\")\n",
    "\n",
    "    parser.add_argument(\"--env\", type=str, default=\"Sokoban-v0\",\n",
    "                        help=\"Gym environment.\")\n",
    "    parser.add_argument(\"--env_disable_noop\", action=\"store_true\",\n",
    "                        help=\"Disable noop in environment or not. (sokoban only)\")\n",
    "\n",
    "    parser.add_argument(\"--xpid\", default=None,\n",
    "                        help=\"Experiment id (default: None).\")\n",
    "\n",
    "    parser.add_argument(\"--disable_checkpoint\", action=\"store_true\",\n",
    "                        help=\"Disable saving checkpoint.\")\n",
    "    parser.add_argument(\"--load_checkpoint\", default=\"\",\n",
    "                        help=\"Load checkpoint directory.\")    \n",
    "    parser.add_argument(\"--savedir\", default=\"~/RS/thinker/logs/torchbeast\",\n",
    "                        help=\"Root dir where experiment data will be saved.\")\n",
    "\n",
    "    # Training settings.        \n",
    "    parser.add_argument(\"--num_actors\", default=48, type=int, metavar=\"N\",\n",
    "                        help=\"Number of actors (default: 48).\")\n",
    "    parser.add_argument(\"--total_steps\", default=500000000, type=int, metavar=\"T\",\n",
    "                        help=\"Total environment steps to train for.\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, metavar=\"B\",\n",
    "                        help=\"Learner batch size.\")\n",
    "    parser.add_argument(\"--unroll_length\", default=100, type=int, metavar=\"T\",\n",
    "                        help=\"The unroll length (time dimension).\")\n",
    "    parser.add_argument(\"--num_buffers\", default=None, type=int,\n",
    "                        metavar=\"N\", help=\"Number of shared-memory buffers.\")\n",
    "    parser.add_argument(\"--num_learner_threads\", \"--num_threads\", default=1, type=int,\n",
    "                        metavar=\"N\", help=\"Number learner threads.\")\n",
    "    parser.add_argument(\"--disable_cuda\", action=\"store_true\",\n",
    "                        help=\"Disable CUDA.\")\n",
    "\n",
    "    # Architecture settings\n",
    "    parser.add_argument(\"--tran_dim\", default=64, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer hidden dim.\")\n",
    "    parser.add_argument(\"--tran_mem_n\", default=5, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer memory.\")\n",
    "    parser.add_argument(\"--tran_layer_n\", default=3, type=int, metavar=\"N\",\n",
    "                        help=\"Number of transformer layer.\")\n",
    "    parser.add_argument(\"--tran_t\", default=1, type=int, metavar=\"T\",\n",
    "                        help=\"Number of recurrent step for transformer.\")\n",
    "    parser.add_argument(\"--tran_ff_n\", default=256, type=int, metavar=\"N\",\n",
    "                        help=\"Size of transformer ff .\")\n",
    "    parser.add_argument(\"--tran_skip\", action=\"store_true\",\n",
    "                        help=\"Whether to enable skip conn.\")\n",
    "    parser.add_argument(\"--tran_norm_first\", action=\"store_true\",\n",
    "                        help=\"Whether to use norm first in transformer.\")\n",
    "    parser.add_argument(\"--tran_rpos\", action=\"store_true\",\n",
    "                        help=\"Whether to use relative position in transformer.\")\n",
    "    parser.add_argument(\"--tran_lstm\", action=\"store_true\",\n",
    "                        help=\"Whether to use LSTM-transformer.\")\n",
    "    parser.add_argument(\"--tran_lstm_new\", action=\"store_true\",\n",
    "                        help=\"Whether to use a speed-up version of LSTM-transformer.\")    \n",
    "    parser.add_argument(\"--tran_lstm_no_attn\", action=\"store_true\",\n",
    "                        help=\"Whether to disable attention in LSTM-transformer.\")\n",
    "    parser.add_argument(\"--tran_attn_b\", default=5.,\n",
    "                        type=float, help=\"Bias attention for current position.\")    \n",
    "    parser.add_argument(\"--tran_erasep\", action=\"store_true\",\n",
    "                        help=\"Whether to erase past memories if not planning.\")\n",
    "    \n",
    "    \n",
    "    # Loss settings.\n",
    "    parser.add_argument(\"--entropy_cost\", default=0.0001,\n",
    "                        type=float, help=\"Entropy cost/multiplier.\")\n",
    "    parser.add_argument(\"--im_entropy_cost\", default=0.0001,\n",
    "                        type=float, help=\"Imagainary Entropy cost/multiplier.\")         \n",
    "    parser.add_argument(\"--baseline_cost\", default=0.5,\n",
    "                        type=float, help=\"Baseline cost/multiplier.\")\n",
    "    parser.add_argument(\"--reg_cost\", default=0.1,\n",
    "                        type=float, help=\"Reg cost/multiplier.\")\n",
    "    parser.add_argument(\"--real_cost\", default=1,\n",
    "                        type=float, help=\"Real reward - real action cost/multiplier.\")      \n",
    "    parser.add_argument(\"--real_im_cost\", default=1,\n",
    "                        type=float, help=\"Real reward - imagainary action cost/multiplier.\")          \n",
    "    parser.add_argument(\"--im_cost\", default=1,\n",
    "                        type=float, help=\"Imaginary reward cost/multiplier.\")   \n",
    "    parser.add_argument(\"--discounting\", default=0.99,\n",
    "                        type=float, help=\"Discounting factor.\")\n",
    "    parser.add_argument(\"--lamb\", default=1.,\n",
    "                        type=float, help=\"Lambda when computing trace.\")\n",
    "    parser.add_argument(\"--reward_clipping\", default=10, type=int, \n",
    "                        metavar=\"N\", help=\"Reward clipping.\")\n",
    "    parser.add_argument(\"--trun_bs\", action=\"store_true\",\n",
    "                        help=\"Whether to add baseline as reward when truncated.\")\n",
    "    \n",
    "    # Model settings\n",
    "    parser.add_argument(\"--reward_type\", default=1, type=int, metavar=\"N\",\n",
    "                        help=\"Reward type\")   \n",
    "    parser.add_argument(\"--reset_m\", default=-1, type=int, metavar=\"N\",\n",
    "                        help=\"Auto reset after passing m node since an unexpanded noded\")    \n",
    "    parser.add_argument(\"--model_type_nn\", default=0,\n",
    "                        type=float, help=\"Model type.\")     \n",
    "    parser.add_argument(\"--perfect_model\", action=\"store_true\",\n",
    "                        help=\"Whether to use perfect model.\")    \n",
    "    parser.add_argument(\"--stat_pos_encode\", action=\"store_true\",\n",
    "                        help=\"Whether to use positional encoding for integers\")       \n",
    "    parser.add_argument(\"--stat_pos_encode_dim\", default=32, type=int, metavar=\"N\",\n",
    "                        help=\"Dimension of positional encoding (only enabled when stat_pos_encode == True).\")        \n",
    "    parser.add_argument(\"--rec_t\", default=5, type=int, metavar=\"N\",\n",
    "                        help=\"Number of planning steps.\")\n",
    "    parser.add_argument(\"--flex_t\", action=\"store_true\",\n",
    "                        help=\"Whether to enable flexible planning steps.\") \n",
    "    parser.add_argument(\"--flex_t_cost\", default=-1e-5,\n",
    "                        type=float, help=\"Cost of planning step (only enabled when flex_t == True).\")\n",
    "    parser.add_argument(\"--flex_t_cost_m\", default=-1e-2,\n",
    "                        type=float, help=\"Multipler to exp. of planning cost (only enabled when flex_t_cost_type == 1).\")    \n",
    "    parser.add_argument(\"--flex_t_cost_type\", default=0,\n",
    "                        type=int, help=\"Type of planning cost; 0 for constant, 1 for exp. decay\")                    \n",
    "    parser.add_argument(\"--flex_t_term_b\", default=-5,\n",
    "                        type=float, help=\"Bias added to the logit of term action.\")      \n",
    "    parser.add_argument(\"--no_mem\", action=\"store_true\",\n",
    "                        help=\"Whether to erase all memories after each real action.\")   \n",
    "    parser.add_argument(\"--tree_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry over the tree.\")   \n",
    "    parser.add_argument(\"--tree_vb\", default=0., type=float,\n",
    "                        help=\"Adjustment to initial max-Q.\")    \n",
    "    parser.add_argument(\"--thres_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry threshold over.\")   \n",
    "    parser.add_argument(\"--reward_carry\", action=\"store_true\",\n",
    "                        help=\"Whether to carry planning reward over.\")      \n",
    "    parser.add_argument(\"--thres_discounting\", default=0.99,\n",
    "                        type=float, help=\"Threshold discounting factor.\")    \n",
    "    \n",
    "\n",
    "    # Optimizer settings.\n",
    "    parser.add_argument(\"--learning_rate\", default=0.00005,\n",
    "                        type=float, metavar=\"LR\", help=\"Learning rate.\")\n",
    "    parser.add_argument(\"--disable_adam\", action=\"store_true\",\n",
    "                        help=\"Use Aadm optimizer or not.\")\n",
    "    parser.add_argument(\"--alpha\", default=0.99, type=float,\n",
    "                        help=\"RMSProp smoothing constant.\")\n",
    "    parser.add_argument(\"--momentum\", default=0, type=float,\n",
    "                        help=\"RMSProp momentum.\")\n",
    "    parser.add_argument(\"--epsilon\", default=0.01, type=float,\n",
    "                        help=\"RMSProp epsilon.\")\n",
    "    parser.add_argument(\"--grad_norm_clipping\", default=0.0, type=float,\n",
    "                        help=\"Global gradient norm clip.\")\n",
    "    # yapf: enable\n",
    "\n",
    "    return parser\n",
    "\n",
    "parser = define_parser()\n",
    "flags = parser.parse_args([])        \n",
    "\n",
    "flags.xpid = None\n",
    "flags.load_checkpoint = \"\"\n",
    "\n",
    "flags.env = \"cSokoban-v0\"\n",
    "flags.num_actors = 1\n",
    "flags.batch_size = 8\n",
    "flags.unroll_length = 50\n",
    "flags.learning_rate = 0.0001\n",
    "flags.grad_norm_clipping = 60\n",
    "\n",
    "flags.entropy_cost = 0.00001\n",
    "flags.im_entropy_cost = 0.00001\n",
    "flags.reg_cost = 0.01\n",
    "flags.real_cost = 1\n",
    "flags.real_im_cost = 1\n",
    "flags.im_cost = 1\n",
    "flags.discounting = 0.97\n",
    "flags.lamb = 1.\n",
    "\n",
    "flags.trun_bs = False\n",
    "flags.total_steps = 500000000\n",
    "flags.disable_adam = False\n",
    "\n",
    "flags.tran_t = 1\n",
    "flags.tran_mem_n = 5\n",
    "flags.tran_layer_n = 3\n",
    "flags.tran_lstm = True\n",
    "flags.tran_lstm_no_attn = False\n",
    "flags.tran_attn_b = 5\n",
    "flags.tran_norm_first = False\n",
    "flags.tran_ff_n = 256\n",
    "flags.tran_skip = False\n",
    "flags.tran_erasep = False\n",
    "flags.tran_dim = 64\n",
    "flags.tran_rpos = True\n",
    "\n",
    "flags.no_mem = True\n",
    "flags.rec_t = 10\n",
    "flags.model_type_nn = 0\n",
    "flags.perfect_model = True\n",
    "flags.reward_type = 1\n",
    "flags.stat_pos_encode = False\n",
    "flags.stat_pos_encode_dim = 32\n",
    "\n",
    "flags.reset_m = -1\n",
    "flags.tree_carry = True\n",
    "flags.thres_carry = True\n",
    "flags.reward_carry = False\n",
    "flags.thres_discounting = 0.97\n",
    "flags.flex_t = False\n",
    "flags.flex_t_cost = 1e-6\n",
    "flags.flex_t_cost_m = 1e-2\n",
    "flags.flex_t_cost_type = 0\n",
    "flags.flex_t_term_b = -3.\n",
    "\n",
    "flags.savedir = \"~/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d04a968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating log directory: /home/sc/tmp/torchbeast-20221206-223221\n",
      "Creating log directory: /home/sc/tmp/torchbeast-20221206-223221\n",
      "Symlinked log directory: /home/sc/tmp/latest\n",
      "Symlinked log directory: /home/sc/tmp/latest\n",
      "Saving arguments to /home/sc/tmp/torchbeast-20221206-223221/meta.json\n",
      "Saving arguments to /home/sc/tmp/torchbeast-20221206-223221/meta.json\n",
      "Saving messages to /home/sc/tmp/torchbeast-20221206-223221/out.log\n",
      "Saving messages to /home/sc/tmp/torchbeast-20221206-223221/out.log\n",
      "Saving logs data to /home/sc/tmp/torchbeast-20221206-223221/logs.csv\n",
      "Saving logs data to /home/sc/tmp/torchbeast-20221206-223221/logs.csv\n",
      "Saving logs' fields to /home/sc/tmp/torchbeast-20221206-223221/fields.csv\n",
      "Saving logs' fields to /home/sc/tmp/torchbeast-20221206-223221/fields.csv\n",
      "Using CUDA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  298694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actor 0 started.\n",
      "# Step\tmean_episode_return\tepisode_returns\ttotal_loss\tpg_loss\tbaseline_loss\tentropy_loss\tmax_rollout_depth\tim_pg_loss\tim_baseline_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  298694\n",
      "Using Adam...\n",
      "All parameters: \n",
      "conv1.weight 2208\n",
      "conv1.bias 32\n",
      "conv2.weight 2048\n",
      "conv2.bias 64\n",
      "core.layers.0.pos_w 320\n",
      "core.layers.0.pos_b 40\n",
      "core.layers.0.main.weight 61440\n",
      "core.layers.0.main.bias 320\n",
      "core.layers.0.proj.weight 24576\n",
      "core.layers.0.proj.bias 192\n",
      "core.layers.0.out.weight 4096\n",
      "core.layers.0.out.bias 64\n",
      "core.layers.0.norm.weight 64\n",
      "core.layers.0.norm.bias 64\n",
      "core.layers.1.pos_w 320\n",
      "core.layers.1.pos_b 40\n",
      "core.layers.1.main.weight 61440\n",
      "core.layers.1.main.bias 320\n",
      "core.layers.1.proj.weight 24576\n",
      "core.layers.1.proj.bias 192\n",
      "core.layers.1.out.weight 4096\n",
      "core.layers.1.out.bias 64\n",
      "core.layers.1.norm.weight 64\n",
      "core.layers.1.norm.bias 64\n",
      "core.layers.2.pos_w 320\n",
      "core.layers.2.pos_b 40\n",
      "core.layers.2.main.weight 61440\n",
      "core.layers.2.main.bias 320\n",
      "core.layers.2.proj.weight 24576\n",
      "core.layers.2.proj.bias 192\n",
      "core.layers.2.out.weight 4096\n",
      "core.layers.2.out.bias 64\n",
      "core.layers.2.norm.weight 64\n",
      "core.layers.2.norm.bias 64\n",
      "core.proj_list.0.weight 128\n",
      "core.proj_list.0.bias 64\n",
      "core.proj_list.1.weight 128\n",
      "core.proj_list.1.bias 64\n",
      "core.proj_list.2.weight 128\n",
      "core.proj_list.2.bias 64\n",
      "fc.weight 16384\n",
      "fc.bias 256\n",
      "im_policy.weight 1280\n",
      "im_policy.bias 5\n",
      "policy.weight 1280\n",
      "policy.bias 5\n",
      "baseline.weight 512\n",
      "baseline.bias 2\n",
      "reset.weight 512\n",
      "reset.bias 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated log fields: ['_tick', '_time', 'step', 'real_step', 'mean_episode_return', 'episode_returns', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'max_rollout_depth', 'im_pg_loss', 'im_baseline_loss', 'rmean_im_episode_return', 'rmean_episode_return', 'episode']\n",
      "Updated log fields: ['_tick', '_time', 'step', 'real_step', 'mean_episode_return', 'episode_returns', 'total_loss', 'pg_loss', 'baseline_loss', 'entropy_loss', 'max_rollout_depth', 'im_pg_loss', 'im_baseline_loss', 'rmean_im_episode_return', 'rmean_episode_return', 'episode']\n",
      "Steps 280 (2800) @ 559.7 SPS. Eps 1. Return -1.449999 (0.000330). Loss -2.73 mean_plan_step 10.00 max_rollout_depth 3.15 pg_loss -29.28 baseline_loss 0.16 im_pg_loss 26.27 im_baseline_loss 0.14 entropy_loss -0.02 reg_loss 0.00 total_norm 21.97\n",
      "Steps 640 (6400) @ 719.5 SPS. Eps 4. Return -0.709999 (0.000144). Loss -22.98 mean_plan_step 10.00 max_rollout_depth 3.45 pg_loss 7.65 baseline_loss 0.07 im_pg_loss -30.89 im_baseline_loss 0.21 entropy_loss -0.02 reg_loss 0.00 total_norm 19.82\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38149/2902932188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38149/2902932188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Try joining actors then quit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if flags.reward_type == 0:\n",
    "    flags.num_rewards = num_rewards = 1\n",
    "else:\n",
    "    flags.num_rewards = num_rewards = 2\n",
    "flags.im_discounting = flags.discounting ** (1/flags.rec_t)    \n",
    "    \n",
    "raw_env = EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "\n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])    \n",
    "\n",
    "env = Environment(ModelWrapper(EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env), \n",
    "     model=model, flags=flags))\n",
    "obs_shape = env.gym_env.observation_space.shape\n",
    "\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "if flags.load_checkpoint:\n",
    "    flags.savedir = os.path.split(os.path.split(flags.load_checkpoint)[0])[0]\n",
    "    flags.xpid = os.path.split(os.path.split(flags.load_checkpoint)[0])[-1]    \n",
    "else:\n",
    "    if flags.xpid is None:\n",
    "        flags.xpid = \"torchbeast-%s\" % time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "flags.git_revision = get_git_revision_hash()\n",
    "\n",
    "plogger = file_writer.FileWriter(\n",
    "    xpid=flags.xpid, xp_args=flags.__dict__, rootdir=flags.savedir\n",
    ")\n",
    "\n",
    "flags.device = None\n",
    "if not flags.disable_cuda and torch.cuda.is_available():\n",
    "    logging.info(\"Using CUDA.\")\n",
    "    flags.device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logging.info(\"Not using CUDA.\")\n",
    "    flags.device = torch.device(\"cpu\")\n",
    "\n",
    "checkpointpath = os.path.expandvars(\n",
    "    os.path.expanduser(\"%s/%s/%s\" % (flags.savedir, flags.xpid, \"model.tar\"))\n",
    ")\n",
    "\n",
    "if flags.num_buffers is None:  # Set sensible default for num_buffers.\n",
    "    flags.num_buffers = max(2 * flags.num_actors, flags.batch_size)\n",
    "if flags.num_actors >= flags.num_buffers:\n",
    "    raise ValueError(\"num_buffers should be larger than num_actors\")\n",
    "if flags.num_buffers < flags.batch_size:\n",
    "    raise ValueError(\"num_buffers should be larger than batch_size\")\n",
    "\n",
    "T = flags.unroll_length\n",
    "B = flags.batch_size\n",
    "\n",
    "actor_net = Actor_net(obs_shape, num_actions, flags)\n",
    "buffers = create_buffers(flags, obs_shape, num_actions, num_rewards)\n",
    "\n",
    "if flags.load_checkpoint:\n",
    "    train_checkpoint = torch.load(flags.load_checkpoint)\n",
    "    actor_net.load_state_dict(train_checkpoint[\"model_state_dict\"])  \n",
    "\n",
    "actor_net.share_memory()\n",
    "\n",
    "# Add initial RNN state.\n",
    "initial_agent_state_buffers = []\n",
    "for _ in range(flags.num_buffers):\n",
    "    state = actor_net.initial_state(batch_size=1)\n",
    "    for t in state:\n",
    "        t.share_memory_()\n",
    "    initial_agent_state_buffers.append(state)\n",
    "\n",
    "actor_processes = []\n",
    "ctx = mp.get_context()\n",
    "free_queue = ctx.SimpleQueue()\n",
    "full_queue = ctx.SimpleQueue()\n",
    "\n",
    "for i in range(flags.num_actors):\n",
    "    actor = ctx.Process(target=act, args=(flags, i, free_queue, full_queue,\n",
    "            actor_net, model, buffers, initial_agent_state_buffers,),)\n",
    "    actor.start()\n",
    "    actor_processes.append(actor)\n",
    "\n",
    "learner_net = Actor_net(obs_shape, num_actions, flags)\n",
    "if flags.load_checkpoint:\n",
    "    learner_net.load_state_dict(train_checkpoint[\"model_state_dict\"])\n",
    "#learner_net= DataParallelWrapper(nn.DataParallel(learner_net))   # commented out if no need multi-gpu\n",
    "learner_net = learner_net.to(device=flags.device)  \n",
    "\n",
    "if not flags.disable_adam:\n",
    "    print(\"Using Adam...\")        \n",
    "    optimizer = torch.optim.Adam(learner_net.parameters(),lr=flags.learning_rate)\n",
    "else:\n",
    "    print(\"Using RMS Prop...\")\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        learner_net.actor.parameters(),\n",
    "        lr=flags.learning_rate,\n",
    "        momentum=flags.momentum,\n",
    "        eps=flags.epsilon,\n",
    "        alpha=flags.alpha,)\n",
    "    \n",
    "if flags.load_checkpoint:\n",
    "    optimizer.load_state_dict(train_checkpoint[\"optimizer_state_dict\"])    \n",
    "    \n",
    "print(\"All parameters: \")\n",
    "for k, v in learner_net.named_parameters(): print(k, v.numel())    \n",
    "\n",
    "if not flags.flex_t:\n",
    "    lr_lambda = lambda epoch: 1 - min(epoch * T * B, flags.total_steps * flags.rec_t) / (flags.total_steps * flags.rec_t)\n",
    "else:\n",
    "    lr_lambda = lambda epoch: 1 - min(epoch, flags.total_steps) / flags.total_steps\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "if flags.load_checkpoint:\n",
    "    scheduler.load_state_dict(train_checkpoint[\"scheduler_state_dict\"])\n",
    "    \n",
    "logger = logging.getLogger(\"logfile\")\n",
    "stat_keys = [\"mean_episode_return\", \"episode_returns\", \"total_loss\",\n",
    "    \"pg_loss\", \"baseline_loss\", \"entropy_loss\", \"max_rollout_depth\"]\n",
    "if flags.reward_type == 1:\n",
    "    stat_keys.extend([\"im_pg_loss\", \"im_baseline_loss\"])\n",
    "\n",
    "logger.info(\"# Step\\t%s\", \"\\t\".join(stat_keys))\n",
    "\n",
    "step, real_step, stats, last_returns, last_im_returns, tot_eps = 0, 0, {}, deque(maxlen=400), deque(maxlen=40000), 0\n",
    "if flags.load_checkpoint:\n",
    "    if \"step\" in train_checkpoint.keys():    \n",
    "        step = train_checkpoint[\"step\"]\n",
    "        real_step = train_checkpoint[\"real_step\"]\n",
    "    else:\n",
    "        # legacy support\n",
    "        step = train_checkpoint[\"scheduler_state_dict\"][\"_step_count\"] * T * B\n",
    "    \n",
    "def batch_and_learn(i, lock=threading.Lock()):\n",
    "    \"\"\"Thread target for the learning process.\"\"\"\n",
    "    #nonlocal step, stats, last_returns, tot_eps\n",
    "    global step, real_step, stats, last_returns, last_im_returns, tot_eps\n",
    "    timings = prof.Timings()\n",
    "    #while step < flags.total_steps:\n",
    "    while real_step < flags.total_steps:\n",
    "        timings.reset()\n",
    "        batch, agent_state = get_batch(flags, free_queue, full_queue, buffers,\n",
    "            initial_agent_state_buffers, timings,)\n",
    "        stats = learn(flags, actor_net, learner_net, batch, \n",
    "                      agent_state, optimizer, scheduler, real_step)\n",
    "        last_returns.extend(stats[\"episode_returns\"])\n",
    "        if \"im_episode_returns\" in stats:\n",
    "            last_im_returns.extend(stats[\"im_episode_returns\"])\n",
    "        tot_eps = tot_eps + len(stats[\"episode_returns\"])\n",
    "        timings.time(\"learn\")\n",
    "        with lock:\n",
    "            to_log = dict(step=step, real_step=real_step)\n",
    "            to_log.update({k: stats[k] for k in stat_keys})            \n",
    "            to_log.update({\"rmean_im_episode_return\": np.average(last_im_returns) if len(last_im_returns) > 0 else 0.,\n",
    "                           \"rmean_episode_return\": np.average(last_returns) if len(last_returns) > 0 else 0.,\n",
    "                           \"episode\": tot_eps})\n",
    "            plogger.log(to_log)\n",
    "            step += T * B\n",
    "            real_step += stats[\"real_step\"]\n",
    "\n",
    "    if i == 0:\n",
    "        logging.info(\"Batch and learn: %s\", timings.summary())\n",
    "\n",
    "for m in range(flags.num_buffers):\n",
    "    free_queue.put(m)\n",
    "\n",
    "threads = []\n",
    "for i in range(flags.num_learner_threads):\n",
    "    thread = threading.Thread(\n",
    "        target=batch_and_learn, name=\"batch-and-learn-%d\" % i, args=(i,)\n",
    "    )\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "def checkpoint():\n",
    "    if flags.disable_checkpoint:\n",
    "        return\n",
    "    logging.info(\"Saving checkpoint to %s\", checkpointpath)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": actor_net.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"step\": step,\n",
    "            \"real_step\": real_step,\n",
    "            \"flags\": vars(flags),\n",
    "        },\n",
    "        checkpointpath,\n",
    "    )\n",
    "\n",
    "timer = timeit.default_timer\n",
    "try:\n",
    "    last_checkpoint_time = timer()\n",
    "    train_start_time = timer()\n",
    "    while real_step < flags.total_steps:\n",
    "        start_step = step\n",
    "        start_time = timer()\n",
    "        time.sleep(5)\n",
    "\n",
    "        if timer() - last_checkpoint_time > 10 * 60:  # Save every 10 min.\n",
    "            checkpoint()\n",
    "            last_checkpoint_time = timer()\n",
    "\n",
    "        sps = (step - start_step) / (timer() - start_time)\n",
    "        if stats.get(\"episode_returns\", None):\n",
    "            mean_return = (\n",
    "                \"Return per episode: %.1f. \" % stats[\"mean_episode_return\"]\n",
    "            )\n",
    "        else:\n",
    "            mean_return = \"\"\n",
    "        total_loss = stats.get(\"total_loss\", float(\"inf\"))\n",
    "\n",
    "        print_str =  \"Steps %i (%i) @ %.1f SPS. Eps %i. Return %f (%f). Loss %.2f\" % (real_step, step, sps, tot_eps, \n",
    "            np.average(last_returns) if len(last_returns) > 0 else 0.,\n",
    "            np.average(last_im_returns) if len(last_im_returns) > 0 else 0.,\n",
    "            total_loss)\n",
    "\n",
    "        for s in [\"mean_plan_step\", \"max_rollout_depth\", \"pg_loss\", \"baseline_loss\", \"im_pg_loss\", \n",
    "                  \"im_baseline_loss\", \"entropy_loss\", \"reg_loss\", \"total_norm\"]:\n",
    "            if s in stats: print_str += \" %s %.2f\" % (s, stats[s])\n",
    "\n",
    "        logging.info(print_str)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    for thread in threads:\n",
    "        thread.join()        \n",
    "    # Try joining actors then quit.\n",
    "else:\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    logging.info(\"Learning finished after %d steps. (%f s)\" % (step, timer() - train_start_time))\n",
    "finally:\n",
    "    for _ in range(flags.num_actors):\n",
    "        free_queue.put(None)\n",
    "    for actor in actor_processes:\n",
    "        actor.join(timeout=1)\n",
    "\n",
    "checkpoint()\n",
    "plogger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726743",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = flags.total_steps + 1\n",
    "for thread in threads:\n",
    "     thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(flags.num_actors):\n",
    "    free_queue.put(None)\n",
    "for actor in actor_processes:\n",
    "    actor.join(timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b71ad",
   "metadata": {},
   "source": [
    "<font size=\"5\">Agent Debug and Visualize</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3d487f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "def plot_obs(x, ax=None, title=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    ax.imshow(torch.swapaxes(torch.swapaxes(x[0].cpu(),0,2),0,1), interpolation='nearest', aspect=\"auto\")\n",
    "    if title is not None: ax.set_title(title)\n",
    "    \n",
    "def plot_qn_sa(q_s_a, n_s_a, max_q_s_a=None, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    xs = np.arange(len(q_s_a))\n",
    "\n",
    "    ax.bar(xs - 0.3, q_s_a.cpu(), color = 'g', width = 0.3, label=\"q_s_a\")    \n",
    "    ax_n = ax.twinx()\n",
    "    if max_q_s_a is not None:\n",
    "        ax.bar(xs, max_q_s_a.cpu(), color = 'r', width = 0.3, label=\"max_q_s_a\")        \n",
    "    ax_n.bar(xs + (0.3 if max_q_s_a is not None else 0.), \n",
    "             n_s_a.cpu(), bottom=0, color = 'b', width = 0.3, label=\"n_s_a\")\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(len(q_s_a))))\n",
    "    ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right'))    \n",
    "    ax.legend(loc=\"upper left\")   \n",
    "    ax_n.legend(loc=\"upper right\") \n",
    "    ax.set_title(\"q_s_a and n_s_a\")\n",
    "    \n",
    "def plot_policies(model_logit, actor_logit, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    model_prob = torch.softmax(model_logit, dim=-1).detach().cpu().numpy()\n",
    "    prob = torch.softmax(actor_logit, dim=-1).detach().cpu().numpy()\n",
    "    ax.set_title(\"Real policy prob\")\n",
    "    xs = np.arange(len(model_prob))\n",
    "    ax.bar(xs - 0.1, model_prob, color = 'g', width = 0.1, label=\"model policy prob\")\n",
    "    ax.bar(xs, prob, color = 'r', width = 0.1, label=\"agent policy prob\")\n",
    "    ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(len(model_prob))))\n",
    "    ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right'))\n",
    "    ax.set_ylim(0, 1)        \n",
    "    ax.legend()       \n",
    "        \n",
    "def plot_im_policies(im_policy_logits, reset_policy_logits, term_policy_logits, \n",
    "                     im_action, reset_action, term_action,\n",
    "                     one_hot=True, reset_ind=0, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "        \n",
    "    rec_t, num_actions = im_policy_logits.shape\n",
    "    num_actions += 1\n",
    "    rec_t -= 1\n",
    "        \n",
    "    im_prob = torch.softmax(im_policy_logits, dim=-1).detach().cpu().numpy()\n",
    "    reset_prob = torch.softmax(reset_policy_logits, dim=-1)[:,[reset_ind]].detach().cpu().numpy()\n",
    "    full_prob = np.concatenate([im_prob, reset_prob], axis=-1)\n",
    "    if term_policy_logits is not None:\n",
    "        term_prob = torch.softmax(term_policy_logits, dim=-1)[:,[reset_ind]].detach().cpu().numpy()\n",
    "        full_prob = np.concatenate([full_prob, term_prob], axis=-1)\n",
    "    \n",
    "    if not one_hot: im_action = F.one_hot(im_action, num_actions - 1)\n",
    "    im_action = im_action.detach().cpu().numpy()\n",
    "    reset_action = reset_action.unsqueeze(-1).detach().cpu().numpy()    \n",
    "    full_action = np.concatenate([im_action, reset_action], axis=-1)\n",
    "    if term_action is not None:\n",
    "        term_action = term_action.unsqueeze(-1).detach().cpu().numpy() \n",
    "        full_action = np.concatenate([full_action, term_action], axis=-1)\n",
    "    \n",
    "    #full_prob = full_prob[:-1]\n",
    "    #full_action = full_action[:-1]    \n",
    "    #xs = np.arange(rec_t)\n",
    "    \n",
    "    xs = np.arange(rec_t+1)\n",
    "    labels = ['noop', 'up', 'down', 'left', 'right', 'reset']   \n",
    "    \n",
    "    if term_action is not None:\n",
    "        labels.append('term')\n",
    "        num_actions += 1\n",
    "        \n",
    "    for i in range(num_actions):        \n",
    "        c = ax.bar(xs + 0.8 * (i / num_actions), full_prob[:,i], width = 0.8 / (num_actions), label=labels[i])  \n",
    "        color = c.patches[0].get_facecolor()\n",
    "        color = color[:3] + (color[3] * 0.5,)\n",
    "        ax.bar(xs + 0.8 * (i / num_actions), full_action[:,i], width = 0.8 / (num_actions), color=color)\n",
    "        \n",
    "    \n",
    "    #xs = np.arange(num_actions)\n",
    "    #for i in range(rec_t):\n",
    "    #    ax.bar(xs + 0.8 * (i / rec_t), im_reset_action[i], width = 0.8 / (rec_t), color=\"#cccccc\")\n",
    "    #    ax.bar(xs + 0.8 * (i / rec_t), im_reset_prob[i], width = 0.8 / (rec_t))        \n",
    "    #ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(num_actions)))\n",
    "    #ax.set_xticklabels(('noop', 'up', 'down', 'left', 'right', 'reset'))    \n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)   \n",
    "    ax.set_title(\"Imagainary policy prob\")\n",
    "    \n",
    "def print_im_actions(im_dict, print_stat=False):\n",
    "\n",
    "    lookup_dict = {0:\"Noop\",\n",
    "                   1:\"Up\",\n",
    "                   2:\"Down\",\n",
    "                   3:\"Left\",\n",
    "                   4:\"Right\"}\n",
    "\n",
    "    print_strs = []\n",
    "    n, s = 1, \"\"\n",
    "    reset = False\n",
    "    for im, reset in zip(im_dict[\"im_action\"][:-1], im_dict[\"reset_action\"][:-1]):\n",
    "        s += lookup_dict[im.item()] + \", \"\n",
    "        if reset:        \n",
    "            s += \"Reset\"\n",
    "            print_strs.append(\"%d: %s\" %(n, s))\n",
    "            s = \"\"\n",
    "            n += 1\n",
    "    if not reset: print_strs.append(\"%d: %s\" %(n, s[:-2]))\n",
    "    if print_stat: \n",
    "        for s in print_strs: print(s) \n",
    "    return print_strs\n",
    "\n",
    "def plot_im_actions(im_dict, ax=None):    \n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    print_strs = print_im_actions(im_dict, print_stat=False)\n",
    "    for n, s in enumerate(print_strs):  \n",
    "        txt = ax.text(0, 0.8 - 0.1 * n, s, size='x-large')        \n",
    "        txt.set_clip_on(True) \n",
    "    ax.set_xlim(0,1)    \n",
    "        \n",
    "def plot_base_policies(logits, ax=None):\n",
    "    if ax is None: fig, ax = plt.subplots()\n",
    "    prob = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    rec_t, num_actions = logits.shape\n",
    "    xs = np.arange(rec_t)\n",
    "    labels = ['noop', 'up', 'down', 'left', 'right']\n",
    "    for i in range(num_actions):        \n",
    "        c = ax.bar(xs + 0.8 * (i / num_actions), prob[:,i], width = 0.8 / (num_actions), label=labels[i])  \n",
    "        color = c.patches[0].get_facecolor()\n",
    "        color = color[:3] + (color[3] * 0.5,)\n",
    "        ax.bar(xs + 0.8 * (i / num_actions), prob[:,i], width = 0.8 / (num_actions), color=color)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)   \n",
    "    ax.set_title(\"Model policy prob\")\n",
    "        \n",
    "def plot_attn(attn_output):\n",
    "    plt.figure()\n",
    "    ln = flags.tran_layer_n\n",
    "    fig, axarr = plt.subplots(ln,8, figsize=(12,4)) \n",
    "    attn_output_ = torch.concat(attn_output, dim=-2)\n",
    "    for k in range(ln):\n",
    "        for i in range(8):\n",
    "            out = attn_output_[k, i]\n",
    "            out = out.detach().cpu().numpy()\n",
    "            axarr[k, i].imshow(out, interpolation='nearest', vmin=0, vmax=1)   \n",
    "            axarr[k, i].set_xticks([])\n",
    "            axarr[k, i].set_yticks([])\n",
    "    fig.suptitle('Attention')\n",
    "    fig.text(0.5, 0.04, 'Attention Head', ha='center', va='center')\n",
    "    fig.text(0.12, 0.5, 'Layer', ha='center', va='center', rotation='vertical')\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8908d69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CUDA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor size:  885696\n",
      "flags: Namespace(env='Sokoban-v0', env_disable_noop=False, xpid='torchbeast-20221126-161700', disable_checkpoint=False, load_checkpoint='', savedir='~/RS/thinker/logs/torchbeast', num_actors=48, total_steps=100000000, batch_size=32, unroll_length=200, num_buffers=96, num_learner_threads=1, disable_cuda=False, tran_dim=96, tran_mem_n=50, tran_layer_n=3, tran_t=1, tran_ff_n=256, tran_skip=False, tran_norm_first=False, tran_rpos=True, tran_lstm=True, tran_lstm_no_attn=False, tran_attn_b=5.0, tran_erasep=False, entropy_cost=1e-05, im_entropy_cost=1e-05, reset_entropy_cost=1e-05, term_entropy_cost=0.0, baseline_cost=0.5, reg_cost=0.01, im_cost=1.0, discounting=0.97, lamb=1.0, reward_clipping=10, trun_bs=False, reward_type=1, reset_m=-1, model_type_nn=0.0, perfect_model=True, rec_t=200, flex_t=True, flex_t_cost=5e-05, flex_t_cost_m=-0.01, flex_t_cost_type=0, flex_t_term_b=-3.0, stat_type=2, no_mem=False, tree_carry=True, tree_vb=0.0, thres_carry=True, reward_carry=False, thres_discounting=0.99, learning_rate=0.0002, disable_adam=False, alpha=0.99, momentum=0, epsilon=0.01, grad_norm_clipping=600.0, num_rewards=2, im_discounting=0.9998477155590293, device=device(type='cuda'))\n"
     ]
    }
   ],
   "source": [
    "bsz = 1\n",
    "\n",
    "name = \"alstm_3_1_flext_5e-5\"\n",
    "#checkpoint = torch.load(\"/home/sc/RS/thinker/logs/planner_logs/%s/model.tar\" % name)\n",
    "checkpoint = torch.load(\"D:/data/thinker/logs/planner_logs/%s/model.tar\" % name)\n",
    "\n",
    "flags_ = checkpoint[\"flags\"]\n",
    "parser = define_parser()\n",
    "flags = parser.parse_args([])  \n",
    "for k, v in flags_.items(): setattr(flags, k, v)\n",
    "\n",
    "if flags.reward_type == 0:\n",
    "    flags.num_rewards = num_rewards = 1\n",
    "else:\n",
    "    flags.num_rewards = num_rewards = 2\n",
    "\n",
    "raw_env = EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "model_checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(model_checkpoint[\"model_state_dict\"])   \n",
    "\n",
    "env = Environment(ModelWrapper(EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env), \n",
    "     model=model, flags=flags))\n",
    "obs_shape = env.gym_env.observation_space.shape\n",
    "\n",
    "flags.device = None\n",
    "if not flags.disable_cuda and torch.cuda.is_available():\n",
    "    logging.info(\"Using CUDA.\")\n",
    "    flags.device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logging.info(\"Not using CUDA.\")\n",
    "    flags.device = torch.device(\"cpu\")\n",
    "\n",
    "actor_net = Actor_net(obs_shape, num_actions, flags).to(flags.device)\n",
    "actor_net.load_state_dict(checkpoint[\"model_state_dict\"]) \n",
    "\n",
    "print(\"flags:\", flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb82bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "eps_n = 1000\n",
    "\n",
    "raw_env = EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])  \n",
    "model.train(False)\n",
    "env = ModelWrapper(EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env), model=model, flags=flags)\n",
    "env = Environment(env)\n",
    "\n",
    "core_state = actor_net.initial_state(bsz)\n",
    "core_state = tuple(v.to(flags.device) for v in core_state)\n",
    "returns = []\n",
    "obs = env.initial()\n",
    "initial_obs = env.gym_env.x.clone()\n",
    "\n",
    "t = 0\n",
    "im_list = [\"im_policy_logits\", \"reset_policy_logits\", \"term_policy_logits\", \"im_action\", \"reset_action\", \"term_action\"]\n",
    "im_dict = {k: [] for k in im_list}\n",
    "model_logits, attn_output = [], []\n",
    "\n",
    "while(True):\n",
    "    if len(returns) > (0 if debug else eps_n): break    \n",
    "    with torch.no_grad():\n",
    "        obs = {k:v.to(flags.device) for k, v in obs.items()}                             \n",
    "        actor_out, core_state = actor_net(obs, core_state, debug=False)\n",
    "        action = [actor_out['action'][0].unsqueeze(-1), actor_out['im_action'][0].unsqueeze(-1), actor_out['reset_action'][0].unsqueeze(-1)]\n",
    "        if flags.flex_t: action.append(actor_out['term_action'][0].unsqueeze(-1))\n",
    "        action = torch.cat(action, dim=-1)\n",
    "        if len(im_dict['reset_action']) > 0:\n",
    "            im_dict['reset_action'][-1] = env.gym_env.ret_dict['reset'].to(flags.device)\n",
    "        for k in im_list: \n",
    "            im_dict[k].append(actor_out[k][0,0].unsqueeze(0) if k in actor_out.keys() else None)          \n",
    "        model_logits.append(env.gym_env.ret_dict[\"logit\"])\n",
    "        attn_output.append(torch.cat([x.attn_output_weights.unsqueeze(0).unsqueeze(-2) for x in actor_net.core.layers])[:, :, 0, :])           \n",
    "        ret_dict = env.gym_env.ret_dict\n",
    "        \n",
    "        obs = env.step(action.unsqueeze(0))        \n",
    "        \n",
    "        if debug and (obs[\"cur_t\"][0,0] == 0):\n",
    "            plot_attn(attn_output)\n",
    "            for k in im_list: im_dict[k] = torch.concat(im_dict[k], dim=0)            \n",
    "            fig, axs = plt.subplots(1, 5, figsize=(30,6))                          \n",
    "            title = \"step: %d; values: %.4f\" % (t, ret_dict[\"v0\"][0].cpu())\n",
    "            if \"thres\" in ret_dict: title += \" thres: %.4f\" % ret_dict[\"thres\"][0].cpu()\n",
    "            if flags.reward_type == 1: title += \" im_return: %.4f\" % obs['episode_return'][..., 1]                        \n",
    "            plot_obs(initial_obs/255, axs[0], title=title)          \n",
    "            max_q_s_a = ret_dict[\"max_q_s_a\"][0] if \"max_q_s_a\" in ret_dict else None                        \n",
    "            plot_qn_sa(ret_dict[\"q_s_a\"][0], ret_dict[\"n_s_a\"][0], max_q_s_a, ax=axs[3]) \n",
    "            plot_policies(ret_dict[\"logit0\"][0], actor_out[\"policy_logits\"][0,0], ax=axs[4])    \n",
    "            plot_base_policies(torch.concat(model_logits), ax=axs[1])  \n",
    "            plot_im_policies(**im_dict, one_hot=False, reset_ind=1, ax=axs[2])              \n",
    "            plt.show()                        \n",
    "            print_im_actions(im_dict, print_stat=True)            \n",
    "            im_dict = {k: [] for k in im_list}          \n",
    "            model_logits, attn_output = [], []          \n",
    "            initial_obs = env.gym_env.x.clone()\n",
    "        \n",
    "        if torch.any(obs['done']):\n",
    "            new_rets = obs['episode_return'][obs['done']][:,0].numpy()\n",
    "            returns.extend(new_rets)\n",
    "            print(\"Finish %d episode: avg. return: %.2f (+-%.2f) \" % (len(returns),\n",
    "                np.average(returns), np.std(returns) / np.sqrt(len(returns))))  \n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b3d8f-5a0f-42eb-9b8f-cb79cf20c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, axarr = plt.subplots(1, 3, figsize=(6,6)) \n",
    "for k in range(3):\n",
    "    out = actor_net.core.layers[k].pos_b.detach().cpu().numpy()\n",
    "    ax = axarr[k]\n",
    "    ax.imshow(out, interpolation='nearest')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    im = ax.imshow(out)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "f.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66750c-3fcf-4ab3-96dc-d571a1c0aa90",
   "metadata": {},
   "source": [
    "<font size=\"5\">Misc.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scale(x, start, end, n):\n",
    "    return (end - start) * (np.clip(x, 0, n) / n) + start\n",
    "\n",
    "def square_scale(x, start, end, n):\n",
    "    return np.square((np.sqrt(end) - np.sqrt(start)) * (np.clip(x, 0, n) / n) + np.sqrt(start))\n",
    "\n",
    "def exp_scale(x, start, end, n, m):\n",
    "    a = (end - start) / (np.exp(m * n) - 1)\n",
    "    c = start - a\n",
    "    x = np.clip(x, 0, n)    \n",
    "    return a * np.exp(m * x) + c\n",
    "\n",
    "xs = np.arange(-50, 250, 1)\n",
    "y_min, y_max = 1e-7, 5e-3\n",
    "\n",
    "plt.plot(xs, linear_scale(xs, y_min, y_max, 200), label='linear')\n",
    "plt.plot(xs, square_scale(xs, y_min, y_max, 200), label='square')\n",
    "ys = exp_scale(xs, y_min, y_max, 200, 0.01)\n",
    "plt.plot(xs, ys, label='exp')\n",
    "plt.axhline(5e-4)\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "\n",
    "c = -9\n",
    "for x, y in zip(xs, ys):\n",
    "    if x % 5 == 0: print(x, y)\n",
    "    while (y > (10**c)): \n",
    "        print(\"%d exceed %d\" % (x, c))\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "322b0170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flags.perfect_model = True\n",
    "flags.reward_type = 1\n",
    "flags.rec_t = 2000\n",
    "flags.flex_t = True\n",
    "flags.flex_t_cost = 1e-5\n",
    "flags.flex_t_cost_m = 0\n",
    "flags.flex_t_cost_type = 0\n",
    "flags.reset_m = -1\n",
    "flags.tree_carry = True\n",
    "flags.tree_vb = 0.\n",
    "flags.thres_carry = True\n",
    "flags.thres_discounting = 1.\n",
    "\n",
    "raw_env = EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env)\n",
    "raw_obs_shape, num_actions = raw_env.observation_space.shape, raw_env.action_space.n         \n",
    "model = Model(flags, raw_obs_shape, num_actions=num_actions)\n",
    "checkpoint = torch.load(\"../models/model_1.tar\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])    \n",
    "\n",
    "env = ModelWrapper(EnvWrapper(gym.make(flags.env), noop=not flags.env_disable_noop, name=flags.env), \n",
    "     model=model, flags=flags)\n",
    "env = Environment(env)\n",
    "obs = env.initial()\n",
    "plot_obs(env.gym_env.x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a544c489-1277-4e3e-9e7c-deb1c09aa63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': tensor([1, 0, 0, 0, 0]), 'r': tensor([0.]), 'v': tensor([1.1627]), 'child_logits': tensor([-1.1596, -0.5757, -1.7534,  1.0446, -2.5840]), 'child_rollout_qs_mean': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.1104]), 'child_rollout_qs_max': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.1104]), 'child_rollout_ns': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0005])}\n"
     ]
    }
   ],
   "source": [
    "env.gym_env.root_node.stat()\n",
    "print(env.gym_env.root_node.ret_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e7e543ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========0========\n",
      "a_tensor tensor([[[4, 4, 1, 1]]])\n",
      "eps_step tensor([[12]], dtype=torch.int32)\n",
      "eps_return tensor([[[-0.0400,  0.0000]]])\n",
      "reward tensor([[[-0.0100,  0.0000]]])\n",
      "cur_t tensor([[0]])\n",
      "thres tensor([1.3565])\n",
      "root_node qs [tensor([1.1551])]\n",
      "child_node qs []\n",
      "=========1========\n",
      "a_tensor tensor([[[4, 4, 1, 1]]])\n",
      "eps_step tensor([[13]], dtype=torch.int32)\n",
      "eps_return tensor([[[-0.0500,  0.0000]]])\n",
      "reward tensor([[[-0.0100,  0.0000]]])\n",
      "cur_t tensor([[0]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551])]\n",
      "child_node qs []\n",
      "=========2========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[14]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -1.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[1]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n",
      "=========3========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[15]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -2.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[2]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n",
      "=========4========\n",
      "a_tensor tensor([[[4, 4, 1, 0]]])\n",
      "eps_step tensor([[16]], dtype=torch.int32)\n",
      "eps_return tensor([[[-5.0000e-02, -3.0000e-05]]])\n",
      "reward tensor([[[ 0.0000e+00, -1.0000e-05]]])\n",
      "cur_t tensor([[3]])\n",
      "thres tensor([1.4088])\n",
      "root_node qs [tensor([1.1551]), tensor([1.1104])]\n",
      "child_node qs [tensor([1.1104])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGgCAYAAAAKKQXsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAph0lEQVR4nO3df3RU9Z3/8VdikkkQMuFnQpYEaUsbrIIaNMyC/QHRHI7rgSXraqVbLFRWNlAg21MNp/6oxxLW/VZ+7AngD06wVTYtPQuteoTFqPFHA0JEq4uNWDmSCgm6p5mJgSRA7vcP16lj5g65yeQzM3eej3PmHPncO/f9+cxHwuvcfOZ+UizLsgQAAGBIaqw7AAAAkgvhAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABg1ZOGjpqZGl1xyiTIzM1VSUqLXXnttqEoBAIAEkjIUe7v86le/0ve+9z1t3bpVJSUl2rBhg3bu3Knm5maNGzcu4nt7e3t14sQJjRgxQikpKdHuGgAAGAKWZamjo0P5+flKTb3AvQ1rCFxzzTVWRUVF8M/nz5+38vPzrerq6gu+t6WlxZLEixcvXrx48UrAV0tLywX/rU9TlPX09KipqUlVVVXBttTUVJWWlqqxsbHP+d3d3eru7g7+2fq/GzGPXS0N62/vLp9jf+yt+n5eZIA1onV9agz++iZqJNLn5JYazHdy1WC+E7bG6XPSDw5KI0aMuOBlox4+Pv74Y50/f165ubkh7bm5ufrjH//Y5/zq6mr99Kc/7dM+LM1B+MiIcGK0RmhXI5qfIDUGd30TNRLpc3JLDeY7uWow3wlfoz9LJmL+bZeqqir5/f7gq6WlJdZdAgAAQyjqdz7GjBmjiy66SG1tbSHtbW1tysvL63O+x+ORx+OJdjcAAECcivqdj4yMDBUXF6u+/q+/D+rt7VV9fb18Pl+0ywEAgAQT9TsfklRZWalFixZp+vTpuuaaa7RhwwZ1dnbq+9///lCUAwAACWRIwsfNN9+sjz76SPfcc49aW1t1xRVXaM+ePX0WoQIAgOQzJA8ZG4xAICCv16sdG9dqWFZmrLsDAAD64fSZLt26co38fr+ys7Mjnhvzb7sAAIDkQvgAAABGET4AAIBRhA8AAGDUkHzbJSrq1vTt3bSy8Oe+uTd6dakxuOubqJFIn5NbajDfyVWD+U6uGtGa73P9P5U7HwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACj2NUWAAAMGrvaAgCAuEX4AAAARhE+AACAUYQPAABgVGLtamuHHRiTqwbznVw1mO/kqsF8J24NdrUFAADxivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwKj4fcgYEEX/70BG2PZZ6enh3/D6KzZXujg6HYpQ45Wz4fsaSSKN45WeHmfXfzmKD0yiRoh3/tnmQKT/Bafa1JjmqLS9dyKM4fLwzVM2h28fe/uIsO2djS+GbT/dFKFfNoYVe8K2X9z9+7DtH70c/jq7r3VeO5Fx5wMAABhF+AAAAEYRPgAAgFGEDwAAYBQLTpEU7BZkruvsNNyTC7vrYueLQRNpHI4XnGLoZNq050V4zyib9txB9uUzbRGOXeTsUh892hG2fcpr+c4uNADvXHNiyGskMu58AAAAowgfAADAKMfh46WXXtKNN96o/Px8paSkaPfu3SHHLcvSPffco/HjxysrK0ulpaU6evRotPoLAAASnOM1H52dnZo2bZoWL16sBQsW9Dn+4IMPatOmTXr88cc1adIk3X333SorK9ORI0eUmWn3C8YwblkrZTk4387UssFfI5bXp0Z0arx+d1QuPyvCMbvHecUju3Ek0hgQBZfZtI+N8J4XbNq/bdM+xqbd5mFbtn2SpI8iHAtj4tbwxT+2WQsSTXa1P7jj4/Bv+KeHolc8Vj9rz3RJjWv69XbH4WPu3LmaO3du2GOWZWnDhg36yU9+onnz5kmSfvGLXyg3N1e7d+/WLbfc4rQcAABwmaiu+Th27JhaW1tVWloabPN6vSopKVFjY2PY93R3dysQCIS8AACAe0U1fLS2tkqScnNDv3OVm5sbPPZF1dXV8nq9wVdBQUE0uwQAAOJMzL/tUlVVJb/fH3y1tLTEuksAAGAIRfUhY3l5nz6Zpq2tTePHjw+2t7W16Yorrgj7Ho/HI48nzK6AdWv69m6azSKaN6O4WyQ1Bnd9EzUGdH1nD+6yW5D5zBi71XPSyx3hF7H9XXe3o9rR5HQc8TgGxID9/+bSN2za6x1ey24X3Ei1bRac2i3uHHZV+O157dpNsOurfllp/6ZE+Xl+rv+nRvXOx6RJk5SXl6f6+r/+XxgIBHTgwAH5fL5olgIAAAnK8Z2PTz75RO+9917wz8eOHdMbb7yhUaNGqbCwUKtWrdIDDzygyZMnB79qm5+fr/nz50ez3wAAIEE5Dh+HDh3St7/91y90V1Z+eqto0aJF2r59u3784x+rs7NTS5cuVXt7u2bNmqU9e/Y4e8YHAABwLcfh41vf+pYsy7I9npKSovvvv1/333//oDoGxJLdw7bs1kRI0ro4XBfhdBzxOAbEmWhtIBdFsVzD4ZRtX580249Yi/m3XQAAQHIhfAAAAKMIHwAAwCjCBwAAMCqqDxmLKie72rp9R1ZqDP76UdrV1i0P23LLODBINhusqi3Ce961aZ/jsLbT3XHdbiC72sbbz3MHu9py5wMAABhF+AAAAEYRPgAAgFGEDwAAYFT8LjgNt6utnYTbYZUaQ3L9iDWc7WoLJIVWm/YTEd5jt7A00m604djtjmu3EDWCd24P3+Gxt48I2z6sOMxO6pJONzlfiO30Wh89avOU5Gsj7GprJ95+nsdqV1sAAIALIXwAAACjCB8AAMCo+F3zAUTRK2fPhm2/6+L4Wwti19dI3DIOGNZl0x7p+Y4fOWyPJrv+2rBbXzHW4fmRRPNayYQ7HwAAwCjCBwAAMIrwAQAAjCJ8AAAAo1hwOoTmv+zwDS9H8cEwUarxzj/bHMiI8KapNjWmOSpt750IY7g8fPMrL/eEb+8J3x6PbOdCkjJsxjF1SLoS6p3wzYtsFgdO2Tx0XTHJ8d+NGM6F3ULN2x8L39lZ6enR6U+U2S1inmXzmduOY0dv+PaBLNx2eC37hdiJ87MoGrjzAQAAjCJ8AAAAowgfAADAKMIHAAAwigWniMzuSYd5Ed4zyqY9d5B9+UxbhGMXRalGPIr01Em7+RjquZDs58PNcyE5/7sRh3NhtyBzXWdndPoTZU6f5BuP47AfAwtOAQAAhgzhAwAAGEX4AAAARsXvmo9b1kpZkX7J3U9TywZ/jYFe/+XKoa1twmU27XZbOUrSCzbt37ZpH2PTbveQNrs+SWZ21oyVSOO2m4+hngvJvl9ungvJ+d+NaM2F5PzvhoG5mGXT/srQl44auzFIBsbxTw9F71pD/e+eXY0zXVLjmn69nTsfAADAKMIHAAAwivABAACMInwAAACj4nfBad2avr2bZrOI5s0o7gZrooYbRFoM9w2b9nqH17LbBTdSbbcvcrRj95kM9VxEeg9zESpacyE5/7sRxbmwW5T5zJjwxV/u6Ajb/nfd3VHqkXNOxyAZGMcvI3xBYaj/XbK7vtMa5/p/Knc+AACAUYQPAABglKPwUV1drauvvlojRozQuHHjNH/+fDU3N4ec09XVpYqKCo0ePVrDhw9XeXm52toibcYBAACSiaM1Hw0NDaqoqNDVV1+tc+fOac2aNbr++ut15MgRXfx/m+WsXr1azzzzjHbu3Cmv16vly5drwYIFevXVV4dkAIhD0dwoC4PDXMQPl8yF3cO27NZErIvh2g47Tscgxec4Epmj8LFnz56QP2/fvl3jxo1TU1OTvvGNb8jv92vbtm3asWOHZs+eLUmqra3VlClTtH//fs2YMSN6PQcAAAlpUGs+/H6/JGnUqE/3im5qatLZs2dVWloaPKeoqEiFhYVqbGwMe43u7m4FAoGQFwAAcK8Bh4/e3l6tWrVKM2fO1GWXfbqhQGtrqzIyMpSTkxNybm5urlpbW8Nep7q6Wl6vN/gqKCgYaJcAAEACGHD4qKio0Ntvv626urpBdaCqqkp+vz/4amlpGdT1AABAfBvQQ8aWL1+up59+Wi+99JImTJgQbM/Ly1NPT4/a29tD7n60tbUpLy8v7LU8Ho88Hk/fA052tY3VDn4X4oZdbT+2aY/0BaZ3bdrnOKztdBdQt7ObC8l+PoZ6LiTm44uGei6kuPy7EcuHhkVLTMcwkF1t4+3fvqHa1dayLC1fvly7du3S888/r0mTJoUcLy4uVnp6uurr//rIvubmZh0/flw+n89JKQAA4FKO7nxUVFRox44d+u1vf6sRI0YE13F4vV5lZWXJ6/VqyZIlqqys1KhRo5Sdna0VK1bI5/PxTRcAACDJYfjYsmWLJOlb3/pWSHttba1uu+02SdL69euVmpqq8vJydXd3q6ysTJs3b45KZwEAQOJzFD4sy7rgOZmZmaqpqVFNTc2AOwUAANwrsXa1tROtHfkGUsPtu92G/4a0dCLCe+wW0EXapTMcu11AIy1+dDO7uZDs52Oo50JiPr5oqOdC4u+GG0Xa1dZOvO30zq62AAAgXhE+AACAUYQPAABgVPyu+UB86LJpj/T8t48ctkeTXX/dINLY7OaDuRg6Tv9uxOFcvHL2bNj2u/5vl/J4Y9dfO/E4DrsxJNvDKLjzAQAAjCJ8AAAAowgfAADAKMIHAAAwigWniGjKw7HuAT7DXMQXd8xHT9jWV3rCtyeaRBrHj2LdAcO48wEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwKn4fMnbLWikr0tap/TS1bPDXGOj1X64c2toAAHf4p4eid62h/nfPrsaZLqlxTb/ezp0PAABgFOEDAAAYRfgAAABGET4AAIBR8bvgtG5N395Ns1lE8+be6NU1UQMAgM/7ZYQvKAz1v0t213da41z/T+XOBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMCo+H3ImJNdbWO1g9+FsKstAKA/BrKrbbz928eutgAAIF4RPgAAgFGEDwAAYJSj8LFlyxZNnTpV2dnZys7Ols/n07PPPhs83tXVpYqKCo0ePVrDhw9XeXm52traot5pAACQuBwtOJ0wYYLWrVunyZMny7IsPf7445o3b54OHz6sr3/961q9erWeeeYZ7dy5U16vV8uXL9eCBQv06quvOu9ZuF1t7URrR76B1GC3WwDAYEXa1dZOvO307mBXW0fh48Ybbwz5889+9jNt2bJF+/fv14QJE7Rt2zbt2LFDs2fPliTV1tZqypQp2r9/v2bMmOGkFAAAcKkBr/k4f/686urq1NnZKZ/Pp6amJp09e1alpaXBc4qKilRYWKjGxkbb63R3dysQCIS8AACAezkOH2+99ZaGDx8uj8ejO+64Q7t27dKll16q1tZWZWRkKCcnJ+T83Nxctba22l6vurpaXq83+CooKHA8CAAAkDgch4+vfe1reuONN3TgwAEtW7ZMixYt0pEjRwbcgaqqKvn9/uCrpaVlwNcCAADxz/ETTjMyMvSVr3xFklRcXKyDBw9q48aNuvnmm9XT06P29vaQux9tbW3Ky8uzvZ7H45HH43HecwAAkJAG/ZyP3t5edXd3q7i4WOnp6aqvrw8ea25u1vHjx+Xz+QZbBgAAuISjOx9VVVWaO3euCgsL1dHRoR07dujFF1/U3r175fV6tWTJElVWVmrUqFHKzs7WihUr5PP5+KYLAAAIchQ+Tp06pe9973s6efKkvF6vpk6dqr179+q6666TJK1fv16pqakqLy9Xd3e3ysrKtHnz5iHpOAAASEyOwse2bdsiHs/MzFRNTY1qamoG1Sm32H2twzfE2wNj4rWGWx4qR43BXd9EjUT6nNxSYwDzPf/l6JSGOeztAgAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADAqxbIsK9ad+LxAICCv16sdG9dqWFZmrLsDAIhz85dWxroLg7b7kYdi3YVBO32mS7euXCO/36/s7OyI53LnAwAAGEX4AAAARhE+AACAUYQPAABglKNdbY2qW9O3d27YsdEtNdhpNLlqMN/JVcMt851Ifhlh0WyizPe5/p/KnQ8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUexqCwBIaOxqGx/Y1RYAAMQtwgcAADCK8AEAAIwifAAAAKMSa1dbO27ZgZEag7u+iRqJ9Dm5pQbznVw1TMx3PIq0q62deJtvdrUFAADxivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMGFT7WrVunlJQUrVq1KtjW1dWliooKjR49WsOHD1d5ebna2toG208AAOASAw4fBw8e1MMPP6ypU6eGtK9evVpPPfWUdu7cqYaGBp04cUILFiwYdEcBAIA7DCh8fPLJJ1q4cKEeffRRjRw5Mtju9/u1bds2PfTQQ5o9e7aKi4tVW1ur3//+99q/f3/UOg0AABLXgMJHRUWFbrjhBpWWloa0NzU16ezZsyHtRUVFKiwsVGNjY9hrdXd3KxAIhLwAAIB7Od7bpa6uTq+//roOHjzY51hra6syMjKUk5MT0p6bm6vW1taw16uurtZPf/pTp90AAAAJytGdj5aWFq1cuVJPPvmkMjMzo9KBqqoq+f3+4KulpSUq1wUAAPHJUfhoamrSqVOndNVVVyktLU1paWlqaGjQpk2blJaWptzcXPX09Ki9vT3kfW1tbcrLywt7TY/Ho+zs7JAXAABwL0e/dpkzZ47eeuutkLbvf//7Kioq0p133qmCggKlp6ervr5e5eXlkqTm5mYdP35cPp8ver0GAAAJy1H4GDFihC677LKQtosvvlijR48Oti9ZskSVlZUaNWqUsrOztWLFCvl8Ps2YMSN6vQYAAAnL8YLTC1m/fr1SU1NVXl6u7u5ulZWVafPmzdEuAwAAElSKZVlWrDvxeYFAQF6vVzs2rtWwrOgsagUAuNf8pZWx7sKg7X7koVh3YdBOn+nSrSvXyO/3X3D9Jnu7AAAAowgfAADAKMIHAAAwivABAACMivq3XaKmbk3f3k0rC3/um3ujV5cag7u+iRqJ9Dm5pQbznVw13DLfieSXERbNJsp8n+v/qdz5AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABjFrrYAgITGrrbxgV1tAQBA3CJ8AAAAowgfAADAKMIHAAAwKrF2tbXjlh0YqTG465uokUifk1tqMN/JVcPEfMejSLva2om3+WZXWwAAEK8IHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMit+HjAEA0A+7r3X4hnh7OFcS4s4HAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMchY/77rtPKSkpIa+ioqLg8a6uLlVUVGj06NEaPny4ysvL1dbWFvVOAwCAxJViWZbV35Pvu+8+/eY3v9Fzzz0XbEtLS9OYMWMkScuWLdMzzzyj7du3y+v1avny5UpNTdWrr77a7w4FAgF5vV7t2LhWw7IyHQwFAADEyukzXbp15Rr5/X5lZ2dHPNfxE07T0tKUl5fXp93v92vbtm3asWOHZs+eLUmqra3VlClTtH//fs2YMcNpKQAA4EKO13wcPXpU+fn5+tKXvqSFCxfq+PHjkqSmpiadPXtWpaWlwXOLiopUWFioxsZG2+t1d3crEAiEvAAAgHs5Ch8lJSXavn279uzZoy1btujYsWO69tpr1dHRodbWVmVkZCgnJyfkPbm5uWptbbW9ZnV1tbxeb/BVUFAwoIEAAIDE4OjXLnPnzg3+99SpU1VSUqKJEyfq17/+tbKysgbUgaqqKlVWVgb/HAgECCAAALjYoHa1zcnJ0Ve/+lW99957uu6669TT06P29vaQux9tbW1h14h8xuPxyOPx9D1Qt6Zv79yyE6Ebathd30SNRPqc3FKD+U6uGsx3ctWI1nyf6/+pg3rOxyeffKI//elPGj9+vIqLi5Wenq76+vrg8ebmZh0/flw+n28wZQAAgIs4uvPxox/9SDfeeKMmTpyoEydO6N5779VFF12k73znO/J6vVqyZIkqKys1atQoZWdna8WKFfL5fHzTBQAABDkKH3/+85/1ne98R//7v/+rsWPHatasWdq/f7/Gjh0rSVq/fr1SU1NVXl6u7u5ulZWVafPmzUPScQAAkJgchY+6urqIxzMzM1VTU6OamppBdQoAALgXe7sAAACjCB8AAMAowgcAADCK8AEAAIxytKutCexqCwBA4nGyqy13PgAAgFGEDwAAYBThAwAAGEX4AAAARg1qV9shFW5XWzvswJhcNZjv5KrBfCdXDeY7cWuY2tUWAADAKcIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMCoFMuyrFh34vMCgYC8Xq92bFyrYVmZse4OAADoh9NnunTryjXy+/3Kzs6OeC53PgAAgFGEDwAAYBThAwAAGEX4AAAARqXFugO26tb07d20svDnvrk3enWpMbjrm6iRSJ+TW2ow38lVg/lOrhrRmu9z/T+VOx8AAMAowgcAADDKcfj48MMP9d3vflejR49WVlaWLr/8ch06dCh43LIs3XPPPRo/fryysrJUWlqqo0ePRrXTAAAgcTkKH3/5y180c+ZMpaen69lnn9WRI0f085//XCNHjgye8+CDD2rTpk3aunWrDhw4oIsvvlhlZWXq6uqKeucBAEDicbTg9N/+7d9UUFCg2traYNukSZOC/21ZljZs2KCf/OQnmjdvniTpF7/4hXJzc7V7927dcsstUeo2AABIVI7ufPzud7/T9OnTddNNN2ncuHG68sor9eijjwaPHzt2TK2trSotLQ22eb1elZSUqLGxMew1u7u7FQgEQl4AAMC9HIWP999/X1u2bNHkyZO1d+9eLVu2TD/84Q/1+OOPS5JaW1slSbm5uSHvy83NDR77ourqanm93uCroKBgIOMAAAAJwlH46O3t1VVXXaW1a9fqyiuv1NKlS3X77bdr69atA+5AVVWV/H5/8NXS0jLgawEAgPjnaFfbiRMn6rrrrtNjjz0WbNuyZYseeOABffjhh3r//ff15S9/WYcPH9YVV1wRPOeb3/ymrrjiCm3cuPGCNdjVFgCAxDNku9rOnDlTzc3NIW3vvvuuJk6cKOnTxad5eXmqr68PHg8EAjpw4IB8Pp+TUgAAwKUcfdtl9erV+tu//VutXbtW//iP/6jXXntNjzzyiB555BFJUkpKilatWqUHHnhAkydP1qRJk3T33XcrPz9f8+fPH4r+AwCABOMofFx99dXatWuXqqqqdP/992vSpEnasGGDFi5cGDznxz/+sTo7O7V06VK1t7dr1qxZ2rNnjzIz+RUKAABwuObDBNZ8AACQeJys+UisXW3tsANjctVgvpOrBvOdXDWY78Stwa62AAAgXhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGpViWZcW6E58XCATk9Xq1Y+NaDcvKjHV3AABAP5w+06VbV66R3+9XdnZ2xHO58wEAAIwifAAAAKMIHwAAwCjCBwAAMCot1h2wVbemb++mlYU/98290atLjcFd30SNRPqc3FKD+U6uGsx3ctWI1nyf6/+p3PkAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGMWutgAAYNDY1RYAAMQtwgcAADDKUfi45JJLlJKS0udVUVEhSerq6lJFRYVGjx6t4cOHq7y8XG1tbUPScQAAkJgchY+DBw/q5MmTwde+ffskSTfddJMkafXq1Xrqqae0c+dONTQ06MSJE1qwYEH0ew0AABLWoBacrlq1Sk8//bSOHj2qQCCgsWPHaseOHfqHf/gHSdIf//hHTZkyRY2NjZoxY0a/rhlccOqThvV3z112YEyuGsx3ctVgvpOrBvOdsDVOn5NubdTQLjjt6enRE088ocWLFyslJUVNTU06e/asSktLg+cUFRWpsLBQjY2Nttfp7u5WIBAIeQEAAPcacPjYvXu32tvbddttt0mSWltblZGRoZycnJDzcnNz1draanud6upqeb3e4KugoGCgXQIAAAlgwOFj27Ztmjt3rvLz8wfVgaqqKvn9/uCrpaVlUNcDAADxrb+rKkJ88MEHeu655/Rf//Vfwba8vDz19PSovb095O5HW1ub8vLybK/l8Xjk8XgG0g0AAJCABnTno7a2VuPGjdMNN9wQbCsuLlZ6errq6+uDbc3NzTp+/Lh8Pt/gewoAAFzB8Z2P3t5e1dbWatGiRUpL++vbvV6vlixZosrKSo0aNUrZ2dlasWKFfD5fv7/pAgAA3M9x+Hjuued0/PhxLV68uM+x9evXKzU1VeXl5eru7lZZWZk2b94clY4CAAB3cBw+rr/+etk9GiQzM1M1NTWqqakZdMcAAIA7sbcLAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMCrFsntcaYwEAgF5vV7t2LhWw7IyY90dAADQD6fPdOnWlWvk9/uVnZ0d8VzufAAAAKMIHwAAwCjCBwAAMIrwAQAAjEqLdQds1a3p27tpZeHPfXNv9OpSY3DXN1EjkT4nt9RgvpOrBvOdXDWiNd/n+n8qdz4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARrGrLQAAGDR2tQUAAHGL8AEAAIwifAAAAKMIHwAAwKjE2tXWDjswJlcN5ju5ajDfyVWD+U7cGuxqCwAA4hXhAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGxd1zPj7b5+60g+8LqyfCyU6uM5Aa0bo+NQZ/fRM1EulzcksN5ju5ajDfCVvjs3+3+7NfbdztavvnP/9ZBQUFse4GAAAYgJaWFk2YMCHiOXEXPnp7e3XixAmNGDFCHR0dKigoUEtLywW353WTQCDAuBm36zFuxp0MkmnclmWpo6ND+fn5Sk2NvKoj7n7tkpqaGkxMKSkpkqTs7GzXT1o4jDu5MO7kwriTS7KM2+v19us8FpwCAACjCB8AAMCouA4fHo9H9957rzweT6y7YhTjZtzJgHEz7mSQrOO+kLhbcAoAANwtru98AAAA9yF8AAAAowgfAADAKMIHAAAwivABAACMiuvwUVNTo0suuUSZmZkqKSnRa6+9FusuRdVLL72kG2+8Ufn5+UpJSdHu3btDjluWpXvuuUfjx49XVlaWSktLdfTo0dh0Noqqq6t19dVXa8SIERo3bpzmz5+v5ubmkHO6urpUUVGh0aNHa/jw4SovL1dbW1uMehwdW7Zs0dSpU4NPOvT5fHr22WeDx9045i9at26dUlJStGrVqmCbW8d93333KSUlJeRVVFQUPO7WcUvShx9+qO9+97saPXq0srKydPnll+vQoUPB42782XbJJZf0me+UlBRVVFRIcvd8D0Tcho9f/epXqqys1L333qvXX39d06ZNU1lZmU6dOhXrrkVNZ2enpk2bppqamrDHH3zwQW3atElbt27VgQMHdPHFF6usrExdXV2GexpdDQ0Nqqio0P79+7Vv3z6dPXtW119/vTo7O4PnrF69Wk899ZR27typhoYGnThxQgsWLIhhrwdvwoQJWrdunZqamnTo0CHNnj1b8+bN0//8z/9IcueYP+/gwYN6+OGHNXXq1JB2N4/761//uk6ePBl8vfLKK8Fjbh33X/7yF82cOVPp6el69tlndeTIEf385z/XyJEjg+e48WfbwYMHQ+Z63759kqSbbrpJknvne8CsOHXNNddYFRUVwT+fP3/eys/Pt6qrq2PYq6Ejydq1a1fwz729vVZeXp717//+78G29vZ2y+PxWP/5n/8Zgx4OnVOnTlmSrIaGBsuyPh1nenq6tXPnzuA577zzjiXJamxsjFU3h8TIkSOtxx57zPVj7ujosCZPnmzt27fP+uY3v2mtXLnSsix3z/W9995rTZs2LewxN4/7zjvvtGbNmmV7PFl+tq1cudL68pe/bPX29rp6vgcqLu989PT0qKmpSaWlpcG21NRUlZaWqrGxMYY9M+fYsWNqbW0N+Qy8Xq9KSkpc9xn4/X5J0qhRoyRJTU1NOnv2bMjYi4qKVFhY6Jqxnz9/XnV1ders7JTP53P9mCsqKnTDDTeEjE9y/1wfPXpU+fn5+tKXvqSFCxfq+PHjktw97t/97neaPn26brrpJo0bN05XXnmlHn300eDxZPjZ1tPToyeeeEKLFy9WSkqKq+d7oOIyfHz88cc6f/68cnNzQ9pzc3PV2toao16Z9dk43f4Z9Pb2atWqVZo5c6Yuu+wySZ+OPSMjQzk5OSHnumHsb731loYPHy6Px6M77rhDu3bt0qWXXurqMdfV1en1119XdXV1n2NuHndJSYm2b9+uPXv2aMuWLTp27JiuvfZadXR0uHrc77//vrZs2aLJkydr7969WrZsmX74wx/q8ccfl5QcP9t2796t9vZ23XbbbZLc/f/5QKXFugNIbhUVFXr77bdDfhfuZl/72tf0xhtvyO/36ze/+Y0WLVqkhoaGWHdryLS0tGjlypXat2+fMjMzY90do+bOnRv876lTp6qkpEQTJ07Ur3/9a2VlZcWwZ0Ort7dX06dP19q1ayVJV155pd5++21t3bpVixYtinHvzNi2bZvmzp2r/Pz8WHclbsXlnY8xY8booosu6rMSuK2tTXl5eTHqlVmfjdPNn8Hy5cv19NNP64UXXtCECROC7Xl5eerp6VF7e3vI+W4Ye0ZGhr7yla+ouLhY1dXVmjZtmjZu3OjaMTc1NenUqVO66qqrlJaWprS0NDU0NGjTpk1KS0tTbm6uK8cdTk5Ojr761a/qvffec+18S9L48eN16aWXhrRNmTIl+Csnt/9s++CDD/Tcc8/pBz/4QbDNzfM9UHEZPjIyMlRcXKz6+vpgW29vr+rr6+Xz+WLYM3MmTZqkvLy8kM8gEAjowIEDCf8ZWJal5cuXa9euXXr++ec1adKkkOPFxcVKT08PGXtzc7OOHz+e8GP/ot7eXnV3d7t2zHPmzNFbb72lN954I/iaPn26Fi5cGPxvN447nE8++UR/+tOfNH78eNfOtyTNnDmzz1fn3333XU2cOFGSu3+2SVJtba3GjRunG264Idjm5vkesFiveLVTV1dneTwea/v27daRI0espUuXWjk5OVZra2usuxY1HR0d1uHDh63Dhw9bkqyHHnrIOnz4sPXBBx9YlmVZ69ats3Jycqzf/va31h/+8Adr3rx51qRJk6wzZ87EuOeDs2zZMsvr9VovvviidfLkyeDr9OnTwXPuuOMOq7Cw0Hr++eetQ4cOWT6fz/L5fDHs9eDdddddVkNDg3Xs2DHrD3/4g3XXXXdZKSkp1n//939bluXOMYfz+W+7WJZ7x/2v//qv1osvvmgdO3bMevXVV63S0lJrzJgx1qlTpyzLcu+4X3vtNSstLc362c9+Zh09etR68sknrWHDhllPPPFE8By3/mw7f/68VVhYaN155519jrl1vgcqbsOHZVnWf/zHf1iFhYVWRkaGdc0111j79++PdZei6oUXXrAk9XktWrTIsqxPv5J29913W7m5uZbH47HmzJljNTc3x7bTURBuzJKs2tra4Dlnzpyx/uVf/sUaOXKkNWzYMOvv//7vrZMnT8au01GwePFia+LEiVZGRoY1duxYa86cOcHgYVnuHHM4Xwwfbh33zTffbI0fP97KyMiw/uZv/sa6+eabrffeey943K3jtizLeuqpp6zLLrvM8ng8VlFRkfXII4+EHHfrz7a9e/daksKOxc3zPRAplmVZMbnlAgAAklJcrvkAAADuRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUf8fkjxVINWabPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 4\n",
    "a_seqs = ([a,a,1,1],[a,a,1,1],[a,a,1,0],[a,a,1,0],[a,a,1,0])\n",
    "\n",
    "#a_seqs = ([2,4,0],[2,2,0],[2,2,0],[2,2,0],[2,3,0])\n",
    "\n",
    "for n, act in enumerate(a_seqs):\n",
    "    print(\"=========%d========\"%n)\n",
    "    a_tensor = torch.tensor([[act]]).long()\n",
    "    print(\"a_tensor\", a_tensor)\n",
    "    obs = env.step(a_tensor)\n",
    "    print(\"eps_step\", obs['episode_step'])\n",
    "    print(\"eps_return\", obs['episode_return'])\n",
    "    print(\"reward\", obs['reward'])\n",
    "    print(\"cur_t\", obs['cur_t'])\n",
    "    print(\"thres\", env.gym_env.thres)\n",
    "    print(\"root_node qs\", [x / 0.97 for x in env.gym_env.root_node.rollout_qs])\n",
    "    print(\"child_node qs\", env.gym_env.root_node.children[a].rollout_qs)\n",
    "    plot_obs(env.gym_env.x_/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_seqs = [[0,0,0]]\n",
    "\n",
    "for n, a in enumerate(a_seqs):\n",
    "    print(\"=========%d========\"%n)\n",
    "    a_tensor = torch.tensor([[a]]).long()\n",
    "    print(\"a_tensor\", a_tensor)\n",
    "    obs = env.step(a_tensor)\n",
    "    print(\"eps_step\", obs['episode_step'])\n",
    "    print(\"eps_return\", obs['episode_return'])\n",
    "    print(\"reward\", obs['reward'])\n",
    "    print(\"cur_t\", obs['cur_t'])\n",
    "    plot_obs(env.gym_env.x_/255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
