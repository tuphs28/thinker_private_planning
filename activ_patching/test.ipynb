{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/mlmi/dissertation/working_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-15 11:04:45,997\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import thinker\n",
    "import thinker.viz_utils as viz\n",
    "import thinker.util as util\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import os\n",
    "import torch\n",
    "from thinker.actor_net import sample, DRCNet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0113, 0.9598, 0.0120, 0.0087, 0.0082]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_n = 1\n",
    "gpu = False\n",
    "mini_sokoban = True \n",
    "mini_unqtar = False\n",
    "mini_unqbox = False\n",
    "\n",
    "env = thinker.make(\n",
    "    \"Sokoban-cutoffpush_corrupt_0000-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    "    ) \n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) \n",
    "flags.mini = mini_sokoban\n",
    "flags.mini_unqbtar = mini_unqtar\n",
    "flags.mini_unqbox = mini_unqbox\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "state, reward, done, info = env.step(actor_out.action)\n",
    "env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "actor_out, new_rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "actor_out.action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0117, 0.9528, 0.0092, 0.0138, 0.0125]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "state, reward, done, info = env.step(actor_out.action)\n",
    "env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "actor_out.action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActPatchDRCNet:\n",
    "\n",
    "    def __init__(self, drc_net):\n",
    "        self.drc_net = drc_net\n",
    "\n",
    "    def forward_normal(self, env_out, rnn_state):\n",
    "        return self.drc_net(env_out, rnn_state)\n",
    "    \n",
    "    def forward_patch(self, env_out, rnn_state, greedy=True, activ_type=None, patch_dict={}, activ_ticks=[], activs=None):\n",
    "        \n",
    "        activ_layers = list(patch_dict.keys())\n",
    "\n",
    "        done = env_out.done\n",
    "        T, B = done.shape\n",
    "        x = self.drc_net.normalize(env_out.real_states.float())\n",
    "        x = torch.flatten(x, 0, 1)\n",
    "        x_enc = self.drc_net.encoder(x)\n",
    "        core_input = x_enc.view(*((T, B) + x_enc.shape[1:]))\n",
    "\n",
    "        record_state=self.drc_net.record_state\n",
    "\n",
    "        assert len(core_input.shape) == 5\n",
    "        core_output_list = []\n",
    "        reset = done.float()\n",
    "        if self.drc_net.record_state: \n",
    "            self.drc_net.core.hidden_state = []\n",
    "            self.drc_net.core.hidden_state.append(torch.concat(rnn_state, dim=1)) \n",
    "        for n, (x_single, reset_single) in enumerate(\n",
    "            zip(core_input.unbind(), reset.unbind())\n",
    "        ):\n",
    "            for t in range(self.drc_net.core.tran_t):\n",
    "                if t > 0:\n",
    "                    reset_single = torch.zeros_like(reset_single)\n",
    "                reset_single = reset_single.view(-1)\n",
    "                if t in activ_ticks and (0 in activ_layers or 1 in activ_layers or 2 in activ_layers):\n",
    "                    #print(f\"----- patching activations for tick {t} ---- \")\n",
    "                    output, rnn_state = self.forward_single_patch(\n",
    "                        x=x_single,\n",
    "                        core_state=rnn_state,\n",
    "                        reset=reset_single,\n",
    "                        activ_type=activ_type, \n",
    "                        patch_dict=patch_dict,\n",
    "                        activs=activs[:,t,:,:,:]\n",
    "                    )  # output shape: 1, B, core_output_size\n",
    "                else:\n",
    "                    output, rnn_state = self.drc_net.core.forward_single(\n",
    "                        x_single, rnn_state, reset_single, reset_single\n",
    "                    )        \n",
    "                if self.drc_net.record_state: self.drc_net.core.hidden_state.append(torch.concat(rnn_state, dim=1))      \n",
    "            core_output_list.append(output)\n",
    "        core_output = torch.cat(core_output_list)\n",
    "        if self.drc_net.record_state: \n",
    "           self.drc_net.core.hidden_state = torch.stack(self.drc_net.core.hidden_state, dim=1)\n",
    "\n",
    "        core_output = torch.flatten(core_output, 0, 1)\n",
    "\n",
    "        if activ_type == \"xenc\" and 3 in activ_layers and 2 in activ_ticks:\n",
    "            #print(f\"--- Patching Layer 3 ---\")\n",
    "            #### activ_channels = [192+ c patch_dict[3]]\n",
    "            patch_channels = patch_dict[3]\n",
    "            x_enc[:,patch_channels,:,:] = activs[:,-1,[192+c for c in patch_channels],:,:]\n",
    "\n",
    "        core_output = torch.cat([x_enc, core_output], dim=1)\n",
    "\n",
    "        core_output = torch.flatten(core_output, 1)\n",
    "        final_out = torch.nn.functional.relu(self.drc_net.final_layer(core_output))\n",
    "        pri_logits = self.drc_net.policy(final_out)\n",
    "        pri_logits = pri_logits.view(T*B, self.drc_net.dim_actions, self.drc_net.num_actions)\n",
    "        pri_probs = torch.nn.functional.softmax(pri_logits.view(-1), dim=0)\n",
    "        pri = sample(pri_logits, greedy=greedy, dim=-1)\n",
    "        pri = pri.view(T, B, self.drc_net.dim_actions) \n",
    "        pri_env = pri[-1, :, 0] if not self.drc_net.tuple_action else pri[-1]   \n",
    "        action = pri_env\n",
    "        return action, pri_probs, pri_logits.view(-1), rnn_state\n",
    "    \n",
    "    def forward_single_patch(self, x, core_state, reset, activ_type=None, patch_dict={}, activs=None):\n",
    "        reset = reset.float()\n",
    "\n",
    "        activ_layers = list(patch_dict.keys())\n",
    "\n",
    "        b, c, h, w = x.shape\n",
    "        layer_n = 2\n",
    "        out = core_state[(self.drc_net.core.num_layers - 1) * layer_n] * (1 - reset).view(\n",
    "            b, 1, 1, 1\n",
    "        )  # h_cur on last layer\n",
    "\n",
    "        core_out = []\n",
    "        new_core_state = []\n",
    "        for n, cell in enumerate(self.drc_net.core.layers):\n",
    "            cell_input = torch.concat([x, out], dim=1)\n",
    "            h_cur = core_state[n * layer_n + 0] * (1 - reset.view(b, 1, 1, 1))\n",
    "            c_cur = core_state[n * layer_n + 1] * (1 - reset.view(b, 1, 1, 1))\n",
    "        \n",
    "            if n in activ_layers and activ_type is not None:\n",
    "                #print(f\"--- Patching Layer {n} ---\")\n",
    "                patch_channels = patch_dict[n]\n",
    "                if activ_type == \"xenc\":\n",
    "                    patch_activs = activs[:,[192+c for c in patch_channels],:,:].detach().clone()\n",
    "                elif activ_type == \"hidden\":\n",
    "                    patch_activs = activs[:,[64*n+c for c in patch_channels],:,:].detach().clone()\n",
    "                elif activ_type == \"cell\":\n",
    "                    patch_activs = activs[:,[64*n+32+c for c in patch_channels],:,:].detach().clone()\n",
    "\n",
    "                if activ_type == \"xenc\" and n in activ_layers:\n",
    "                    #print(f\"patching channels {patch_channels} in xenc\")\n",
    "                    cell_input[:,patch_channels,:,:] = patch_activs\n",
    "\n",
    "                #print(\"out, x, cell_input:\", out.sum(), x.sum(), cell_input.sum())\n",
    "\n",
    "                h_next, c_next = self.forward_cell_patch(\n",
    "                    convlstm_cell=cell,\n",
    "                    input=cell_input,\n",
    "                    h_cur=h_cur,\n",
    "                    c_cur=c_cur,\n",
    "                    activ_type=activ_type,\n",
    "                    patch_channels=patch_channels, \n",
    "                    patch_activs=patch_activs\n",
    "                )\n",
    "            else:\n",
    "                #print(f\"--- NOT patching layer {n} ---\")\n",
    "                h_next, c_next, concat_k, concat_v = cell(\n",
    "                    cell_input, h_cur, c_cur, None, None, None\n",
    "                )\n",
    "            if self.drc_net.core.grad_scale < 1 and h_next.requires_grad:\n",
    "                h_next.register_hook(lambda grad: grad * self.drc_net.core.grad_scale)\n",
    "                c_next.register_hook(lambda grad: grad * self.drc_net.core.grad_scale)\n",
    "            new_core_state.append(h_next)\n",
    "            new_core_state.append(c_next)\n",
    "            out = h_next\n",
    "\n",
    "        core_state = tuple(new_core_state)\n",
    "        core_out = out.unsqueeze(0)\n",
    "        return core_out, core_state\n",
    "    \n",
    "    def forward_cell_patch(self, convlstm_cell, input, h_cur, c_cur, activ_type=None, patch_channels=[], patch_activs=None):\n",
    "        B = input.shape[0]\n",
    "        #print(\"h_cur, c_cur, input\", h_cur.sum(), c_cur.sum(), input.sum())\n",
    "        combined = torch.cat([input, h_cur], dim=1)  # concatenate along channel axis\n",
    "        if convlstm_cell.pool_inject:\n",
    "            combined = torch.cat(\n",
    "                [combined, convlstm_cell.proj_max_mean(h_cur)], dim=1\n",
    "            )  # concatenate along channel axis\n",
    "        if convlstm_cell.linear:\n",
    "            combined_conv = convlstm_cell.main(combined[:, :, 0, 0]).unsqueeze(-1).unsqueeze(-1)\n",
    "        else:\n",
    "            combined_conv = convlstm_cell.main(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g, cc_a = torch.split(combined_conv, convlstm_cell.embed_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        #print(\"c_next:\", c_next.sum())\n",
    "        if activ_type==\"cell\":\n",
    "            #print(f\"patching channels {patch_channels} in cell\")\n",
    "            c_next[:,patch_channels,:,:] = patch_activs\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        if activ_type==\"hidden\":\n",
    "            #print(f\"patching channels {patch_channels} in hidden\")\n",
    "            h_next[:,patch_channels,:,:] = patch_activs\n",
    "        #print(h_next.sum())\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actpatchdrc import ActPatchDRCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.008234323933720589, 0.005635156761854887, 0.0043194834142923355, 0.9769455194473267, 0.004865469876676798]\n",
      "corrupt: [0.008973920717835426, 0.9691113829612732, 0.006021568551659584, 0.008533252403140068, 0.007359775248914957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.011133219115436077, 0.9689761996269226, 0.007548628840595484, 0.005681069102138281, 0.0066608889028429985]\n",
      "corrupt: [0.00742545397952199, 0.006735776085406542, 0.007486819289624691, 0.0049478174187242985, 0.9734041094779968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.010836985893547535, 0.006020986940711737, 0.004456295631825924, 0.006134104449301958, 0.9725516438484192]\n",
      "corrupt: [0.008922502398490906, 0.006932535674422979, 0.9682967066764832, 0.007956067100167274, 0.007892311550676823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.009504793211817741, 0.0065822056494653225, 0.9743398427963257, 0.004096832126379013, 0.005476233549416065]\n",
      "corrupt: [0.0074764578603208065, 0.005434134509414434, 0.006897774990648031, 0.9737632274627686, 0.006428353954106569]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.0092707434669137, 0.005745583213865757, 0.005578705109655857, 0.006626136600971222, 0.9727787971496582]\n",
      "corrupt: [0.007109495345503092, 0.9773394465446472, 0.0052839783020317554, 0.004746792372316122, 0.005520206410437822]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.011948324739933014, 0.00996183417737484, 0.960383951663971, 0.008581873029470444, 0.009124068543314934]\n",
      "corrupt: [0.008336116559803486, 0.005344535689800978, 0.009758259169757366, 0.007924509234726429, 0.9686365723609924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.009909654967486858, 0.008772057481110096, 0.004675941541790962, 0.9693443179130554, 0.0072980173863470554]\n",
      "corrupt: [0.006174164824187756, 0.0036624681670218706, 0.9820552468299866, 0.003887529717758298, 0.0042206523939967155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.01185438223183155, 0.9676253199577332, 0.00806732103228569, 0.0051588742062449455, 0.00729399872943759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupt: [0.008512984029948711, 0.006370855495333672, 0.005398996639996767, 0.9725676774978638, 0.007149473298341036]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.010190370492637157, 0.006555916275829077, 0.006333584431558847, 0.9704686999320984, 0.006451509892940521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupt: [0.008491558954119682, 0.9699371457099915, 0.007964941672980785, 0.007286147214472294, 0.00632021389901638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.008744507096707821, 0.9772579073905945, 0.006981835700571537, 0.0033028707839548588, 0.003712874837219715]\n",
      "corrupt: [0.007819700986146927, 0.005759280640631914, 0.009864658117294312, 0.005386981647461653, 0.9711694121360779]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.012786075472831726, 0.010696450248360634, 0.0044001080095767975, 0.00923982448875904, 0.9628775119781494]\n",
      "corrupt: [0.009437145665287971, 0.007477438077330589, 0.9695941805839539, 0.006753779016435146, 0.006737544666975737]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.009566453285515308, 0.011243247427046299, 0.9704217314720154, 0.003958316054195166, 0.004810221027582884]\n",
      "corrupt: [0.00675171846523881, 0.004800072871148586, 0.005542661063373089, 0.9774388670921326, 0.00546663161367178]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.010819394141435623, 0.004898427054286003, 0.0064840167760849, 0.009953847154974937, 0.9678443670272827]\n",
      "corrupt: [0.007032027933746576, 0.9774528741836548, 0.0063795363530516624, 0.004033856559544802, 0.0051017040386796]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.01110102515667677, 0.007894366979598999, 0.966131329536438, 0.007246202323585749, 0.007627174258232117]\n",
      "corrupt: [0.009361768141388893, 0.007593181915581226, 0.0107171181589365, 0.010142386890947819, 0.9621855616569519]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.013928024098277092, 0.013931716792285442, 0.006828133948147297, 0.9478470087051392, 0.017465058714151382]\n",
      "corrupt: [0.006182759068906307, 0.004507747013121843, 0.9802438020706177, 0.0032446293625980616, 0.0058210548013448715]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: [0.012295733205974102, 0.9592663645744324, 0.016326775774359703, 0.0052915881387889385, 0.0068194810301065445]\n",
      "corrupt: [0.007788241375237703, 0.005669744685292244, 0.005492666736245155, 0.9752206206321716, 0.005828700494021177]\n"
     ]
    }
   ],
   "source": [
    "# interv\n",
    "all_results = []\n",
    "eval_metric = \"prob\"\n",
    "exp = \"cutoffpush\"\n",
    "mini_sokoban = True\n",
    "mini_unqtar = False\n",
    "mini_unqbox = False\n",
    "gpu = False\n",
    "env_n = 1\n",
    "num_steps = 3\n",
    "for i in range(16):\n",
    "    results = {}\n",
    "    flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) \n",
    "    flags.mini = mini_sokoban\n",
    "    flags.mini_unqbtar = mini_unqtar\n",
    "    flags.mini_unqbox = mini_unqbox\n",
    "    env = thinker.make(\n",
    "        f\"Sokoban-{exp}_clean_{i:04}-v0\", \n",
    "        env_n=env_n, \n",
    "        gpu=gpu,\n",
    "        wrapper_type=1, \n",
    "        has_model=False, \n",
    "        train_model=False, \n",
    "        parallel=False, \n",
    "        save_flags=False,\n",
    "        mini=mini_sokoban,\n",
    "        mini_unqtar=mini_unqtar,\n",
    "        mini_unqbox=mini_unqbox         \n",
    "    ) \n",
    "\n",
    "    drc_net = DRCNet(\n",
    "        obs_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        flags=flags,\n",
    "        record_state=True,\n",
    "        )\n",
    "    drc_net.to(env.device)\n",
    "\n",
    "    ckp_path = \"../drc_mini\"\n",
    "    ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "    ckp = torch.load(ckp_path, env.device)\n",
    "    drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "    test_net = ActPatchDRCNet(drc_net)\n",
    "\n",
    "    clean_activs = []\n",
    "    corrupt_activs = []\n",
    "    clean_actions = []\n",
    "\n",
    "    rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "    state = env.reset()\n",
    "    env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "    for step in range(num_steps):\n",
    "        actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "        clean_activs.append(drc_net.hidden_state[:,1:,:,:])\n",
    "        #viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "        state, reward, done, info = env.step(actor_out.action)\n",
    "        clean_actions.append(actor_out.action)\n",
    "        env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "\n",
    "    #viz.plot_mini_sokoban(state[\"real_states\"][0])    \n",
    "    clean_loc = state[\"real_states\"][0,[4,5],:,:].sum(dim=0).argmax()\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, _ = drc_net(env_out, rnn_state, greedy=True)\n",
    "    clean_activs.append(drc_net.hidden_state[:,1:,:,:])\n",
    "\n",
    "    clean_probs = actor_out.action_prob.view(-1)\n",
    "    clean_logits = actor_out.pri_param.view(-1).detach()\n",
    "    clean_action_idx = actor_out.action_prob.view(-1).argmax().item()\n",
    "    print(\"clean:\", actor_out.action_prob.view(-1).tolist())\n",
    "\n",
    "    env = thinker.make(\n",
    "        f\"Sokoban-{exp}_corrupt_{i:04}-v0\", \n",
    "        env_n=env_n, \n",
    "        gpu=gpu,\n",
    "        wrapper_type=1, \n",
    "        has_model=False, \n",
    "        train_model=False, \n",
    "        parallel=False, \n",
    "        save_flags=False,\n",
    "        mini=mini_sokoban,\n",
    "        mini_unqtar=mini_unqtar,\n",
    "        mini_unqbox=mini_unqbox         \n",
    "        ) \n",
    "\n",
    "    rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "    state = env.reset()\n",
    "    env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "    for step in range(num_steps):\n",
    "        actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "        corrupt_activs.append(drc_net.hidden_state[:,1:,:,:])\n",
    "        #viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "        state, reward, done, info = env.step(actor_out.action)\n",
    "        env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "\n",
    "    #viz.plot_mini_sokoban(state[\"real_states\"][0])    \n",
    "    corrupt_loc = state[\"real_states\"][0,[4,5],:,:].sum(dim=0).argmax()\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, _ = drc_net(env_out, rnn_state, greedy=True)\n",
    "    corrupt_activs.append(drc_net.hidden_state[:,1:,:,:])\n",
    "\n",
    "    corrupt_probs = actor_out.action_prob.view(-1)\n",
    "    corrupt_logits = actor_out.pri_param.view(-1).detach()\n",
    "    corrupt_action_idx = actor_out.action_prob.view(-1).argmax().item()\n",
    "    print(\"corrupt:\", actor_out.action_prob.view(-1).tolist())\n",
    "\n",
    "    assert clean_loc == corrupt_loc, f\"{clean_loc=},{corrupt_loc=}\"\n",
    "\n",
    "    if eval_metric == \"ld\":\n",
    "        clean_ld = (clean_logits[clean_action_idx] - clean_logits[corrupt_action_idx]).item()\n",
    "        corrupt_ld = (corrupt_logits[clean_action_idx] - corrupt_logits[corrupt_action_idx]).item()\n",
    "        diff_ld = clean_ld - corrupt_ld\n",
    "    elif eval_metric == \"prob\":\n",
    "        corrupt_action_prob = corrupt_probs[clean_action_idx].item()\n",
    "\n",
    "    mode = \"cell\"\n",
    "    for layer in [0,1,2]:\n",
    "        for c in [[20,16]]:\n",
    "        #for c in [list(range(32))]:\n",
    "            patch_dict = {layer: c}\n",
    "\n",
    "            rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "            state = env.reset() \n",
    "            env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                patch_action, patch_action_probs, patch_logits, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=mode, activ_ticks=[],\n",
    "                                                                    patch_dict=patch_dict, activs=clean_activs[step])\n",
    "                state, reward, done, info = env.step(patch_action)\n",
    "                env_out = util.create_env_out(patch_action, state, reward, done, info, flags)\n",
    "\n",
    "            patch_loc = state[\"real_states\"][0,[4,5],:,:].sum(dim=0).argmax()\n",
    "            assert patch_loc==clean_loc, f\"{patch_loc=},{clean_loc=}\"\n",
    "\n",
    "            patch_action, patch_action_probs, patch_logits, _ = test_net.forward_patch(env_out, rnn_state, activ_type=mode, activ_ticks=[0,1],\n",
    "                                                                patch_dict=patch_dict, activs=clean_activs[num_steps])\n",
    "            \n",
    "            if eval_metric == \"ld\":\n",
    "                patch_ld = (patch_logits[clean_action_idx] - patch_logits[corrupt_action_idx]).item()\n",
    "                patch_metric = (patch_ld - corrupt_ld) / diff_ld\n",
    "            elif eval_metric == \"prob\": \n",
    "                patch_metric = patch_action_probs[clean_action_idx].item() - corrupt_action_prob\n",
    "\n",
    "            #print(\"patch:\", patch_action_probs.view(-1).tolist(), \"metric: \", patch_metric)\n",
    "            results[f\"layer{layer}_{mode}_{c}\"] = round(patch_metric,4)\n",
    "\n",
    "    all_results.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer0_cell_[20, 16]</th>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[20, 16]</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_cell_[20, 16]</th>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0       1       2       3       4       5       6   \\\n",
       "layer0_cell_[20, 16] -0.0001 -0.0001 -0.0002  0.0002  0.0000  0.0001  0.0001   \n",
       "layer1_cell_[20, 16] -0.0003 -0.0015 -0.0008 -0.0003 -0.0001 -0.0013 -0.0001   \n",
       "layer2_cell_[20, 16]  0.7303  0.0027 -0.0001  0.0015  0.0704  0.0029  0.0001   \n",
       "\n",
       "                          7       8       9       10      11      12      13  \\\n",
       "layer0_cell_[20, 16] -0.0000  0.0005  0.0004 -0.0000  0.0001 -0.0000  0.0001   \n",
       "layer1_cell_[20, 16]  0.0001 -0.0006  0.0002 -0.0007 -0.0000 -0.0002 -0.0018   \n",
       "layer2_cell_[20, 16]  0.0034  0.6798  0.0016 -0.0001 -0.0001  0.1629  0.0027   \n",
       "\n",
       "                          14      15  \n",
       "layer0_cell_[20, 16]  0.0000  0.0001  \n",
       "layer1_cell_[20, 16]  0.0008 -0.0004  \n",
       "layer2_cell_[20, 16]  0.0002  0.0073  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer1_cell_[20, 16]   -0.000687\n",
       "layer0_cell_[20, 16]    0.000044\n",
       "layer2_cell_[20, 16]    0.223556\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T.mean(axis=1).sort_values()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa487d0f3a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZJklEQVR4nO3df2zVhf3v8ddpjz2t2h4BKbTjUBBRBGyHFPiy6vwBYhokuj8Y4YtZBbdEchhg4/ea5uY7zN13HMzNDLovqcBYMXEMtmVF573QAZOSRTpKSRPQBEGZHEXoXOS0NOMUez73j13Pd/0ipZ/TvvvppzwfySfxnHwO55Xm2CfnnNITcBzHEQAAAyzL6wEAgOGJwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABPBwb7DVCqlc+fOKT8/X4FAYLDvHgDQD47jqKOjQ8XFxcrK6v05yqAH5ty5c4pEIoN9twCAARSPxzVu3Lhezxn0wOTn50uSvvG//qeycnMH++5vSJP+x1GvJ2Tsw/9d7vWEzKT8+ew86/bLXk/ISHd7jtcTMnbncy1eT3DlS13Rn/R/09/LezPogfnqZbGs3Fxl5RGYwRAM3OT1hIz59jHi18Dc7PWCzDhX/BsY3/3/+f9/e2Vf3uLgTX4AgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAExkFJhNmzZpwoQJys3N1Zw5c3TkyJGB3gUA8DnXgdm1a5eqq6u1bt06HTt2TGVlZXrsscfU1tZmsQ8A4FOuA/Pyyy/rBz/4gZYvX66pU6fqtdde080336xf/OIXFvsAAD7lKjBdXV1qaWnR/Pnz/+sPyMrS/Pnzdfjw4a+9TTKZVHt7e48DADD8uQrM559/ru7ubo0ZM6bH9WPGjNH58+e/9jaxWEzhcDh9RCKRzNcCAHzD/KfIampqlEgk0kc8Hre+SwDAEBB0c/Ltt9+u7OxsXbhwocf1Fy5c0NixY7/2NqFQSKFQKPOFAABfcvUMJicnRzNnztSBAwfS16VSKR04cEBz584d8HEAAP9y9QxGkqqrq1VVVaXy8nLNnj1bGzduVGdnp5YvX26xDwDgU64Ds2TJEv31r3/Vj370I50/f17f/OY3tXfv3qve+AcA3NhcB0aSVq1apVWrVg30FgDAMMLvIgMAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmMvo8mAHhBP5x+EjA8XpBZk698i9eT8hYoNvrBZlxsv35YJn0r61eT8jIqZ/N8XpCxk79p7+2p/5+WXr+zT6dyzMYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcB+bQoUNatGiRiouLFQgEtHv3boNZAAC/cx2Yzs5OlZWVadOmTRZ7AADDRNDtDSorK1VZWWmxBQAwjLgOjFvJZFLJZDJ9ub293fouAQBDgPmb/LFYTOFwOH1EIhHruwQADAHmgampqVEikUgf8Xjc+i4BAEOA+UtkoVBIoVDI+m4AAEMM/w4GAGDC9TOYS5cu6fTp0+nLZ86cUWtrq0aOHKnx48cP6DgAgH+5DszRo0f18MMPpy9XV1dLkqqqqrR9+/YBGwYA8DfXgXnooYfkOI7FFgDAMMJ7MAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMCE68+DGTAB5x+Hj6Ru8tfetLxurxdkrsO7h2i/pAJeL8jIqVf+xesJmfHZ95J/5mT7a7ubvTyDAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDCVWBisZhmzZql/Px8FRYW6sknn9TJkyettgEAfMxVYBobGxWNRtXU1KR9+/bpypUrWrBggTo7O632AQB8Kujm5L179/a4vH37dhUWFqqlpUXf/va3B3QYAMDfXAXmv0skEpKkkSNHXvOcZDKpZDKZvtze3t6fuwQA+ETGb/KnUimtXbtWFRUVmj59+jXPi8ViCofD6SMSiWR6lwAAH8k4MNFoVCdOnNDOnTt7Pa+mpkaJRCJ9xOPxTO8SAOAjGb1EtmrVKr399ts6dOiQxo0b1+u5oVBIoVAoo3EAAP9yFRjHcfTDH/5Q9fX1OnjwoCZOnGi1CwDgc64CE41GtWPHDr355pvKz8/X+fPnJUnhcFh5eXkmAwEA/uTqPZja2lolEgk99NBDKioqSh+7du2y2gcA8CnXL5EBANAX/C4yAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMuPrAsQHlBP5x+EhWl7/2pnX59+8RH373Na8nZOS9rr97PSEji/7PWq8nZCRwxaf/b0rKSvpre+By37+f+Pc7DwBgSCMwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABOuAlNbW6vS0lIVFBSooKBAc+fO1Z49e6y2AQB8zFVgxo0bpw0bNqilpUVHjx7VI488oieeeELvvfee1T4AgE8F3Zy8aNGiHpd/8pOfqLa2Vk1NTZo2bdqADgMA+JurwPyz7u5u/eY3v1FnZ6fmzp17zfOSyaSSyWT6cnt7e6Z3CQDwEddv8h8/fly33nqrQqGQnn32WdXX12vq1KnXPD8WiykcDqePSCTSr8EAAH9wHZi7775bra2t+vOf/6yVK1eqqqpK77///jXPr6mpUSKRSB/xeLxfgwEA/uD6JbKcnBzdeeedkqSZM2equblZr7zyijZv3vy154dCIYVCof6tBAD4Tr//HUwqlerxHgsAAJLLZzA1NTWqrKzU+PHj1dHRoR07dujgwYNqaGiw2gcA8ClXgWlra9P3vvc9ffbZZwqHwyotLVVDQ4MeffRRq30AAJ9yFZht27ZZ7QAADDP8LjIAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEy4+sCxG52T5Xg9ITM+/mvEpF8/6/WEjEwujXs9ISPOTSmvJ2Tkpi/8+63MyfZ6gUtdgT6f6uNvPQCAoYzAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEz0KzAbNmxQIBDQ2rVrB2gOAGC4yDgwzc3N2rx5s0pLSwdyDwBgmMgoMJcuXdKyZcu0detWjRgxYqA3AQCGgYwCE41GtXDhQs2fP3+g9wAAhomg2xvs3LlTx44dU3Nzc5/OTyaTSiaT6cvt7e1u7xIA4EOunsHE43GtWbNGv/zlL5Wbm9un28RiMYXD4fQRiUQyGgoA8BdXgWlpaVFbW5vuu+8+BYNBBYNBNTY26tVXX1UwGFR3d/dVt6mpqVEikUgf8Xh8wMYDAIYuVy+RzZs3T8ePH+9x3fLlyzVlyhS98MILys7Ovuo2oVBIoVCofysBAL7jKjD5+fmaPn16j+tuueUWjRo16qrrAQA3Nv4lPwDAhOufIvvvDh48OAAzAADDDc9gAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAw0e8PHLuRBFIBrydkJBXq9npCxoKX/PkQ/ahtlNcTMhK47M+/czrZXi/I3Jf5Ka8nuJIK9n2vPx9NAIAhj8AAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJV4F58cUXFQgEehxTpkyx2gYA8LGg2xtMmzZN+/fv/68/IOj6jwAA3ABc1yEYDGrs2LEWWwAAw4jr92BOnTql4uJi3XHHHVq2bJnOnj3b6/nJZFLt7e09DgDA8OcqMHPmzNH27du1d+9e1dbW6syZM3rggQfU0dFxzdvEYjGFw+H0EYlE+j0aADD0BRzHcTK98cWLF1VSUqKXX35ZzzzzzNeek0wmlUwm05fb29sViUQUeek/lJWXm+ldeyKQ8VfKW6m8bq8nZOymL3z6Ht+ETq8XZOTLtjyvJ2Qk2OnfH4j9Mj/l9QRXUn+/rPjz/65EIqGCgoJez+3X/7233Xab7rrrLp0+ffqa54RCIYVCof7cDQDAh/qV/UuXLunDDz9UUVHRQO0BAAwTrgLz/PPPq7GxUX/5y1/07rvv6jvf+Y6ys7O1dOlSq30AAJ9y9RLZJ598oqVLl+pvf/ubRo8erfvvv19NTU0aPXq01T4AgE+5CszOnTutdgAAhhn//ugFAGBIIzAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcfR4M/ClwOdvrCRn7Ms/xekJGnPaQ1xMyEvB6QIa+vNmfjxNJkt+mu9jLMxgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJlwH5tNPP9VTTz2lUaNGKS8vT/fee6+OHj1qsQ0A4GNBNyd/8cUXqqio0MMPP6w9e/Zo9OjROnXqlEaMGGG1DwDgU64C89JLLykSiaiuri593cSJEwd8FADA/1y9RPbWW2+pvLxcixcvVmFhoWbMmKGtW7f2eptkMqn29vYeBwBg+HMVmI8++ki1tbWaPHmyGhoatHLlSq1evVqvv/76NW8Ti8UUDofTRyQS6fdoAMDQF3Acx+nryTk5OSovL9e7776bvm716tVqbm7W4cOHv/Y2yWRSyWQyfbm9vV2RSESRl/5DWXm5/Zg++AJ9/koNLU7A6wU3Hiev2+sJGQlc9ukPlvr5QZ7lr28sqb9fVvzf/l2JREIFBQW9nuvq0VRUVKSpU6f2uO6ee+7R2bNnr3mbUCikgoKCHgcAYPhzFZiKigqdPHmyx3UffPCBSkpKBnQUAMD/XAXmueeeU1NTk9avX6/Tp09rx44d2rJli6LRqNU+AIBPuQrMrFmzVF9fr1/96leaPn26fvzjH2vjxo1atmyZ1T4AgE+5+ncwkvT444/r8ccft9gCABhGfPojIwCAoY7AAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABOuP3BswGQ5/zh8xEkFvJ5ww8nq8unX/Eq21wsyksrx1/+TaQGf7h7meAYDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmXAVmwoQJCgQCVx3RaNRqHwDAp4JuTm5ublZ3d3f68okTJ/Too49q8eLFAz4MAOBvrgIzevToHpc3bNigSZMm6cEHHxzQUQAA/3MVmH/W1dWlN954Q9XV1QoEAtc8L5lMKplMpi+3t7dnepcAAB/J+E3+3bt36+LFi3r66ad7PS8WiykcDqePSCSS6V0CAHwk48Bs27ZNlZWVKi4u7vW8mpoaJRKJ9BGPxzO9SwCAj2T0EtnHH3+s/fv363e/+911zw2FQgqFQpncDQDAxzJ6BlNXV6fCwkItXLhwoPcAAIYJ14FJpVKqq6tTVVWVgsGMf0YAADDMuQ7M/v37dfbsWa1YscJiDwBgmHD9FGTBggVyHMdiCwBgGOF3kQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATg/6RlF99lkzq8uXBvuv+SwW8XnDjueLTr3nAn5+ZlOr2525f89lD/Kvv3X35XLCAM8ifHvbJJ58oEokM5l0CAAZYPB7XuHHjej1n0AOTSqV07tw55efnKxAY2HS3t7crEokoHo+roKBgQP9sS+weXOwefH7dzu6rOY6jjo4OFRcXKyur93dZBv0lsqysrOtWr78KCgp89WD4CrsHF7sHn1+3s7uncDjcp/N4kx8AYILAAABMDKvAhEIhrVu3TqFQyOsprrB7cLF78Pl1O7v7Z9Df5AcA3BiG1TMYAMDQQWAAACYIDADABIEBAJgYNoHZtGmTJkyYoNzcXM2ZM0dHjhzxetJ1HTp0SIsWLVJxcbECgYB2797t9aQ+icVimjVrlvLz81VYWKgnn3xSJ0+e9HrWddXW1qq0tDT9j8/mzp2rPXv2eD3LtQ0bNigQCGjt2rVeT+nViy++qEAg0OOYMmWK17P65NNPP9VTTz2lUaNGKS8vT/fee6+OHj3q9azrmjBhwlVf80AgoGg06smeYRGYXbt2qbq6WuvWrdOxY8dUVlamxx57TG1tbV5P61VnZ6fKysq0adMmr6e40tjYqGg0qqamJu3bt09XrlzRggUL1NnZ6fW0Xo0bN04bNmxQS0uLjh49qkceeURPPPGE3nvvPa+n9Vlzc7M2b96s0tJSr6f0ybRp0/TZZ5+ljz/96U9eT7quL774QhUVFbrpppu0Z88evf/++/rpT3+qESNGeD3tupqbm3t8vfft2ydJWrx4sTeDnGFg9uzZTjQaTV/u7u52iouLnVgs5uEqdyQ59fX1Xs/ISFtbmyPJaWxs9HqKayNGjHB+/vOfez2jTzo6OpzJkyc7+/btcx588EFnzZo1Xk/q1bp165yysjKvZ7j2wgsvOPfff7/XMwbEmjVrnEmTJjmpVMqT+/f9M5iuri61tLRo/vz56euysrI0f/58HT582MNlN45EIiFJGjlypMdL+q67u1s7d+5UZ2en5s6d6/WcPolGo1q4cGGPx/pQd+rUKRUXF+uOO+7QsmXLdPbsWa8nXddbb72l8vJyLV68WIWFhZoxY4a2bt3q9SzXurq69MYbb2jFihUD/ouF+8r3gfn888/V3d2tMWPG9Lh+zJgxOn/+vEerbhypVEpr165VRUWFpk+f7vWc6zp+/LhuvfVWhUIhPfvss6qvr9fUqVO9nnVdO3fu1LFjxxSLxbye0mdz5szR9u3btXfvXtXW1urMmTN64IEH1NHR4fW0Xn300Ueqra3V5MmT1dDQoJUrV2r16tV6/fXXvZ7myu7du3Xx4kU9/fTTnm0Y9N+mjOElGo3qxIkTvnhtXZLuvvtutba2KpFI6Le//a2qqqrU2Ng4pCMTj8e1Zs0a7du3T7m5uV7P6bPKysr0f5eWlmrOnDkqKSnRr3/9az3zzDMeLutdKpVSeXm51q9fL0maMWOGTpw4oddee01VVVUer+u7bdu2qbKyUsXFxZ5t8P0zmNtvv13Z2dm6cOFCj+svXLigsWPHerTqxrBq1Sq9/fbbeuedd8w/gmGg5OTk6M4779TMmTMVi8VUVlamV155xetZvWppaVFbW5vuu+8+BYNBBYNBNTY26tVXX1UwGFR3d7fXE/vktttu01133aXTp097PaVXRUVFV/2F45577vHFy3tf+fjjj7V//359//vf93SH7wOTk5OjmTNn6sCBA+nrUqmUDhw44JvX1v3GcRytWrVK9fX1+uMf/6iJEyd6PSljqVRKyWTS6xm9mjdvno4fP67W1tb0UV5ermXLlqm1tVXZ2dleT+yTS5cu6cMPP1RRUZHXU3pVUVFx1Y/df/DBByopKfFokXt1dXUqLCzUwoULPd0xLF4iq66uVlVVlcrLyzV79mxt3LhRnZ2dWr58udfTenXp0qUef5s7c+aMWltbNXLkSI0fP97DZb2LRqPasWOH3nzzTeXn56ff6wqHw8rLy/N43bXV1NSosrJS48ePV0dHh3bs2KGDBw+qoaHB62m9ys/Pv+r9rVtuuUWjRo0a0u97Pf/881q0aJFKSkp07tw5rVu3TtnZ2Vq6dKnX03r13HPP6Vvf+pbWr1+v7373uzpy5Ii2bNmiLVu2eD2tT1KplOrq6lRVVaVg0ONv8Z787JqBn/3sZ8748eOdnJwcZ/bs2U5TU5PXk67rnXfecSRddVRVVXk9rVdft1mSU1dX5/W0Xq1YscIpKSlxcnJynNGjRzvz5s1z/vCHP3g9KyN++DHlJUuWOEVFRU5OTo7zjW98w1myZIlz+vRpr2f1ye9//3tn+vTpTigUcqZMmeJs2bLF60l91tDQ4EhyTp486fUUh1/XDwAw4fv3YAAAQxOBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYOL/AS1tz/uIv4XtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(clean_activs[3][0,1,64*2+32:192,:,:][20,:,:].detach(), vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa487d0f850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(corrupt_activs[3][0,1,64*2+32:192,:,:][20,:,:].detach(), vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer0_cell_[29]   -0.000063\n",
       "layer0_cell_[17]    0.000063\n",
       "layer0_cell_[12]    0.000100\n",
       "layer0_cell_[1]     0.000200\n",
       "layer0_cell_[9]     0.000200\n",
       "layer0_cell_[26]    0.000250\n",
       "layer0_cell_[16]    0.000263\n",
       "layer0_cell_[28]    0.000275\n",
       "layer0_cell_[15]    0.000287\n",
       "layer0_cell_[8]     0.000400\n",
       "layer0_cell_[19]    0.000513\n",
       "layer0_cell_[21]    0.000525\n",
       "layer0_cell_[27]    0.000563\n",
       "layer0_cell_[4]     0.000687\n",
       "layer0_cell_[31]    0.000813\n",
       "layer0_cell_[24]    0.000950\n",
       "layer0_cell_[20]    0.001075\n",
       "layer0_cell_[11]    0.001637\n",
       "layer0_cell_[7]     0.002000\n",
       "layer0_cell_[22]    0.010413\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T.mean(axis=1).sort_values()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[22]</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[20]</th>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[24]</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[11]</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[16]</th>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[7]</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[17]</th>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[14]</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[18]</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>-0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[15]</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[27]</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[25]</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>-0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[30]</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[5]</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[6]</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[9]</th>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[26]</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[28]</th>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[29]</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[21]</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>-0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[13]</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[2]</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[4]</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[31]</th>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[8]</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[3]</th>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[10]</th>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[23]</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[0]</th>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[12]</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[1]</th>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.9243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_cell_[19]</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>-0.0038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0       1       2       3       4       5       6  \\\n",
       "layer1_cell_[22] -0.0005  0.0022 -0.0001 -0.0008  0.0013  0.0006 -0.0009   \n",
       "layer1_cell_[20] -0.0008 -0.0006 -0.0008 -0.0006  0.0013 -0.0014 -0.0006   \n",
       "layer1_cell_[24]  0.0030 -0.0008  0.0001 -0.0006  0.0007  0.0005  0.0003   \n",
       "layer1_cell_[11]  0.0003 -0.0010  0.0002 -0.0005 -0.0003 -0.0004  0.0001   \n",
       "layer1_cell_[16] -0.0002 -0.0031 -0.0001 -0.0004  0.0006 -0.0003  0.0011   \n",
       "layer1_cell_[7]   0.0009 -0.0005 -0.0005 -0.0003  0.0013  0.0001  0.0023   \n",
       "layer1_cell_[17] -0.0002 -0.0014  0.0002 -0.0003  0.0000  0.0015 -0.0002   \n",
       "layer1_cell_[14]  0.0177 -0.0017 -0.0001 -0.0001 -0.0004  0.0022  0.0034   \n",
       "layer1_cell_[18]  0.0015 -0.0007 -0.0002 -0.0001 -0.0007 -0.0008  0.0012   \n",
       "layer1_cell_[15]  0.0019 -0.0000  0.0005  0.0000  0.0012  0.0005  0.0016   \n",
       "layer1_cell_[27]  0.0008 -0.0007  0.0003  0.0000  0.0003  0.0001  0.0003   \n",
       "layer1_cell_[25] -0.0005 -0.0005 -0.0012 -0.0000 -0.0004  0.0020  0.0014   \n",
       "layer1_cell_[30]  0.0002  0.0044 -0.0002 -0.0000  0.0010 -0.0006  0.0005   \n",
       "layer1_cell_[5]   0.0025 -0.0004  0.0004  0.0001  0.0004  0.0005  0.0001   \n",
       "layer1_cell_[6]   0.0001 -0.0001  0.0002  0.0002 -0.0000 -0.0007  0.0000   \n",
       "layer1_cell_[9]  -0.0012  0.0009  0.0011  0.0002  0.0007  0.0006 -0.0001   \n",
       "layer1_cell_[26]  0.0002 -0.0009  0.0007  0.0002  0.0004 -0.0012 -0.0001   \n",
       "layer1_cell_[28] -0.0007  0.0003 -0.0003  0.0002  0.0011 -0.0009  0.0006   \n",
       "layer1_cell_[29] -0.0003 -0.0004  0.0003  0.0002  0.0005 -0.0003 -0.0005   \n",
       "layer1_cell_[21]  0.0021  0.0032  0.0043  0.0004 -0.0012 -0.0035  0.0254   \n",
       "layer1_cell_[13]  0.0021 -0.0018  0.0008  0.0005  0.0009  0.0011  0.0018   \n",
       "layer1_cell_[2]   0.0013  0.0004  0.0007  0.0005 -0.0000  0.0008  0.0000   \n",
       "layer1_cell_[4]   0.0028  0.0077 -0.0012  0.0006  0.0020 -0.0074  0.0000   \n",
       "layer1_cell_[31] -0.0013  0.0006  0.0007  0.0009 -0.0006  0.0014 -0.0001   \n",
       "layer1_cell_[8]   0.0040 -0.0002  0.0020  0.0009  0.0009 -0.0000  0.0019   \n",
       "layer1_cell_[3]  -0.0022  0.0007 -0.0011  0.0021  0.0006  0.0050  0.0001   \n",
       "layer1_cell_[10] -0.0013  0.0002  0.0001  0.0024  0.0017  0.0013 -0.0020   \n",
       "layer1_cell_[23]  0.0002 -0.0010 -0.0007  0.0027  0.0001  0.0012  0.0009   \n",
       "layer1_cell_[0]   0.0151  0.0001  0.0001  0.0036 -0.0014 -0.0006  0.0000   \n",
       "layer1_cell_[12]  0.0007 -0.0033  0.0003  0.0037 -0.0004  0.0002 -0.0006   \n",
       "layer1_cell_[1]   0.1166  0.9685  0.9595  0.0071  0.0430  0.9625  0.0007   \n",
       "layer1_cell_[19] -0.0003  0.0009 -0.0011  0.6330  0.0016 -0.0008 -0.0021   \n",
       "\n",
       "                       7  \n",
       "layer1_cell_[22]  0.0016  \n",
       "layer1_cell_[20] -0.0015  \n",
       "layer1_cell_[24]  0.0001  \n",
       "layer1_cell_[11] -0.0008  \n",
       "layer1_cell_[16] -0.0003  \n",
       "layer1_cell_[7]  -0.0014  \n",
       "layer1_cell_[17]  0.0006  \n",
       "layer1_cell_[14] -0.0003  \n",
       "layer1_cell_[18] -0.0002  \n",
       "layer1_cell_[15]  0.0000  \n",
       "layer1_cell_[27] -0.0001  \n",
       "layer1_cell_[25] -0.0018  \n",
       "layer1_cell_[30]  0.0017  \n",
       "layer1_cell_[5]   0.0064  \n",
       "layer1_cell_[6]   0.0000  \n",
       "layer1_cell_[9]   0.0011  \n",
       "layer1_cell_[26] -0.0001  \n",
       "layer1_cell_[28]  0.0002  \n",
       "layer1_cell_[29] -0.0004  \n",
       "layer1_cell_[21] -0.0011  \n",
       "layer1_cell_[13] -0.0011  \n",
       "layer1_cell_[2]   0.0000  \n",
       "layer1_cell_[4]  -0.0008  \n",
       "layer1_cell_[31]  0.0009  \n",
       "layer1_cell_[8]  -0.0012  \n",
       "layer1_cell_[3]   0.0014  \n",
       "layer1_cell_[10]  0.0008  \n",
       "layer1_cell_[23]  0.0010  \n",
       "layer1_cell_[0]  -0.0035  \n",
       "layer1_cell_[12]  0.0035  \n",
       "layer1_cell_[1]   0.9243  \n",
       "layer1_cell_[19] -0.0038  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T.sort_values(by=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16, 1]</th>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.9347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0       1       2  \\\n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16, 1]  0.8817  0.8805  0.8219   \n",
       "\n",
       "                                                       3       4       5  \\\n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16, 1]  0.6762  0.9495  0.8145   \n",
       "\n",
       "                                                       6       7  \n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16, 1]  0.4975  0.9347  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T.sort_values(by=3)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16]</th>\n",
       "      <td>0.8213</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.9165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0       1       2      3  \\\n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16]  0.8213  0.8627  0.8272  0.605   \n",
       "\n",
       "                                                    4       5       6       7  \n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 10, 16]  0.9419  0.7663  0.1328  0.9165  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T.sort_values(by=3)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer2_cell_[3, 16, 20, 6, 8, 28, 15, 1, 10, 16]</th>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0       1       2  \\\n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 1, 10, 16]  0.9609  0.9618  0.9529   \n",
       "\n",
       "                                                       3       4       5  \\\n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 1, 10, 16]  0.9673  0.9483  0.9483   \n",
       "\n",
       "                                                       6       7  \n",
       "layer2_cell_[3, 16, 20, 6, 8, 28, 15, 1, 10, 16]  0.9784  0.8125  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, res in results.items():\n",
    "    if res > 0.01:\n",
    "        print(lab, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"real_states\"][0,[4,5],:,:].sum(dim=0).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n",
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = thinker.make(\n",
    "    \"Sokoban-unsolvable_baseline_000-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    "    ) \n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) \n",
    "flags.mini = mini_sokoban\n",
    "flags.mini_unqbtar = mini_unqtar\n",
    "flags.mini_unqbox = mini_unqbox\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "env = thinker.make(\n",
    "    f\"Sokoban-unsolvable_baseline_000-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    ") \n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "state = env.reset()\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0]) \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "state, reward, done, info = env.step(actor_out.action)\n",
    "baseline_loc = state[\"real_states\"][0,[4,5],:,:].sum(dim=0).argmax()\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "actor_out, _ = drc_net(env_out, rnn_state, greedy=True)\n",
    "results[f\"base_probs\"] = actor_out.action_prob.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out.action_prob.view(-1).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(baseline_loc == interv_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'interv_probs': tensor([0.0158, 0.9393, 0.0129, 0.0052, 0.0267], grad_fn=<ViewBackward0>),\n",
       " 'base_probs': tensor([0.0092, 0.0079, 0.0064, 0.9699, 0.0067], grad_fn=<ViewBackward0>),\n",
       " 'patch_probs': tensor([0.0217, 0.8761, 0.0130, 0.0721, 0.0172], grad_fn=<SoftmaxBackward0>)}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interv\n",
    "env = thinker.make(\n",
    "    f\"Sokoban-unsolvable_baseline_000-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    ") \n",
    "\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "\n",
    "patch_dict = {2:[16]}\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "#print(\"===================Step 1=====================\")\n",
    "test_net = ActPatchDRCNet(drc_net)\n",
    "action, action_probs, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1,2],\n",
    "                                                    patch_dict=patch_dict, activs=intervention_activs_1)\n",
    "state, reward, done, info = env.step(action)#\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "#print(\"===================Step 2=====================\")\n",
    "action, action_probs, _ = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1],\n",
    "                                                     patch_dict=patch_dict, activs=intervention_activs_2)\n",
    "results[\"patch_probs\"] = action_probs\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-36.7094, grad_fn=<SumBackward0>),\n",
       " tensor(-21.0208, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervention_activs_1[:,0,32:64,:,:].sum(), intervention_activs_1[:,0,:32,:,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.2715, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervention_activs_1[:,0,2*64:2*64+32,:,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_cur = intervention_activs_1[:,0,:32,:,:]\n",
    "c_cur = intervention_activs_1[:,0,32:64,:,:]\n",
    "input = cell_input = torch.concat([x, out], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = input.shape[0]\n",
    "print(\"h_cur, c_cur, input\", h_cur.sum(), c_cur.sum(), input.sum())\n",
    "combined = torch.cat([input, h_cur], dim=1)  # concatenate along channel axis\n",
    "if test_net.drc_net.core.layers[0].pool_inject:\n",
    "    combined = torch.cat(\n",
    "        [combined, test_net.drc_net.core.layers[0].proj_max_mean(h_cur)], dim=1\n",
    "    )  # concatenate along channel axis\n",
    "if test_net.drc_net.core.layers[0].linear:\n",
    "    combined_conv = test_net.drc_net.core.layers[0].main(combined[:, :, 0, 0]).unsqueeze(-1).unsqueeze(-1)\n",
    "else:\n",
    "    combined_conv = test_net.drc_net.core.layers[0].main(combined)\n",
    "cc_i, cc_f, cc_o, cc_g, cc_a = torch.split(combined_conv, test_net.drc_net.core.layers[0].embed_dim, dim=1)\n",
    "i = torch.sigmoid(cc_i)\n",
    "f = torch.sigmoid(cc_f)\n",
    "o = torch.sigmoid(cc_o)\n",
    "g = torch.tanh(cc_g)\n",
    "c_next = f * c_cur + i * g\n",
    "print(\"c_next:\", c_next.sum())\n",
    "print(h_next.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Step 1=====================\n",
      "----- patching activations for tick 0 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(0.) tensor(2.5460, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(0.) tensor(0.) tensor(2.5460, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-21.0208, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n",
      "----- patching activations for tick 1 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(7.8204, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>) tensor(10.3664, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(-21.0208, grad_fn=<SumBackward0>) tensor(-33.1600, grad_fn=<SumBackward0>) tensor(10.3664, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-50.8793, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n",
      "----- patching activations for tick 2 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(52.2666, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>) tensor(54.8126, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(-50.8793, grad_fn=<SumBackward0>) tensor(-65.7943, grad_fn=<SumBackward0>) tensor(54.8126, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-41.3416, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n",
      "===================Step 2=====================\n",
      "----- patching activations for tick 0 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(56.7123, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>) tensor(59.2583, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(-41.3416, grad_fn=<SumBackward0>) tensor(-77.1633, grad_fn=<SumBackward0>) tensor(59.2583, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-26.4198, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n",
      "----- patching activations for tick 1 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(50.8150, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>) tensor(53.3610, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(-26.4198, grad_fn=<SumBackward0>) tensor(-49.3295, grad_fn=<SumBackward0>) tensor(53.3610, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-35.1429, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n",
      "----- patching activations for tick 2 ---- \n",
      "reset tensor(0.)\n",
      "--- Patching Layer 0 ---\n",
      "out, x, cell_input: tensor(43.3853, grad_fn=<SumBackward0>) tensor(2.5460, grad_fn=<SumBackward0>) tensor(45.9313, grad_fn=<SumBackward0>)\n",
      "h_cur, c_cur, input tensor(-35.1429, grad_fn=<SumBackward0>) tensor(-43.2812, grad_fn=<SumBackward0>) tensor(45.9313, grad_fn=<SumBackward0>)\n",
      "patching channels range(0, 32) in hidden\n",
      "tensor(-39.4390, grad_fn=<SumBackward0>)\n",
      "--- NOT patching layer 1 ---\n",
      "--- NOT patching layer 2 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'interv_probs': tensor([0.0158, 0.9393, 0.0129, 0.0052, 0.0267], grad_fn=<ViewBackward0>),\n",
       " 'base_probs': tensor([0.0092, 0.0079, 0.0064, 0.9699, 0.0067], grad_fn=<ViewBackward0>),\n",
       " 'patch_probs': tensor([0.0476, 0.0080, 0.1361, 0.1486, 0.6597], grad_fn=<SoftmaxBackward0>)}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interv\n",
    "env = thinker.make(\n",
    "    f\"Sokoban-unsolvable_baseline_000-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    ") \n",
    "\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "\n",
    "patch_dict = {0:range(32)}\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False)\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "print(\"===================Step 1=====================\")\n",
    "test_net = ActPatchDRCNet(drc_net)\n",
    "action, action_probs, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"hidden\", activ_ticks=[0,1,2],\n",
    "                                                    patch_dict=patch_dict, activs=intervention_activs_1)\n",
    "state, reward, done, info = env.step(action)#\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "print(\"===================Step 2=====================\")\n",
    "action, action_probs, _ = test_net.forward_patch(env_out, rnn_state, activ_type=\"hidden\", activ_ticks=[0,1,2],\n",
    "                                                     patch_dict=patch_dict, activs=intervention_activs_2)\n",
    "results[\"patch_probs\"] = action_probs\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interv_probs': tensor([0.0158, 0.9393, 0.0129, 0.0052, 0.0267], grad_fn=<ViewBackward0>),\n",
       " 'base_probs': tensor([0.0092, 0.0079, 0.0064, 0.9699, 0.0067], grad_fn=<ViewBackward0>),\n",
       " 'patch_probs': tensor([0.0298, 0.0070, 0.0459, 0.8133, 0.1039], grad_fn=<SoftmaxBackward0>)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden 0\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = env_out.done\n",
    "T, B = done.shape\n",
    "x = drc_net.normalize(env_out.real_states.float())\n",
    "x = torch.flatten(x, 0, 1)\n",
    "x_enc = drc_net.encoder(x)\n",
    "core_input = x_enc.view(*((T, B) + x_enc.shape[1:]))\n",
    "core_output, rnn_state = drc_net.core(core_input, done, rnn_state, record_state=drc_net.record_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.core.attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActPatchDRCNet:\n",
    "\n",
    "    def __init__(self, drc_net):\n",
    "        self.drc_net = drc_net\n",
    "\n",
    "    def forward_normal(self, env_out, rnn_state):\n",
    "        return self.drc_net(env_out, rnn_state)\n",
    "    \n",
    "    def forward_patch(self, env_out, rnn_state, greedy=True, activ_type=None, activ_channels=[], activ_layer=0, activ_ticks=[], activs=None):\n",
    "\n",
    "        done = env_out.done\n",
    "        T, B = done.shape\n",
    "        x = self.drc_net.normalize(env_out.real_states.float())\n",
    "        x = torch.flatten(x, 0, 1)\n",
    "        x_enc = self.drc_net.encoder(x)\n",
    "        core_input = x_enc.view(*((T, B) + x_enc.shape[1:]))\n",
    "\n",
    "        record_state=self.drc_net.record_state\n",
    "\n",
    "        assert len(core_input.shape) == 5\n",
    "        core_output_list = []\n",
    "        reset = done.float()\n",
    "        if self.drc_net.record_state: \n",
    "            self.drc_net.core.hidden_state = []\n",
    "            self.drc_net.core.hidden_state.append(torch.concat(rnn_state, dim=1)) \n",
    "        for n, (x_single, reset_single) in enumerate(\n",
    "            zip(core_input.unbind(), reset.unbind())\n",
    "        ):\n",
    "            for t in range(self.drc_net.core.tran_t):\n",
    "                if t > 0:\n",
    "                    reset_single = torch.zeros_like(reset_single)\n",
    "                reset_single = reset_single.view(-1)\n",
    "                if t in activ_ticks:\n",
    "                    output, rnn_state = self.forward_single_patch(\n",
    "                        x=x_single,\n",
    "                        core_state=rnn_state,\n",
    "                        reset=reset_single,\n",
    "                        activ_type=activ_type, \n",
    "                        activ_layer=activ_layer,\n",
    "                        activ_channels=activ_channels,\n",
    "                        activs=activs[:,t,:,:,:]\n",
    "                    )  # output shape: 1, B, core_output_size\n",
    "                else:\n",
    "                    output, rnn_state = self.drc_net.core.forward_single(\n",
    "                        x_single, rnn_state, reset_single, reset_single\n",
    "                    )        \n",
    "                if self.drc_net.record_state: self.drc_net.core.hidden_state.append(torch.concat(rnn_state, dim=1))      \n",
    "            core_output_list.append(output)\n",
    "        core_output = torch.cat(core_output_list)\n",
    "        if self.drc_net.record_state: \n",
    "           self.drc_net.core.hidden_state = torch.stack(self.drc_net.core.hidden_state, dim=1)\n",
    "\n",
    "        core_output = torch.flatten(core_output, 0, 1)\n",
    "        core_output = torch.cat([x_enc, core_output], dim=1)\n",
    "\n",
    "        if activ_type == \"xenc\":\n",
    "            core_output[:,activ_channels,:,:] = activs[:activ_channels,:,:]\n",
    "\n",
    "        core_output = torch.flatten(core_output, 1)\n",
    "        final_out = torch.nn.functional.relu(self.drc_net.final_layer(core_output))\n",
    "        pri_logits = self.drc_net.policy(final_out)\n",
    "        pri_logits = pri_logits.view(T*B, self.drc_net.dim_actions, self.drc_net.num_actions)\n",
    "        pri = sample(pri_logits, greedy=greedy, dim=-1)\n",
    "        pri = pri.view(T, B, self.drc_net.dim_actions) \n",
    "        pri_env = pri[-1, :, 0] if not self.drc_net.tuple_action else pri[-1]   \n",
    "        action = pri_env\n",
    "        return action, pri_logits, rnn_state\n",
    "    \n",
    "    def forward_single_patch(self, x, core_state, reset, activ_type=None, activ_layer=None, activ_channels=[], activs=None):\n",
    "        reset = reset.float()\n",
    "\n",
    "        b, c, h, w = x.shape\n",
    "        layer_n = 2\n",
    "        out = core_state[(self.drc_net.core.num_layers - 1) * layer_n] * (1 - reset).view(\n",
    "            b, 1, 1, 1\n",
    "        )  # h_cur on last layer\n",
    "\n",
    "        core_out = []\n",
    "        new_core_state = []\n",
    "        for n, cell in enumerate(self.drc_net.core.layers):\n",
    "            cell_input = torch.concat([x, out], dim=1)\n",
    "            h_cur = core_state[n * layer_n + 0] * (1 - reset.view(b, 1, 1, 1))\n",
    "            c_cur = core_state[n * layer_n + 1] * (1 - reset.view(b, 1, 1, 1))\n",
    "            if activ_type == \"xenc\":\n",
    "                cell_input[:,activ_channels,:,:] = activs[:,activ_channels,:,:]\n",
    "            if n == activ_layer and activ_type is not None:\n",
    "                h_next, c_next = self.forward_cell_patch(\n",
    "                    convlstm_cell=cell,\n",
    "                    input=cell_input,\n",
    "                    h_cur=h_cur,\n",
    "                    c_cur=c_cur,\n",
    "                    activ_type=activ_type, \n",
    "                    activ_channels=activ_channels, \n",
    "                    activs=activs\n",
    "                )\n",
    "            else:\n",
    "                h_next, c_next, concat_k, concat_v = cell(\n",
    "                    cell_input, h_cur, c_cur, None, None, None\n",
    "                )\n",
    "            if self.drc_net.core.grad_scale < 1 and h_next.requires_grad:\n",
    "                h_next.register_hook(lambda grad: grad * self.drc_net.core.grad_scale)\n",
    "                c_next.register_hook(lambda grad: grad * self.drc_net.core.grad_scale)\n",
    "            new_core_state.append(h_next)\n",
    "            new_core_state.append(c_next)\n",
    "            out = h_next\n",
    "\n",
    "        core_state = tuple(new_core_state)\n",
    "        core_out = out.unsqueeze(0)\n",
    "        return core_out, core_state\n",
    "    \n",
    "    def forward_cell_patch(self, convlstm_cell, input, h_cur, c_cur, activ_type=None, activ_channels=[], activs=None):\n",
    "        B = input.shape[0]\n",
    "        combined = torch.cat([input, h_cur], dim=1)  # concatenate along channel axis\n",
    "        if convlstm_cell.pool_inject:\n",
    "            combined = torch.cat(\n",
    "                [combined, convlstm_cell.proj_max_mean(h_cur)], dim=1\n",
    "            )  # concatenate along channel axis\n",
    "        if convlstm_cell.linear:\n",
    "            combined_conv = convlstm_cell.main(combined[:, :, 0, 0]).unsqueeze(-1).unsqueeze(-1)\n",
    "        else:\n",
    "            combined_conv = convlstm_cell.main(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g, cc_a = torch.split(combined_conv, convlstm_cell.embed_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        if activ_type==\"cell\":\n",
    "            c_next[:,activ_channels,:,:] = activs[:,activ_channels,:,:]\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        if activ_type==\"hidden\":\n",
    "            h_next[:,activ_channels,:,:] = activs[:,activ_channels,:,:]\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini=True, unqtar=False, unqbox=False\n",
      "mini=True, unqtar=False, unqbox=False\n",
      "mini=True, unqtar=False, unqbox=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_n = 1\n",
    "gpu = False\n",
    "mini_sokoban = True \n",
    "mini_unqtar = False\n",
    "mini_unqbox = False\n",
    "\n",
    "env = thinker.make(\n",
    "    \"Sokoban-tom-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    "    ) \n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) \n",
    "flags.mini = mini_sokoban\n",
    "flags.mini_unqbtar = mini_unqtar\n",
    "flags.mini_unqbox = mini_unqbox\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep249000192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0128, 0.0048, 0.0060, 0.0085, 0.9679]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "state, reward, done, info = env.step(actor_out.action)\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state, greedy=True)\n",
    "actor_out.action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.0132, 0.0057, 0.0071, 0.0098, 0.9642], grad_fn=<SoftmaxBackward0>)\n",
      "1 tensor([0.0142, 0.0082, 0.0121, 0.0096, 0.9559], grad_fn=<SoftmaxBackward0>)\n",
      "2 tensor([0.0160, 0.0091, 0.0119, 0.0117, 0.9513], grad_fn=<SoftmaxBackward0>)\n",
      "3 tensor([0.0168, 0.0098, 0.0136, 0.0126, 0.9472], grad_fn=<SoftmaxBackward0>)\n",
      "4 tensor([0.0148, 0.0054, 0.0125, 0.0125, 0.9548], grad_fn=<SoftmaxBackward0>)\n",
      "5 tensor([0.0145, 0.0079, 0.0096, 0.0107, 0.9573], grad_fn=<SoftmaxBackward0>)\n",
      "6 tensor([0.0158, 0.0090, 0.0114, 0.0120, 0.9518], grad_fn=<SoftmaxBackward0>)\n",
      "7 tensor([0.0126, 0.0051, 0.0082, 0.0087, 0.9655], grad_fn=<SoftmaxBackward0>)\n",
      "8 tensor([0.0151, 0.0079, 0.0110, 0.0110, 0.9550], grad_fn=<SoftmaxBackward0>)\n",
      "9 tensor([0.0139, 0.0068, 0.0111, 0.0100, 0.9581], grad_fn=<SoftmaxBackward0>)\n",
      "10 tensor([0.0185, 0.0109, 0.0173, 0.0157, 0.9376], grad_fn=<SoftmaxBackward0>)\n",
      "11 tensor([0.0158, 0.0085, 0.0120, 0.0124, 0.9513], grad_fn=<SoftmaxBackward0>)\n",
      "12 tensor([0.0145, 0.0066, 0.0122, 0.0081, 0.9586], grad_fn=<SoftmaxBackward0>)\n",
      "13 tensor([0.0153, 0.0082, 0.0113, 0.0119, 0.9533], grad_fn=<SoftmaxBackward0>)\n",
      "14 tensor([0.0155, 0.0084, 0.0113, 0.0118, 0.9531], grad_fn=<SoftmaxBackward0>)\n",
      "15 tensor([0.0150, 0.0079, 0.0110, 0.0114, 0.9546], grad_fn=<SoftmaxBackward0>)\n",
      "16 tensor([0.0159, 0.0088, 0.0121, 0.0122, 0.9510], grad_fn=<SoftmaxBackward0>)\n",
      "17 tensor([0.0173, 0.0101, 0.0141, 0.0135, 0.9450], grad_fn=<SoftmaxBackward0>)\n",
      "18 tensor([0.0152, 0.0080, 0.0108, 0.0116, 0.9544], grad_fn=<SoftmaxBackward0>)\n",
      "19 tensor([0.0130, 0.0055, 0.0094, 0.0072, 0.9648], grad_fn=<SoftmaxBackward0>)\n",
      "20 tensor([0.0147, 0.0078, 0.0101, 0.0107, 0.9568], grad_fn=<SoftmaxBackward0>)\n",
      "21 tensor([0.0148, 0.0078, 0.0103, 0.0102, 0.9569], grad_fn=<SoftmaxBackward0>)\n",
      "22 tensor([0.0165, 0.0085, 0.0137, 0.0144, 0.9469], grad_fn=<SoftmaxBackward0>)\n",
      "23 tensor([0.0154, 0.0083, 0.0114, 0.0119, 0.9530], grad_fn=<SoftmaxBackward0>)\n",
      "24 tensor([0.0158, 0.0089, 0.0123, 0.0122, 0.9508], grad_fn=<SoftmaxBackward0>)\n",
      "25 tensor([0.0139, 0.0062, 0.0093, 0.0102, 0.9604], grad_fn=<SoftmaxBackward0>)\n",
      "26 tensor([0.0152, 0.0079, 0.0111, 0.0115, 0.9544], grad_fn=<SoftmaxBackward0>)\n",
      "27 tensor([0.0154, 0.0083, 0.0112, 0.0114, 0.9537], grad_fn=<SoftmaxBackward0>)\n",
      "28 tensor([0.0149, 0.0082, 0.0104, 0.0114, 0.9551], grad_fn=<SoftmaxBackward0>)\n",
      "29 tensor([0.0154, 0.0084, 0.0113, 0.0116, 0.9533], grad_fn=<SoftmaxBackward0>)\n",
      "30 tensor([0.0150, 0.0080, 0.0109, 0.0118, 0.9542], grad_fn=<SoftmaxBackward0>)\n",
      "31 tensor([0.0159, 0.0088, 0.0113, 0.0116, 0.9524], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = 1\n",
    "for i in range(32):\n",
    "    channels = [i]\n",
    "    test_net = ActPatchDRCNet(drc_net)\n",
    "    action, logits, new_rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1,2,3], activ_channels=channels, activ_layer=layer, activs=nowall_states[:,:,64*layer+32:64*layer+64,:,:])\n",
    "    print(i, torch.nn.functional.softmax(logits.view(-1), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 tensor([0.0531, 0.6134, 0.0912, 0.0221, 0.2203], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = 1\n",
    "channels = range(32)\n",
    "test_net = ActPatchDRCNet(drc_net)\n",
    "action, logits, new_rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1,2,3], activ_channels=channels, activ_layer=layer, activs=nowall_states[:,:,64*layer+32:64*layer+64,:,:])\n",
    "print(i, torch.nn.functional.softmax(logits.view(-1), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "state, reward, done, info = env.step(actor_out.action)\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0237, 0.8638, 0.0132, 0.0779, 0.0214]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "actor_out.action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "terminate called after throwing an instance of 'std::runtime_error'\n",
      "  what():  box_left must be equal to 4 (room_id: 1)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[555], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rnn_state \u001b[38;5;241m=\u001b[39m drc_net\u001b[38;5;241m.\u001b[39minitial_state(batch_size\u001b[38;5;241m=\u001b[39menv_n, device\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# run the trained drc again\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m env_out \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39minit_env_out(state, flags, dim_actions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tuple_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# this converts the state to EnvOut object that can be processed by actor\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#actor_out, rnn_state = drc_net(env_out, rnn_state)\u001b[39;00m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/main.py:411\u001b[0m, in \u001b[0;36mEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 411\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampled_action \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampled_action\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/wrapper.py:114\u001b[0m, in \u001b[0;36mPostWrapper.reset\u001b[0;34m(self, model_net)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_net):\n\u001b[0;32m--> 114\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal_states\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_n \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal_states\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/wrapper.py:36\u001b[0m, in \u001b[0;36mDummyWrapper.reset\u001b[0;34m(self, model_net)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_net):\n\u001b[0;32m---> 36\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     obs_py \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(obs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_dtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)                \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_model: \n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/wrapper.py:945\u001b[0m, in \u001b[0;36mRecordEpisodeStatistics.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_return[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_step[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/working_venv/lib/python3.10/site-packages/gym/core.py:283\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ObsType, \u001b[38;5;28mtuple\u001b[39m[ObsType, \u001b[38;5;28mdict\u001b[39m]]:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/gym_add/vector_env.py:62\u001b[0m, in \u001b[0;36mVectorEnv.reset\u001b[0;34m(self, idx, seed, options)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reset all sub-environments and return a batch of initial observations.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    A batch of observations from the vectorized environment.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_async(idx\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/gym_add/asyn_vector_env.py:237\u001b[0m, in \u001b[0;36mAsyncVectorEnv.reset_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mTimeoutError(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe call to `reset_wait` has timed out after \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m second\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(timeout, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    232\u001b[0m rec_pipes \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx]\n\u001b[1;32m    236\u001b[0m )\n\u001b[0;32m--> 237\u001b[0m results, successes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[pipe\u001b[38;5;241m.\u001b[39mrecv() \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m rec_pipes])\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_errors(successes)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m AsyncState\u001b[38;5;241m.\u001b[39mDEFAULT\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/gym_add/asyn_vector_env.py:237\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mTimeoutError(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe call to `reset_wait` has timed out after \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m second\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(timeout, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    232\u001b[0m rec_pipes \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx]\n\u001b[1;32m    236\u001b[0m )\n\u001b[0;32m--> 237\u001b[0m results, successes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m rec_pipes])\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_errors(successes)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m AsyncState\u001b[38;5;241m.\u001b[39mDEFAULT\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:383\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m size:\n\u001b[0;32m--> 383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot end of file during message\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "#actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "layer = 2\n",
    "channels = list(range(32))\n",
    "test_net = ActPatchDRCNet(drc_net)\n",
    "action, logits, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1,2,3], activ_channels=channels, activ_layer=layer, activs=nowall_states[:,:,64*layer+32:64*layer+64,:,:])\n",
    "print(torch.nn.functional.softmax(logits.view(-1), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0548, 0.4744, 0.0477, 0.3799, 0.0432]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_out.action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DRCNet' object has no attribute 'hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[422], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nowall_states \u001b[38;5;241m=\u001b[39m \u001b[43mdrc_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_state\u001b[49m\n\u001b[1;32m      2\u001b[0m nowall_states\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/mlmi/dissertation/working_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DRCNet' object has no attribute 'hidden_state'"
     ]
    }
   ],
   "source": [
    "nowall_states = drc_net.hidden_state\n",
    "nowall_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini=True, unqtar=False, unqbox=False\n",
      "mini=True, unqtar=False, unqbox=False\n",
      "mini=True, unqtar=False, unqbox=False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0561, 0.2003, 0.0643, 0.6668, 0.0125], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18617/2755026123.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(logits.view(-1)))\n"
     ]
    }
   ],
   "source": [
    "env = thinker.make(\n",
    "    \"Sokoban-tom-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, \n",
    "    has_model=False, \n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban,\n",
    "    mini_unqtar=mini_unqtar,\n",
    "    mini_unqbox=mini_unqbox         \n",
    "    ) \n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "#actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "layer = 2\n",
    "channels = list(range(32))\n",
    "test_net = ActPatchDRCNet(drc_net)\n",
    "action, logits, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"cell\", activ_ticks=[0,1,2,3], activ_channels=channels, activ_layer=layer, activs=nowall_states[:,:,64*layer+32:64*layer+64,:,:])\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "state, reward, done, info = env.step(action)\n",
    "env_out = util.create_env_out(action, state, reward, done, info, flags)\n",
    "print(torch.nn.functional.softmax(logits.view(-1)))\n",
    "#viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DRCNet' object has no attribute 'hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[423], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdrc_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_state\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/working_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DRCNet' object has no attribute 'hidden_state'"
     ]
    }
   ],
   "source": [
    "drc_net.hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = ActPatchDRCNet(drc_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0638, 0.4602, 0.1077, 0.3576, 0.0108], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18617/1211942467.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(logits.view(-1)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = 2\n",
    "action, logits, rnn_state = test_net.forward_patch(env_out, rnn_state, activ_type=\"hidden\", activ_ticks=[0,1,2,3], activ_channels=list(range(32)), activ_layer=layer, activs=nowall_states[:,:,64*layer:64*layer+32,:,:])\n",
    "state, reward, done, info = env.step(action)\n",
    "env_out = util.create_env_out(action, state, reward, done, info, flags)\n",
    "print(torch.nn.functional.softmax(logits.view(-1)))\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0096, 0.0104, 0.9656, 0.0062, 0.0081], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18617/2008896402.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(logits.view(-1)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action, logits, rnn_state = test_net.forward_patch(env_out, rnn_state)\n",
    "state, reward, done, info = env.step(action)\n",
    "env_out = util.create_env_out(action, state, reward, done, info, flags)\n",
    "print(torch.nn.functional.softmax(logits.view(-1)))\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = core_input\n",
    "done = done\n",
    "core_state = rnn_state\n",
    "record_state=drc_net.record_state\n",
    "\n",
    "assert len(x.shape) == 5\n",
    "core_output_list = []\n",
    "reset = done.float()\n",
    "if record_state: \n",
    "    drc_net.core.hidden_state = []\n",
    "    drc_net.core.hidden_state.append(torch.concat(core_state, dim=1)) \n",
    "for n, (x_single, reset_single) in enumerate(\n",
    "    zip(x.unbind(), reset.unbind())\n",
    "):\n",
    "    for t in range(drc_net.core.tran_t):\n",
    "        if t > 0:\n",
    "            reset_single = torch.zeros_like(reset_single)\n",
    "        reset_single = reset_single.view(-1)\n",
    "        output, core_state = drc_net.core.forward_single(\n",
    "            x_single, core_state, reset_single, reset_single\n",
    "        )  # output shape: 1, B, core_output_size        \n",
    "        if record_state: drc_net.core.hidden_state.append(torch.concat(core_state, dim=1))      \n",
    "    core_output_list.append(output)\n",
    "core_output = torch.cat(core_output_list)\n",
    "if record_state: \n",
    "    drc_net.core.hidden_state = torch.stack(drc_net.core.hidden_state, dim=1)\n",
    "\n",
    "core_output, rnn_state = core_output, core_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGZElEQVR4nO3ZsW4bRwBF0V2BnUGztiB9ZdoAQfr4K2XQbUQ2rjRp4tsJomlRY8rntJziSVjsxZDrGGMsALAsy83sAQD8OkQBgIgCABEFACIKAEQUAIgoAJDNKYeenp6W/X6/bLfbZV3XS28C4JWNMZbj8bjc3t4uNzfP3wdOisJ+v1/u7+9fbRwAczw8PCx3d3fPfn7S10fb7fbVBgEwz0vv85Oi4CsjgPfhpfe5H5oBiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQzewBANdmjDF7wg87HA7Lbrd78ZybAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJDN7AG8P2OM2RPOsq7r7Am/lWt9Tt47NwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgm9kDLm2MMXsCV8Kz8rbW2QN+wnt+UtwUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgGxmD7i0dV1nTzjPGLMXnO16l8NpHr9+nj3hhx2O304656YAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyGb2gEv7d//P7Aln2c0e8BPW2QPO9fd1Lh9/jdkTznKdq//36Y/ZC37Y+uGwLMufL55zUwAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQCyjjHGS4cOh8Oy2+3eYs+rO+HP+yU9fv08e8LZdp/+mD3ht3Ktz4rn5G19f48/Pj4uHz9+fPacmwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADI5pRDY4xL77iYw+Ewe8JZDsdvsyecbf1wnf/za3Wtz4rn5G19fxe+9D5fxwlv/C9fviz39/evswyAaR4eHpa7u7tnPz8pCk9PT8t+v1+22+2yruurDgTg8sYYy/F4XG5vb5ebm+d/OTgpCgD8HvzQDEBEAYCIAgARBQAiCgBEFACIKACQ/wBoo4RnX9LL3QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_output = torch.flatten(core_output, 0, 1)\n",
    "core_output = torch.cat([x_enc, core_output], dim=1)\n",
    "core_output = torch.flatten(core_output, 1)\n",
    "final_out = torch.nn.functional.relu(drc_net.final_layer(core_output))\n",
    "pri_logits = drc_net.policy(final_out)\n",
    "pri_logits = pri_logits.view(T*B, drc_net.dim_actions, drc_net.num_actions)\n",
    "pri = sample(pri_logits, greedy=True, dim=-1)\n",
    "pri = pri.view(T, B, drc_net.dim_actions) \n",
    "pri_env = pri[-1, :, 0] if not drc_net.tuple_action else pri[-1]   \n",
    "action = pri_env \n",
    "state, reward, done, info = env.step(action)\n",
    "env_out = util.create_env_out(action, state, reward, done, info, flags)\n",
    "viz.plot_mini_sokoban(state[\"real_states\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
