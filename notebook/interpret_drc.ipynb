{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting DRC\n",
    "\n",
    "This notebook will give a brief guide for the project of interpreting planning agents. Note that the majority of the code in this repo is used for another planning algorithm called the Thinker, so only a few Python files in this repo are necessary for the project. First, follow the readme to install Sokoban and the Thinker repo. If Sokoban is installed successfully, you should be able to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import thinker\n",
    "import thinker.viz_utils as viz\n",
    "import thinker.util as util\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment shape + type: (8, 8, 7) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Sokoban is installed sucessfully\n",
    "mini = True\n",
    "env = gym.make(\"Sokoban-v0\", mini=mini)\n",
    "state = env.reset()\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(\"Environment shape + type:\", state.shape, type(state))\n",
    "if mini:\n",
    "    viz.plot_mini_sokoban(state, True)\n",
    "else:  \n",
    "    plt.imshow(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sokoban\n",
    "The goal is to push all four boxes to the target space (the red-bordered location). There are five actions: no-op, left, up, down, right. Boxes can only be pushed but not pulled. A reward of +1 is given if a box is pushed onto the target, and an additional +10 reward is given if all four boxes are on the target, which will also end the episode. A reward of -1 is given if a box on the target is pushed away from it. A reward of -0.01 is added at every time step to encourage solving the task as quickly as possible. The maximum length of each episode is around 120 steps, after which the episode is forced to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 8, 8]) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Thinker is installed sucessfully\n",
    "# the thinker.make environment return a batched environment; here we use a batch size of 16\n",
    "\n",
    "env_n = 4 # batch size of the environment; can be increased to like 128 if using GPU\n",
    "gpu = False # change to True for using GPU instead of CPU\n",
    "mini_sokoban = True # if True, use mini-sokoban board (i.e. board is 8x8x7 array)\n",
    "\n",
    "env = thinker.make(\n",
    "    \"Sokoban-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, # wrapper_type 1 means default environment without Thinker-augmentation\n",
    "    has_model=False, # the following arg are mainly for Thinker-augmentation only\n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban     \n",
    "    ) \n",
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    action = torch.tensor(env.action_space.sample())\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(state[\"real_states\"].shape, type(state[\"real_states\"]))\n",
    "if mini_sokoban:\n",
    "    viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "else:\n",
    "    util.plot_raw_state(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: -0.51\n"
     ]
    }
   ],
   "source": [
    "# now let's define a DRC agent\n",
    "from thinker.actor_net import DRCNet\n",
    "\n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) # the default flags; almost all of them won't be used in DRC\n",
    "flags.mini = mini\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# should take less than a few minutes to complete 100 episodes; average return should be around -1.00\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: 12.37\n"
     ]
    }
   ],
   "source": [
    "# now let load a trained DRC agent\n",
    "import os\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep49500192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "\n",
    "# create list to store agent+env states\n",
    "agent_env_list = []\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# create and activate logit lens\n",
    "from thinker.logitlens import DRCTickLogitLens\n",
    "drc_lens = DRCTickLogitLens(drc_net=drc_net)\n",
    "drc_lens.activate()\n",
    "logit_list = []\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    logit_list.append(drc_lens.get_logits(env_out))\n",
    "    agent_env_list.append((drc_net.hidden_state, state[\"real_states\"]))\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "\n",
    "drc_lens.deactivate()\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns))) # should have a return of around 13, i.e. over 90% solving rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mcreate_gif_multi_env_single_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_env_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_env_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgif_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_channel\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchannel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/viz_utils.py:177\u001b[0m, in \u001b[0;36mcreate_gif_multi_env_single_channel\u001b[0;34m(agent_env_list, envs, layer, channel, mini, max_frames, gif_file, gif_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tick_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m    176\u001b[0m         axs[tick_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, env_idx]\u001b[38;5;241m.\u001b[39mimshow(agent_states[env, tick_idx,layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m+\u001b[39mchannel,:,:]\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 177\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m camera\u001b[38;5;241m.\u001b[39msnap()\n\u001b[1;32m    179\u001b[0m n_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:665\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    663\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from thinker.viz_utils import create_gif_multi_env_single_channel, create_gif_single_env_multi_channels\n",
    "for layer in [0,1,2]:\n",
    "    for channel in range(64):\n",
    "        create_gif_multi_env_single_channel(agent_env_list=agent_env_list,\n",
    "                                            envs=[0,1,2,3], layer=layer,\n",
    "                                            channel=channel, \n",
    "                                            mini=True, \n",
    "                                            gif_name=f\"layer{layer}_channel{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_detector(feature_idx, mode):\n",
    "    \"\"\"Create feature detector functions to extract features from mini-sokoban boards. Boards must be (7,8,8) arrays\n",
    "    Args:\n",
    "        feature_idx (int): index of feature of interest (see sokoban.cpp)\n",
    "        mode (str): either \"adj\" (to count number of adjacent features) or \"num\" (to count total number of features on board)\n",
    "    \"\"\"\n",
    "    assert mode in [\"adj\", \"num\"], \"Please enter a valid mode - either ADJ or NUM\"\n",
    "    if mode == \"adj\":\n",
    "        def feature_detector(board):\n",
    "            h, w = board.shape[1:]\n",
    "            x, y = ((board[4,:,:]==1) + (board[5,:,:]==1)).nonzero()[0,:]\n",
    "            adj_coords = [(xp, yp) for xp, yp in [(x+1,y), (x-1,y), (x,y+1), (x,y-1)] if xp>-1 and xp<h and yp>-1 and yp<w]\n",
    "            n_hits = 0\n",
    "            for (xp,yp) in adj_coords:\n",
    "                if board[feature_idx, xp, yp] == 1:\n",
    "                    n_hits += 1\n",
    "            return n_hits\n",
    "    else:\n",
    "        def feature_detector(board):\n",
    "            return torch.sum((board[feature_idx,:,:]==1).int()).item()\n",
    "    return feature_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_wall_detector = make_feature_detector(feature_idx=0, mode=\"adj\")\n",
    "adj_boxnotontar_detector = make_feature_detector(feature_idx=2, mode=\"adj\")\n",
    "adj_boxontar_detector = make_feature_detector(feature_idx=3, mode=\"adj\")\n",
    "adj_tar_detector = make_feature_detector(feature_idx=6, mode=\"adj\")\n",
    "num_boxnotontar_detector = make_feature_detector(feature_idx=2, mode=\"num\")\n",
    "feature_fncs = [\n",
    "    (\"adj_walls\", adj_wall_detector),\n",
    "    (\"adj_boxnotontar\", adj_boxnotontar_detector),\n",
    "    (\"adj_boxontar\", adj_boxontar_detector),\n",
    "    (\"adj_tar_detector\", adj_tar_detector),\n",
    "    (\"num_boxnotontar_detector\", num_boxnotontar_detector)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tom/mlmi/dissertation/thinker_private_planning/logs/thinker/drc_base/ckp_actor.tar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.full_path(ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = thinker.make(\n",
    "    \"Sokoban-v0\", \n",
    "    env_n=1, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, # wrapper_type 1 means default environment without Thinker-augmentation\n",
    "    has_model=False, # the following arg are mainly for Thinker-augmentation only\n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        return self.data[index]\n",
    "    def get_feature_range(self, feature: str) -> tuple[int, int]:\n",
    "        assert feature in self.data[0].keys(), f\"Please enter a feature in dataset: {self.data[0].keys()}\"\n",
    "        min_feature_value, max_feature_value = self.data[0][feature], self.data[0][feature]\n",
    "        for entry in self.data:\n",
    "            if entry[feature] > max_feature_value:\n",
    "                max_feature_value = entry[feature]\n",
    "            elif entry[feature] < min_feature_value:\n",
    "                min_feature_value = entry[feature]\n",
    "        return (min_feature_value, max_feature_value)\n",
    "\n",
    "probing_data = []\n",
    "episode_entry = []\n",
    "\n",
    "rnn_state = drc_net.initial_state(batch_size=1, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "episode_length = 0\n",
    "board_num = 0\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "\n",
    "    if episode_length > 0:\n",
    "        step_entry[\"reward\"] = reward.item()\n",
    "        episode_entry.append(step_entry)\n",
    "\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "\n",
    "    step_entry = {feature:fnc(state[\"real_states\"][0]) for feature, fnc in feature_fncs}\n",
    "    step_entry[\"action\"] = actor_out.action.item()\n",
    "    step_entry[\"board_state\"] = state[\"real_states\"][0]\n",
    "    step_entry[\"hidden_states\"] = drc_net.hidden_state[0]\n",
    "    step_entry[\"board_num\"] = board_num\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        for step, step_entry in enumerate(episode_entry):\n",
    "            step_entry[\"episode_length\"] = episode_length\n",
    "            step_entry[\"steps_remaining\"] = episode_length - step\n",
    "            step_entry[\"action_plus1\"] = episode_entry[step+1][\"action\"] if step < episode_length-2 else 9\n",
    "            step_entry[\"action_plus2\"] = episode_entry[step+2][\"action\"] if step < episode_length-3 else 9\n",
    "            step_entry[\"action_plus3\"] = episode_entry[step+3][\"action\"] if step < episode_length-4 else 9\n",
    "            step_entry[\"action_plus4\"] = episode_entry[step+4][\"action\"] if step < episode_length-5 else 9\n",
    "            step_entry[\"action_plus5\"] = episode_entry[step+5][\"action\"] if step < episode_length-6 else 9\n",
    "            step_entry[\"reward_plus1\"] = episode_entry[step+1][\"reward\"] if step < episode_length-2 else 9\n",
    "            step_entry[\"reward_plus2\"] = episode_entry[step+2][\"reward\"] if step < episode_length-3 else 9\n",
    "            step_entry[\"reward_plus3\"] = episode_entry[step+3][\"reward\"] if step < episode_length-4 else 9\n",
    "            step_entry[\"reward_plus4\"] = episode_entry[step+4][\"reward\"] if step < episode_length-5 else 9\n",
    "            step_entry[\"reward_plus5\"] = episode_entry[step+5][\"reward\"] if step < episode_length-6 else 9\n",
    "        probing_data += episode_entry\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "        episode_length = 0\n",
    "        board_num += 1\n",
    "\n",
    "probing_dataset = ProbingDataset(probing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(probing_dataset, './probe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"./probe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, NamedTuple, Callable\n",
    "class LinearProbe(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer: int, tick: int, target_dim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        assert layer in [0,1,2], \"Please chose a valid layer: 0, 1 or 2\"\n",
    "        assert tick in [0,1,2,3], \"Please enter a valid tick: 0, 1, 2, or 4\"\n",
    "        self.layer = layer\n",
    "        self.tick = tick\n",
    "        self.target_dim = target_dim\n",
    "        self.linear = nn.Linear(in_features=64*64, out_features=self.target_dim, bias=bias)\n",
    "\n",
    "    def forward(self, hidden_states: torch.tensor) -> torch.tensor:\n",
    "        probe_inputs = hidden_states[:,self.tick,64*self.layer:64*(self.layer+1),:,:]\n",
    "        probe_inputs = probe_inputs.view(hidden_states.shape[0],-1)\n",
    "        probe_logits = self.linear(probe_inputs)\n",
    "        probe_probs = F.softmax(probe_logits, dim=-1)\n",
    "        return probe_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 --- Train loss: 1.466135797056101, Val loss: 1.337951678340718\n",
      "EPOCH 2 --- Train loss: 1.2506467592918267, Val loss: 1.176947417905775\n",
      "EPOCH 3 --- Train loss: 1.1361232579764673, Val loss: 1.1009750466225512\n",
      "EPOCH 4 --- Train loss: 1.0805146404242112, Val loss: 1.0610883378376395\n",
      "EPOCH 5 --- Train loss: 1.0493658492120645, Val loss: 1.037329767720174\n",
      "EPOCH 6 --- Train loss: 1.030004870891571, Val loss: 1.0216663242396662\n",
      "EPOCH 7 --- Train loss: 1.0165119182255309, Val loss: 1.0109329448918165\n",
      "EPOCH 8 --- Train loss: 1.0066582534272792, Val loss: 1.0025986941184029\n",
      "EPOCH 9 --- Train loss: 0.999466976472887, Val loss: 0.9957765117540198\n",
      "EPOCH 10 --- Train loss: 0.9935125426720764, Val loss: 0.9901916537244441\n",
      "EPOCH 11 --- Train loss: 0.9886659763627134, Val loss: 0.9858122583162987\n",
      "EPOCH 12 --- Train loss: 0.9845780449398494, Val loss: 0.9821819767103357\n",
      "EPOCH 13 --- Train loss: 0.9810686380176221, Val loss: 0.9791026535680738\n",
      "EPOCH 14 --- Train loss: 0.9782296181735346, Val loss: 0.9764119459410845\n",
      "EPOCH 15 --- Train loss: 0.9756160564341787, Val loss: 0.9739726748506902\n",
      "EPOCH 16 --- Train loss: 0.9732729625903954, Val loss: 0.9718168572854188\n",
      "EPOCH 17 --- Train loss: 0.9711746076406058, Val loss: 0.9699706686755358\n",
      "EPOCH 18 --- Train loss: 0.9693954510203863, Val loss: 0.968997778932927\n",
      "EPOCH 19 --- Train loss: 0.9676731456134279, Val loss: 0.9665092965303841\n",
      "EPOCH 20 --- Train loss: 0.966200099557133, Val loss: 0.9651646499916658\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=3)\n",
    "num_targets = 4\n",
    "\n",
    "probe = LinearProbe(layer=2,tick=3,target_dim=5)\n",
    "optimiser = torch.optim.SGD(params=probe.parameters(), lr=1e-4)\n",
    "loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(probe: LinearProbe, feature: str, optimiser: torch.optim.Optimizer, loss_fnc: Callable, train_loader: DataLoader) -> int:\n",
    "    train_loss = []\n",
    "    for transition in train_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        optimiser.zero_grad()\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    return sum(train_loss) / len(train_loss)\n",
    "\n",
    "def calc_loss(probe: LinearProbe, feature: str, data_loader: DataLoader) -> int:\n",
    "    losses = []\n",
    "    for transition in data_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def train_probe(probe: LinearProbe, feature: str, n_epochs: int, optimiser: torch.optim.Optimizer, loss_fnc: Callable, train_loader: DataLoader, val_loader: DataLoader, display_loss_freq: int = 1) -> int:\n",
    "    n_epochs = 20\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = train_one_epoch(probe=probe, feature=feature, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader)\n",
    "        with torch.no_grad():\n",
    "            val_loss = calc_loss(probe=probe, feature=feature, data_loader=train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if display_loss_freq and epoch % display_loss_freq == 0:\n",
    "            print(f\"EPOCH {epoch} --- Train loss: {train_loss}, Val loss: {val_loss}\") \n",
    "    train_output = {\"probe\": probe, \"train_loss\": train_losses, \"val_loss\": val_losses}\n",
    "    return train_output\n",
    "\n",
    "def make_trained_probe_for_discrete_feature(feature: str, layer: int, tick: int, train_dataset: ProbingDataset, val_dataset: ProbingDataset, batch_size: int = 16, n_epochs: int = 20, lr: float = 1e-3, weight_decay: float =  1, optimiser_name: str = \"SGD\", display_loss_freq: int = 5) -> dict:\n",
    "    assert layer in [0,1,2], \"Please enter a valid DRC layer: [0,1,2]\"\n",
    "    assert tick in [0,1,2,3], \"Please enter a valid DRC tick: [0,1,2,3]\"\n",
    "    assert feature in train_dataset[0].keys(), f\"Please enter a concept contained in the dataset: {next(iter(train_loader))[0].keys()}\"\n",
    "\n",
    "    min_feature, max_feature = train_dataset.get_feature_range(feature=feature)\n",
    "    if min_feature != 0:\n",
    "        for entry in train_dataset.data:\n",
    "            entry[feature] -= min_feature\n",
    "        for entry in val_dataset.data:\n",
    "            entry[feature] -= min_feature\n",
    "\n",
    "    probe = LinearProbe(layer=2, tick=3, target_dim=max_feature+1-min_feature)\n",
    "    loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "    if optimiser_name == \"SGD\":\n",
    "        optimiser = torch.optim.SGD(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimiser_name == \"Adam\":\n",
    "        optimiser = torch.optim.Adam(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(\"Please select a supported optimiser: SGD, Adam\")\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "    train_output = train_probe(probe=probe, feature=feature, n_epochs=n_epochs, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader, val_loader=val_loader, display_loss_freq=display_loss_freq)\n",
    "    return train_output\n",
    "\n",
    "train_output = make_trained_probe_for_discrete_feature(feature=\"action\",\n",
    "                                                       layer=2,\n",
    "                                                       tick=3,\n",
    "                                                       train_dataset=dataset,\n",
    "                                                       val_dataset=dataset,\n",
    "                                                       batch_size=4,\n",
    "                                                       display_loss_freq=1, \n",
    "                                                       weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1829, 0.3042, 0.2490, 0.2640],\n",
       "        [0.1751, 0.2985, 0.2512, 0.2752],\n",
       "        [0.1982, 0.2996, 0.2521, 0.2501]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 1]), tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_adj_walls, torch.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2tick3_probe = LinearProbe(layer=2,tick=3,target_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adj_walls', 'adj_boxnotontar', 'adj_boxontar', 'adj_tar_detector', 'num_boxnotontar_detector', 'action', 'board_state', 'hidden_states', 'board_num', 'reward', 'episode_length', 'steps_remaining', 'action_plus1', 'action_plus2', 'action_plus3', 'action_plus4', 'action_plus5', 'reward_plus1', 'reward_plus2', 'reward_plus3', 'reward_plus4', 'reward_plus5'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2494, 0.2633, 0.2292, 0.2582],\n",
       "        [0.2625, 0.2587, 0.2511, 0.2277],\n",
       "        [0.2164, 0.2590, 0.2567, 0.2679]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = dl_item[\"hidden_states\"]\n",
    "ys = layer2tick3_probe(hs)\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick=3\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t(hs[:,tick,64*layer:64*(layer+1),:,:].view(hs.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2732, 0.2018, 0.2308, 0.2942],\n",
       "        [0.2540, 0.2105, 0.2213, 0.3141],\n",
       "        [0.2463, 0.2044, 0.2292, 0.3200]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 192, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "You can directly access the stacked hidden state by `.hidden_state` after each call to drc_net:\n",
    "\n",
    "`print(drc_net.hidden_state.shape) # should be [16, 4, 192, 10, 10]`\n",
    "\n",
    "16 is the batch size; 4 is the four hidden state for the three inner ticks (h_0, h_1, h_2, h_3); 192 is the stacked channel (each RNN-layer has 64 channel, and there are 3 RNN-layers); 10 are the width and height \n",
    "\n",
    "## Relevant Files\n",
    "\n",
    "- `thinker/actor_net.py` contains the DRC network\n",
    "- `thinker/core/rnn.py` contains the DRC-block used for building DRC\n",
    "- `learn_actor.py` contains the code for training the agent; not necessary for this project unless you need to train a new agent\n",
    "\n",
    "In case you want to train a new DRC agent, run (take around a day for a 3090):\n",
    "\n",
    "`python train.py --xpid drc --drc true --actor_unroll_len 20 --reg_cost 1 --actor_learning_rate 4e-4 --entropy_cost 1e-2 --v_trace_lamb 0.97 --actor_adam_eps 1e-4 --has_model false`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
