{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting DRC\n",
    "\n",
    "This notebook will give a brief guide for the project of interpreting planning agents. Note that the majority of the code in this repo is used for another planning algorithm called the Thinker, so only a few Python files in this repo are necessary for the project. First, follow the readme to install Sokoban and the Thinker repo. If Sokoban is installed successfully, you should be able to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import thinker\n",
    "import thinker.viz_utils as viz\n",
    "import thinker.util as util\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment shape + type: (8, 8, 7) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Sokoban is installed sucessfully\n",
    "mini = True\n",
    "env = gym.make(\"Sokoban-v0\", mini=mini)\n",
    "state = env.reset()\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(\"Environment shape + type:\", state.shape, type(state))\n",
    "if mini:\n",
    "    viz.plot_mini_sokoban(state, True)\n",
    "else:  \n",
    "    plt.imshow(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sokoban_room_status': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 6, 1, 1, 0, 0, 0, 0, 1,\n",
       "        2, 6, 1, 1, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 4, 0, 0, 0, 6, 1, 0, 0, 1, 1, 1, 0, 0, 0, 6, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 'sokoban_step_n': 102,\n",
       " 'sokoban_done': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.clone_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sokoban\n",
    "The goal is to push all four boxes to the target space (the red-bordered location). There are five actions: no-op, left, up, down, right. Boxes can only be pushed but not pulled. A reward of +1 is given if a box is pushed onto the target, and an additional +10 reward is given if all four boxes are on the target, which will also end the episode. A reward of -1 is given if a box on the target is pushed away from it. A reward of -0.01 is added at every time step to encourage solving the task as quickly as possible. The maximum length of each episode is around 120 steps, after which the episode is forced to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 8, 8]) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Thinker is installed sucessfully\n",
    "# the thinker.make environment return a batched environment; here we use a batch size of 16\n",
    "\n",
    "env_n = 4 # batch size of the environment; can be increased to like 128 if using GPU\n",
    "gpu = False # change to True for using GPU instead of CPU\n",
    "mini_sokoban = True # if True, use mini-sokoban board (i.e. board is 8x8x7 array)\n",
    "\n",
    "env = thinker.make(\n",
    "    \"Sokoban-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, # wrapper_type 1 means default environment without Thinker-augmentation\n",
    "    has_model=False, # the following arg are mainly for Thinker-augmentation only\n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban     \n",
    "    ) \n",
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    action = torch.tensor(env.action_space.sample())\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(state[\"real_states\"].shape, type(state[\"real_states\"]))\n",
    "if mini_sokoban:\n",
    "    viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "else:\n",
    "    util.plot_raw_state(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: -0.71\n"
     ]
    }
   ],
   "source": [
    "# now let's define a DRC agent\n",
    "from thinker.actor_net import DRCNet\n",
    "\n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) # the default flags; almost all of them won't be used in DRC\n",
    "flags.mini = mini\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# should take less than a few minutes to complete 100 episodes; average return should be around -1.00\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: 12.56\n"
     ]
    }
   ],
   "source": [
    "# now let load a trained DRC agent\n",
    "import os\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep49500192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "\n",
    "# create list to store agent+env states\n",
    "agent_env_list = []\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# create and activate logit lens\n",
    "from thinker.logitlens import DRCTickLogitLens\n",
    "drc_lens = DRCTickLogitLens(drc_net=drc_net)\n",
    "drc_lens.activate()\n",
    "logit_list = []\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    logit_list.append(drc_lens.get_logits(env_out))\n",
    "    agent_env_list.append((drc_net.hidden_state, state[\"real_states\"]))\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "\n",
    "drc_lens.deactivate()\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns))) # should have a return of around 13, i.e. over 90% solving rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mcreate_gif_multi_env_single_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_env_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_env_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgif_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_channel\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchannel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/viz_utils.py:177\u001b[0m, in \u001b[0;36mcreate_gif_multi_env_single_channel\u001b[0;34m(agent_env_list, envs, layer, channel, mini, max_frames, gif_file, gif_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tick_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m    176\u001b[0m         axs[tick_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, env_idx]\u001b[38;5;241m.\u001b[39mimshow(agent_states[env, tick_idx,layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m+\u001b[39mchannel,:,:]\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 177\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m camera\u001b[38;5;241m.\u001b[39msnap()\n\u001b[1;32m    179\u001b[0m n_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:665\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    663\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from thinker.viz_utils import create_gif_multi_env_single_channel, create_gif_single_env_multi_channels\n",
    "for layer in [0,1,2]:\n",
    "    for channel in range(64):\n",
    "        create_gif_multi_env_single_channel(agent_env_list=agent_env_list,\n",
    "                                            envs=[0,1,2,3], layer=layer,\n",
    "                                            channel=channel, \n",
    "                                            mini=True, \n",
    "                                            gif_name=f\"layer{layer}_channel{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_detector(feature_idx, mode):\n",
    "    \"\"\"Create feature detector functions to extract features from mini-sokoban boards. Boards must be (7,8,8) arrays\n",
    "    Args:\n",
    "        feature_idx (int): index of feature of interest (see sokoban.cpp)\n",
    "        mode (str): either \"adj\" (to count number of adjacent features) or \"num\" (to count total number of features on board)\n",
    "    \"\"\"\n",
    "    assert mode in [\"adj\", \"num\"], \"Please enter a valid mode - either ADJ or NUM\"\n",
    "    if mode == \"adj\":\n",
    "        def feature_detector(board):\n",
    "            h, w = board.shape[1:]\n",
    "            x, y = ((board[4,:,:]==1) + (board[5,:,:]==1)).nonzero()[0,:]\n",
    "            adj_coords = [(xp, yp) for xp, yp in [(x+1,y), (x-1,y), (x,y+1), (x,y-1)] if xp>-1 and xp<h and yp>-1 and yp<w]\n",
    "            n_hits = 0\n",
    "            for (xp,yp) in adj_coords:\n",
    "                if board[feature_idx, xp, yp] == 1:\n",
    "                    n_hits += 1\n",
    "            return n_hits\n",
    "    else:\n",
    "        def feature_detector(board):\n",
    "            return torch.sum((board[feature_idx,:,:]==1).int()).item()\n",
    "    return feature_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_wall_detector = make_feature_detector(feature_idx=0, mode=\"adj\")\n",
    "adj_boxnotontar_detector = make_feature_detector(feature_idx=2, mode=\"adj\")\n",
    "adj_boxontar_detector = make_feature_detector(feature_idx=3, mode=\"adj\")\n",
    "adj_tar_detector = make_feature_detector(feature_idx=6, mode=\"adj\")\n",
    "num_boxnotontar_detector = make_feature_detector(feature_idx=2, mode=\"num\")\n",
    "feature_fncs = [\n",
    "    (\"adj_walls\", adj_wall_detector),\n",
    "    (\"adj_boxnotontar\", adj_boxnotontar_detector),\n",
    "    (\"adj_boxontar\", adj_boxontar_detector),\n",
    "    (\"adj_tar_detector\", adj_tar_detector),\n",
    "    (\"num_boxnotontar_detector\", num_boxnotontar_detector)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tom/mlmi/dissertation/thinker_private_planning/logs/thinker/drc_base/ckp_actor.tar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.full_path(ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = thinker.make(\n",
    "    \"Sokoban-v0\", \n",
    "    env_n=1, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, # wrapper_type 1 means default environment without Thinker-augmentation\n",
    "    has_model=False, # the following arg are mainly for Thinker-augmentation only\n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        return self.data[index]\n",
    "    def get_feature_range(self, feature: str) -> tuple[int, int]:\n",
    "        assert feature in self.data[0].keys(), f\"Please enter a feature in dataset: {self.data[0].keys()}\"\n",
    "        min_feature_value, max_feature_value = self.data[0][feature], self.data[0][feature]\n",
    "        for entry in self.data:\n",
    "            if entry[feature] > max_feature_value:\n",
    "                max_feature_value = entry[feature]\n",
    "            elif entry[feature] < min_feature_value:\n",
    "                min_feature_value = entry[feature]\n",
    "        return (min_feature_value, max_feature_value)\n",
    "\n",
    "probing_data = []\n",
    "episode_entry = []\n",
    "\n",
    "rnn_state = drc_net.initial_state(batch_size=1, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "episode_length = 0\n",
    "board_num = 0\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "\n",
    "    if episode_length > 0:\n",
    "        step_entry[\"reward\"] = reward.item()\n",
    "        episode_entry.append(step_entry)\n",
    "\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "\n",
    "    step_entry = {feature:fnc(state[\"real_states\"][0]) for feature, fnc in feature_fncs}\n",
    "    step_entry[\"action\"] = actor_out.action.item()\n",
    "    step_entry[\"board_state\"] = state[\"real_states\"][0]\n",
    "    step_entry[\"hidden_states\"] = drc_net.hidden_state[0]\n",
    "    step_entry[\"board_num\"] = board_num\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        for step, step_entry in enumerate(episode_entry):\n",
    "            step_entry[\"episode_length\"] = episode_length\n",
    "            step_entry[\"steps_remaining\"] = episode_length - step\n",
    "            step_entry[\"action_plus1\"] = episode_entry[step+1][\"action\"] if step < episode_length-2 else 9\n",
    "            step_entry[\"action_plus2\"] = episode_entry[step+2][\"action\"] if step < episode_length-3 else 9\n",
    "            step_entry[\"action_plus3\"] = episode_entry[step+3][\"action\"] if step < episode_length-4 else 9\n",
    "            step_entry[\"action_plus4\"] = episode_entry[step+4][\"action\"] if step < episode_length-5 else 9\n",
    "            step_entry[\"action_plus5\"] = episode_entry[step+5][\"action\"] if step < episode_length-6 else 9\n",
    "            step_entry[\"reward_plus1\"] = episode_entry[step+1][\"reward\"] if step < episode_length-2 else 9\n",
    "            step_entry[\"reward_plus2\"] = episode_entry[step+2][\"reward\"] if step < episode_length-3 else 9\n",
    "            step_entry[\"reward_plus3\"] = episode_entry[step+3][\"reward\"] if step < episode_length-4 else 9\n",
    "            step_entry[\"reward_plus4\"] = episode_entry[step+4][\"reward\"] if step < episode_length-5 else 9\n",
    "            step_entry[\"reward_plus5\"] = episode_entry[step+5][\"reward\"] if step < episode_length-6 else 9\n",
    "        probing_data += episode_entry\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "        episode_length = 0\n",
    "        board_num += 1\n",
    "\n",
    "probing_dataset = ProbingDataset(probing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(probing_dataset, './probe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "probing_dataset = torch.load(\"./probe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(probing_dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, NamedTuple, Callable\n",
    "class LinearProbe(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer: int, tick: int, target_dim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        assert layer in [0,1,2], \"Please chose a valid layer: 0, 1 or 2\"\n",
    "        assert tick in [0,1,2,3], \"Please enter a valid tick: 0, 1, 2, or 4\"\n",
    "        self.layer = layer\n",
    "        self.tick = tick\n",
    "        self.target_dim = target_dim\n",
    "        self.linear = nn.Linear(in_features=64*64, out_features=self.target_dim, bias=bias)\n",
    "\n",
    "    def forward(self, hidden_states: torch.tensor) -> torch.tensor:\n",
    "        probe_inputs = hidden_states[:,self.tick,64*self.layer:64*(self.layer+1),:,:]\n",
    "        probe_inputs = probe_inputs.view(hidden_states.shape[0],-1)\n",
    "        probe_logits = self.linear(probe_inputs)\n",
    "        probe_probs = F.softmax(probe_logits, dim=-1)\n",
    "        return probe_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 --- Train loss: 1.4770791474330067, Val loss: 1.36956243172224\n",
      "EPOCH 2 --- Train loss: 1.2888137547243306, Val loss: 1.2173280733849359\n",
      "EPOCH 3 --- Train loss: 1.1742539964776182, Val loss: 1.1350189411589005\n",
      "EPOCH 4 --- Train loss: 1.1115810125426673, Val loss: 1.089120436507745\n",
      "EPOCH 5 --- Train loss: 1.0754297896260356, Val loss: 1.0613432031588492\n",
      "EPOCH 6 --- Train loss: 1.0526568933106288, Val loss: 1.0428470928269906\n",
      "EPOCH 7 --- Train loss: 1.0367224235647226, Val loss: 1.0299723116369206\n",
      "EPOCH 8 --- Train loss: 1.0254510427493395, Val loss: 1.019865202417701\n",
      "EPOCH 9 --- Train loss: 1.0167277364515952, Val loss: 1.0122703372664719\n",
      "EPOCH 10 --- Train loss: 1.009776673731374, Val loss: 1.0060763090465201\n",
      "EPOCH 11 --- Train loss: 1.0040502123566657, Val loss: 1.0010943025222663\n",
      "EPOCH 12 --- Train loss: 0.9993443588842138, Val loss: 0.9966291253147207\n",
      "EPOCH 13 --- Train loss: 0.9953237807801865, Val loss: 0.9930023433312838\n",
      "EPOCH 14 --- Train loss: 0.9918490343851081, Val loss: 0.9897025641965252\n",
      "EPOCH 15 --- Train loss: 0.9887956776076632, Val loss: 0.9868933169626882\n",
      "EPOCH 16 --- Train loss: 0.9861095900699305, Val loss: 0.9845126512992024\n",
      "EPOCH 17 --- Train loss: 0.9837275657786831, Val loss: 0.9821958471521287\n",
      "EPOCH 18 --- Train loss: 0.981578902753126, Val loss: 0.9802536585811893\n",
      "EPOCH 19 --- Train loss: 0.9797722985048662, Val loss: 0.9783810824795343\n",
      "EPOCH 20 --- Train loss: 0.9779095900416885, Val loss: 0.9767612701066062\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(probing_dataset, batch_size=3)\n",
    "num_targets = 4\n",
    "\n",
    "probe = LinearProbe(layer=2,tick=3,target_dim=5)\n",
    "optimiser = torch.optim.SGD(params=probe.parameters(), lr=1e-4)\n",
    "loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(probe: LinearProbe, feature: str, optimiser: torch.optim.Optimizer, loss_fnc: Callable, train_loader: DataLoader) -> int:\n",
    "    train_loss = []\n",
    "    for transition in train_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        optimiser.zero_grad()\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    return sum(train_loss) / len(train_loss)\n",
    "\n",
    "def calc_loss(probe: LinearProbe, feature: str, data_loader: DataLoader) -> int:\n",
    "    losses = []\n",
    "    for transition in data_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def train_probe(probe: LinearProbe, feature: str, n_epochs: int, optimiser: torch.optim.Optimizer, loss_fnc: Callable, train_loader: DataLoader, val_loader: DataLoader, display_loss_freq: int = 1) -> int:\n",
    "    n_epochs = 20\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = train_one_epoch(probe=probe, feature=feature, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader)\n",
    "        with torch.no_grad():\n",
    "            val_loss = calc_loss(probe=probe, feature=feature, data_loader=train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if display_loss_freq and epoch % display_loss_freq == 0:\n",
    "            print(f\"EPOCH {epoch} --- Train loss: {train_loss}, Val loss: {val_loss}\") \n",
    "    train_output = {\"probe\": probe, \"train_loss\": train_losses, \"val_loss\": val_losses}\n",
    "    return train_output\n",
    "\n",
    "def make_trained_probe_for_discrete_feature(feature: str, layer: int, tick: int, train_dataset: ProbingDataset, val_dataset: ProbingDataset, batch_size: int = 16, n_epochs: int = 20, lr: float = 1e-3, weight_decay: float =  1, optimiser_name: str = \"SGD\", display_loss_freq: int = 5) -> dict:\n",
    "    assert layer in [0,1,2], \"Please enter a valid DRC layer: [0,1,2]\"\n",
    "    assert tick in [0,1,2,3], \"Please enter a valid DRC tick: [0,1,2,3]\"\n",
    "    assert feature in train_dataset[0].keys(), f\"Please enter a concept contained in the dataset: {next(iter(train_loader))[0].keys()}\"\n",
    "\n",
    "    min_feature, max_feature = train_dataset.get_feature_range(feature=feature)\n",
    "    if min_feature != 0:\n",
    "        for entry in train_dataset.data:\n",
    "            entry[feature] -= min_feature\n",
    "        for entry in val_dataset.data:\n",
    "            entry[feature] -= min_feature\n",
    "\n",
    "    probe = LinearProbe(layer=2, tick=3, target_dim=max_feature+1-min_feature)\n",
    "    loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "    if optimiser_name == \"SGD\":\n",
    "        optimiser = torch.optim.SGD(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimiser_name == \"Adam\":\n",
    "        optimiser = torch.optim.Adam(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(\"Please select a supported optimiser: SGD, Adam\")\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "    train_output = train_probe(probe=probe, feature=feature, n_epochs=n_epochs, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader, val_loader=val_loader, display_loss_freq=display_loss_freq)\n",
    "    return train_output\n",
    "\n",
    "train_output = make_trained_probe_for_discrete_feature(feature=\"action\",\n",
    "                                                       layer=0,\n",
    "                                                       tick=0,\n",
    "                                                       train_dataset=probing_dataset,\n",
    "                                                       val_dataset=probing_dataset,\n",
    "                                                       batch_size=4,\n",
    "                                                       display_loss_freq=1, \n",
    "                                                       weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2494, 0.2633, 0.2292, 0.2582],\n",
       "        [0.2625, 0.2587, 0.2511, 0.2277],\n",
       "        [0.2164, 0.2590, 0.2567, 0.2679]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = dl_item[\"hidden_states\"]\n",
    "ys = layer2tick3_probe(hs)\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinker import make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick=3\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2732, 0.2018, 0.2308, 0.2942],\n",
       "        [0.2540, 0.2105, 0.2213, 0.3141],\n",
       "        [0.2463, 0.2044, 0.2292, 0.3200]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 192, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "You can directly access the stacked hidden state by `.hidden_state` after each call to drc_net:\n",
    "\n",
    "`print(drc_net.hidden_state.shape) # should be [16, 4, 192, 10, 10]`\n",
    "\n",
    "16 is the batch size; 4 is the four hidden state for the three inner ticks (h_0, h_1, h_2, h_3); 192 is the stacked channel (each RNN-layer has 64 channel, and there are 3 RNN-layers); 10 are the width and height \n",
    "\n",
    "## Relevant Files\n",
    "\n",
    "- `thinker/actor_net.py` contains the DRC network\n",
    "- `thinker/core/rnn.py` contains the DRC-block used for building DRC\n",
    "- `learn_actor.py` contains the code for training the agent; not necessary for this project unless you need to train a new agent\n",
    "\n",
    "In case you want to train a new DRC agent, run (take around a day for a 3090):\n",
    "\n",
    "`python train.py --xpid drc --drc true --actor_unroll_len 20 --reg_cost 1 --actor_learning_rate 4e-4 --entropy_cost 1e-2 --v_trace_lamb 0.97 --actor_adam_eps 1e-4 --has_model false`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
