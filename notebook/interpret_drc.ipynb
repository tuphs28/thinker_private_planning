{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting DRC\n",
    "\n",
    "This notebook will give a brief guide for the project of interpreting planning agents. Note that the majority of the code in this repo is used for another planning algorithm called the Thinker, so only a few Python files in this repo are necessary for the project. First, follow the readme to install Sokoban and the Thinker repo. If Sokoban is installed successfully, you should be able to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import thinker\n",
    "import thinker.viz_utils as viz\n",
    "import thinker.util as util\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tracked_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackedSokobanBox:\n",
    "\n",
    "    def __init__(self, loc):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): 1, (1, 2): 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment shape + type: (8, 8, 7) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Sokoban is installed sucessfully\n",
    "mini = True\n",
    "env = gym.make(\"Sokoban-v0\", mini=mini)\n",
    "state = env.reset()\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(\"Environment shape + type:\", state.shape, type(state))\n",
    "if mini:\n",
    "    viz.plot_mini_sokoban(state, True)\n",
    "else:  \n",
    "    plt.imshow(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sokoban_room_status': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 6, 1, 1, 0, 0, 0, 0, 1,\n",
       "        2, 6, 1, 1, 1, 2, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 4, 0, 0, 0, 6, 1, 0, 0, 1, 1, 1, 0, 0, 0, 6, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 'sokoban_step_n': 102,\n",
       " 'sokoban_done': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.clone_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sokoban\n",
    "The goal is to push all four boxes to the target space (the red-bordered location). There are five actions: no-op, left, up, down, right. Boxes can only be pushed but not pulled. A reward of +1 is given if a box is pushed onto the target, and an additional +10 reward is given if all four boxes are on the target, which will also end the episode. A reward of -1 is given if a box on the target is pushed away from it. A reward of -0.01 is added at every time step to encourage solving the task as quickly as possible. The maximum length of each episode is around 120 steps, after which the episode is forced to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cpu\n",
      "Init. environment with obs space \u001b[91mBox(0, 1, (7, 8, 8), uint8)\u001b[0m and action space \u001b[91mDiscrete(5)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 8, 8]) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if Thinker is installed sucessfully\n",
    "# the thinker.make environment return a batched environment; here we use a batch size of 16\n",
    "\n",
    "env_n = 4 # batch size of the environment; can be increased to like 128 if using GPU\n",
    "gpu = False # change to True for using GPU instead of CPU\n",
    "mini_sokoban = True # if True, use mini-sokoban board (i.e. board is 8x8x7 array)\n",
    "\n",
    "env = thinker.make(\n",
    "    \"Sokoban-v0\", \n",
    "    env_n=env_n, \n",
    "    gpu=gpu,\n",
    "    wrapper_type=1, # wrapper_type 1 means default environment without Thinker-augmentation\n",
    "    has_model=False, # the following arg are mainly for Thinker-augmentation only\n",
    "    train_model=False, \n",
    "    parallel=False, \n",
    "    save_flags=False,\n",
    "    mini=mini_sokoban     \n",
    "    ) \n",
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    action = torch.tensor(env.action_space.sample())\n",
    "    state, reward, done, info = env.step(action)\n",
    "print(state[\"real_states\"].shape, type(state[\"real_states\"]))\n",
    "if mini_sokoban:\n",
    "    viz.plot_mini_sokoban(state[\"real_states\"][0])\n",
    "else:\n",
    "    util.plot_raw_state(state[\"real_states\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: -0.51\n"
     ]
    }
   ],
   "source": [
    "# now let's define a DRC agent\n",
    "from thinker.actor_net import DRCNet\n",
    "\n",
    "flags = util.create_setting(args=[], save_flags=False, wrapper_type=1) # the default flags; almost all of them won't be used in DRC\n",
    "flags.mini = True\n",
    "drc_net = DRCNet(\n",
    "    obs_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    flags=flags,\n",
    "    record_state=True,\n",
    "    )\n",
    "drc_net.to(env.device)\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# should take less than a few minutes to complete 100 episodes; average return should be around -1.00\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return: 12.35\n"
     ]
    }
   ],
   "source": [
    "# now let load a trained DRC agent\n",
    "import os\n",
    "ckp_path = \"../drc_mini\"\n",
    "ckp_path = os.path.join(util.full_path(ckp_path), \"ckp_actor_realstep49500192.tar\")\n",
    "ckp = torch.load(ckp_path, env.device)\n",
    "drc_net.load_state_dict(ckp[\"actor_net_state_dict\"], strict=False)\n",
    "\n",
    "# create list to store agent+env states\n",
    "agent_env_list = []\n",
    "\n",
    "# define initial RNN-state of DRC\n",
    "rnn_state = drc_net.initial_state(batch_size=env_n, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "\n",
    "# create and activate logit lens\n",
    "from thinker.logitlens import DRCTickLogitLens\n",
    "drc_lens = DRCTickLogitLens(drc_net=drc_net)\n",
    "drc_lens.activate()\n",
    "logit_list = []\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 10):\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "    logit_list.append(drc_lens.get_logits(env_out))\n",
    "    agent_env_list.append((drc_net.hidden_state, state[\"real_states\"]))\n",
    "    # record done episode\n",
    "    if torch.any(done):\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "\n",
    "drc_lens.deactivate()\n",
    "    \n",
    "print(\"Average return: %.2f\" % torch.mean(torch.tensor(episode_returns))) # should have a return of around 13, i.e. over 90% solving rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 288, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mcreate_gif_multi_env_single_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_env_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_env_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgif_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_channel\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchannel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlmi/dissertation/thinker_private_planning/thinker/thinker/viz_utils.py:177\u001b[0m, in \u001b[0;36mcreate_gif_multi_env_single_channel\u001b[0;34m(agent_env_list, envs, layer, channel, mini, max_frames, gif_file, gif_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tick_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m    176\u001b[0m         axs[tick_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, env_idx]\u001b[38;5;241m.\u001b[39mimshow(agent_states[env, tick_idx,layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m+\u001b[39mchannel,:,:]\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 177\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m camera\u001b[38;5;241m.\u001b[39msnap()\n\u001b[1;32m    179\u001b[0m n_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:665\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    663\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from thinker.viz_utils import create_gif_multi_env_single_channel, create_gif_single_env_multi_channels\n",
    "for layer in [0,1,2]:\n",
    "    for channel in range(64):\n",
    "        create_gif_multi_env_single_channel(agent_env_list=agent_env_list,\n",
    "                                            envs=[0,1,2,3], layer=layer,\n",
    "                                            channel=channel, \n",
    "                                            mini=True, \n",
    "                                            gif_name=f\"layer{layer}_channel{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 192, 8, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 32, 8, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = drc_net.normalize(env_out.real_states.float())\n",
    "x = torch.flatten(x, 0, 1)\n",
    "x_enc = drc_net.encoder(x)\n",
    "torch.stack([x_enc]*4, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 64, 8, 8]),\n",
       " torch.Size([4, 4, 64, 8, 8]),\n",
       " torch.Size([4, 4, 64, 8, 8]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state[:,:,:64,:,:].shape, drc_net.hidden_state[:,:,64:128,:,:].shape, drc_net.hidden_state[:,:,128:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 288, 8, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([\n",
    "    drc_net.hidden_state[:,:,torch.arange(0,64,2),:,:], drc_net.hidden_state[:,:,torch.arange(1,64,2),:,:], torch.stack([x_enc]*4, dim=0),\n",
    "    drc_net.hidden_state[:,:,torch.arange(64,128,2),:,:], drc_net.hidden_state[:,:,torch.arange(65,128,2),:,:], torch.stack([x_enc]*4, dim=0),\n",
    "    drc_net.hidden_state[:,:,torch.arange(128,192,2),:,:], drc_net.hidden_state[:,:,torch.arange(129,192,2),:,:], torch.stack([x_enc]*4, dim=0)\n",
    "], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 32, 8, 8]), torch.Size([4, 4, 32, 8, 8]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state[:,:,torch.arange(0,64,2),:,:].shape, drc_net.hidden_state[:,:,torch.arange(1,64,2),:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        return self.data[index]\n",
    "    def get_feature_range(self, feature: str) -> tuple[int, int]:\n",
    "        assert feature in self.data[0].keys(), f\"Please enter a feature in dataset: {self.data[0].keys()}\"\n",
    "        min_feature_value, max_feature_value = self.data[0][feature], self.data[0][feature]\n",
    "        for entry in self.data:\n",
    "            if entry[feature] > max_feature_value:\n",
    "                max_feature_value = entry[feature]\n",
    "            elif entry[feature] < min_feature_value:\n",
    "                min_feature_value = entry[feature]\n",
    "        return (min_feature_value, max_feature_value)\n",
    "\n",
    "probing_data = []\n",
    "episode_entry = []\n",
    "\n",
    "rnn_state = drc_net.initial_state(batch_size=1, device=env.device)\n",
    "\n",
    "# run the trained drc again\n",
    "state = env.reset() \n",
    "env_out = util.init_env_out(state, flags, dim_actions=1, tuple_action=False) # this converts the state to EnvOut object that can be processed by actor\n",
    "actor_out, rnn_state = drc_net(env_out, rnn_state) # actor_out contains both the critic and actor output of DRC\n",
    "episode_length = 0\n",
    "board_num = 0\n",
    "\n",
    "episode_returns = []\n",
    "while(len(episode_returns) < 1):\n",
    "\n",
    "    if episode_length > 0:\n",
    "        step_entry[\"reward\"] = reward.item()\n",
    "        episode_entry.append(step_entry)\n",
    "\n",
    "    state, reward, done, info = env.step(actor_out.action)\n",
    "    env_out = util.create_env_out(actor_out.action, state, reward, done, info, flags)\n",
    "    actor_out, rnn_state = drc_net(env_out, rnn_state)\n",
    "\n",
    "    step_entry = {feature:fnc(state[\"real_states\"][0]) for feature, fnc in feature_fncs}\n",
    "    step_entry[\"action\"] = actor_out.action.item()\n",
    "    step_entry[\"board_state\"] = state[\"real_states\"][0]\n",
    "    step_entry[\"hidden_states\"] = drc_net.hidden_state[0]\n",
    "    step_entry[\"board_num\"] = board_num\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        viz.plot_mini_sokoban(episode_entry[-1][\"board_state\"])\n",
    "        for step, step_entry in enumerate(episode_entry):\n",
    "            step_entry[\"episode_length\"] = episode_length\n",
    "            step_entry[\"steps_remaining\"] = episode_length - step - 1\n",
    "            step_entry[\"action_plus1\"] = episode_entry[step+1][\"action\"] if step < episode_length-2 else 9\n",
    "            step_entry[\"action_plus2\"] = episode_entry[step+2][\"action\"] if step < episode_length-3 else 9\n",
    "            step_entry[\"action_plus3\"] = episode_entry[step+3][\"action\"] if step < episode_length-4 else 9\n",
    "            #step_entry[\"action_plus4\"] = episode_entry[step+4][\"action\"] if step < episode_length-5 else 9\n",
    "            #step_entry[\"action_plus5\"] = episode_entry[step+5][\"action\"] if step < episode_length-6 else 9\n",
    "            #step_entry[\"reward_plus1\"] = episode_entry[step+1][\"reward\"] if step < episode_length-2 else 9\n",
    "            #step_entry[\"reward_plus2\"] = episode_entry[step+2][\"reward\"] if step < episode_length-3 else 9\n",
    "            #step_entry[\"reward_plus3\"] = episode_entry[step+3][\"reward\"] if step < episode_length-4 else 9\n",
    "            #step_entry[\"reward_plus4\"] = episode_entry[step+4][\"reward\"] if step < episode_length-5 else 9\n",
    "            #step_entry[\"reward_plus5\"] = episode_entry[step+5][\"reward\"] if step < episode_length-6 else 9\n",
    "        probing_data += episode_entry\n",
    "        episode_returns.extend(info[\"episode_return\"][done].tolist())\n",
    "        episode_length = 0\n",
    "        board_num += 1\n",
    "\n",
    "probing_dataset = ProbingDataset(probing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(probing_dataset, './probe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "probing_dataset = torch.load(\"./probe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "from typing import Optional\n",
    "\n",
    "class DRCProbe(nn.Module):\n",
    "    \"\"\"Linear probe for the DRC(3,3) agent\"\"\"\n",
    "    \n",
    "    def __init__(self, drc_layer: int, drc_tick: int, target_dim: int, linear: bool = True, num_layers: int = 1, hidden_dim: int = 64, bias: bool = True, drc_channels: Optional[list] = None):\n",
    "        super().__init__()\n",
    "        assert drc_layer in [0,1,2], \"Please chose a valid layer: 0, 1 or 2\"\n",
    "        assert drc_tick in [0,1,2,3], \"Please enter a valid tick: 0, 1, 2, or 4\"\n",
    "        self.drc_layer = drc_layer\n",
    "        self.drc_tick = drc_tick\n",
    "        self.target_dim = target_dim\n",
    "        self.linear = linear\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.drc_channels = [64*self.layer + c for c in drc_channels] if drc_channels is not None else list(range(64*self.drc_layer, 64*(self.drc_layer+1)))\n",
    "        self.in_dim = 64 * len(self.drc_channels)\n",
    "\n",
    "        if self.linear:\n",
    "            self.network = nn.Linear(in_features=self.in_dim, out_features=self.target_dim, bias=bias)\n",
    "        else:\n",
    "            layers = []\n",
    "            for layer_idx in range(num_layers):\n",
    "                if layer_idx == 0:\n",
    "                    layers += [nn.Linear(in_features=self.in_dim, out_features=self.hidden_dim), nn.ReLU()]\n",
    "                else:\n",
    "                    layers += [nn.Linear(in_features=self.hidden_dim, out_features=self.hidden_dim), nn.ReLU()]\n",
    "            layers += [nn.Linear(in_features=self.hidden_dim, out_features=self.target_dim)]\n",
    "            self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, hidden_states: torch.tensor) -> torch.tensor:\n",
    "        probe_inputs = hidden_states[:,self.drc_tick,self.drc_channels,:,:]\n",
    "        probe_inputs = probe_inputs.view(hidden_states.shape[0],-1)\n",
    "        probe_logits = self.network(probe_inputs)\n",
    "        probe_probs = softmax(probe_logits, dim=-1)\n",
    "        return probe_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(probing_dataset, batch_size=3)\n",
    "num_targets = 4\n",
    "\n",
    "#probe = DRCProbe(layer=2,tick=3,target_dim=5)\n",
    "#optimiser = torch.optim.SGD(params=probe.parameters(), lr=1e-4)\n",
    "loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(probe: DRCProbe, feature: str, optimiser: torch.optim.Optimizer, loss_fnc, train_loader: DataLoader) -> int:\n",
    "    train_loss = []\n",
    "    for transition in train_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        optimiser.zero_grad()\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    return sum(train_loss) / len(train_loss)\n",
    "\n",
    "def calc_loss(probe: DRCProbe, feature: str, data_loader: DataLoader) -> int:\n",
    "    losses = []\n",
    "    for transition in data_loader:\n",
    "        hidden_states = transition[\"hidden_states\"]\n",
    "        targets = transition[feature]\n",
    "        probe_logits = probe(hidden_states)\n",
    "        loss = loss_fnc(probe_logits, targets)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def train_probe(probe: DRCProbe, feature: str, n_epochs: int, optimiser: torch.optim.Optimizer, loss_fnc: Callable, train_loader: DataLoader, val_loader: DataLoader, display_loss_freq: int = 1) -> int:\n",
    "    n_epochs = 20\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = train_one_epoch(probe=probe, feature=feature, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader)\n",
    "        with torch.no_grad():\n",
    "            val_loss = calc_loss(probe=probe, feature=feature, data_loader=train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if display_loss_freq and epoch % display_loss_freq == 0:\n",
    "            print(f\"EPOCH {epoch} --- Train loss: {train_loss}, Val loss: {val_loss}\") \n",
    "    train_output = {\"probe\": probe, \"train_loss\": train_losses, \"val_loss\": val_losses}\n",
    "    return train_output\n",
    "\n",
    "def make_trained_probe_for_discrete_feature(feature: str, layer: int, tick: int, train_dataset: ProbingDataset, val_dataset: ProbingDataset, batch_size: int = 16, n_epochs: int = 20, lr: float = 1e-3, weight_decay: float =  1, optimiser_name: str = \"SGD\", display_loss_freq: int = 5) -> dict:\n",
    "    assert layer in [0,1,2], \"Please enter a valid DRC layer: [0,1,2]\"\n",
    "    assert tick in [0,1,2,3], \"Please enter a valid DRC tick: [0,1,2,3]\"\n",
    "    assert feature in train_dataset[0].keys(), f\"Please enter a concept contained in the dataset: {next(iter(train_loader))[0].keys()}\"\n",
    "\n",
    "    min_feature, max_feature = train_dataset.get_feature_range(feature=feature)\n",
    "    if min_feature != 0:\n",
    "        print(min_feature, max_feature)\n",
    "        for entry in train_dataset.data:\n",
    "            entry[feature] -= min_feature\n",
    "        #for entry in val_dataset.data:\n",
    "            #entry[feature] -= min_feature\n",
    "\n",
    "    probe = DRCProbe(drc_layer=2, drc_tick=3, target_dim=max_feature+1-min_feature, linear=False)\n",
    "    loss_fnc = torch.nn.CrossEntropyLoss()\n",
    "    if optimiser_name == \"SGD\":\n",
    "        optimiser = torch.optim.SGD(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimiser_name == \"Adam\":\n",
    "        optimiser = torch.optim.Adam(params=probe.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(\"Please select a supported optimiser: SGD, Adam\")\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "    train_output = train_probe(probe=probe, feature=feature, n_epochs=n_epochs, optimiser=optimiser, loss_fnc=loss_fnc, train_loader=train_loader, val_loader=val_loader, display_loss_freq=display_loss_freq)\n",
    "    return train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_args = {\n",
    "    \"layer\": 2,\n",
    "    \"tick\": 3,\n",
    "    \"target_dim\": 5,\n",
    "    \"linear\": False,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_dim\": 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"1\": 1}\n",
    "b = a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '2': 2}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"2\"] = 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([probing_dataset[i][\"num_boxnotontar\"] for i in range(len(probing_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'train_loader' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[43mmake_trained_probe_for_discrete_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_boxnotontar_until_change\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtick\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobing_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobing_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdisplay_loss_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 48\u001b[0m, in \u001b[0;36mmake_trained_probe_for_discrete_feature\u001b[0;34m(feature, layer, tick, train_dataset, val_dataset, batch_size, n_epochs, lr, weight_decay, optimiser_name, display_loss_freq)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a valid DRC layer: [0,1,2]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a valid DRC tick: [0,1,2,3]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m train_dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a concept contained in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m min_feature, max_feature \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mget_feature_range(feature\u001b[38;5;241m=\u001b[39mfeature)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_feature \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'train_loader' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train_output = make_trained_probe_for_discrete_feature(feature=\"num_boxnotontar_until_change\",\n",
    "                                                       layer=2,\n",
    "                                                       tick=0,\n",
    "                                                       train_dataset=probing_dataset,\n",
    "                                                       val_dataset=probing_dataset,\n",
    "                                                       batch_size=4,\n",
    "                                                       display_loss_freq=1, \n",
    "                                                       weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2494, 0.2633, 0.2292, 0.2582],\n",
       "        [0.2625, 0.2587, 0.2511, 0.2277],\n",
       "        [0.2164, 0.2590, 0.2567, 0.2679]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = dl_item[\"hidden_states\"]\n",
    "ys = layer2tick3_probe(hs)\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinker import make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick=3\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2732, 0.2018, 0.2308, 0.2942],\n",
       "        [0.2540, 0.2105, 0.2213, 0.3141],\n",
       "        [0.2463, 0.2044, 0.2292, 0.3200]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRCNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(7, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (core): ConvAttnLSTM(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ConvAttnLSTMCell(\n",
       "        (main): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (proj): Conv2d(32, 32, kernel_size=(2, 1), stride=(1, 1), groups=32)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=4096, out_features=256, bias=True)\n",
       "  (policy): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (baseline): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 192, 8, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drc_net.hidden_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "You can directly access the stacked hidden state by `.hidden_state` after each call to drc_net:\n",
    "\n",
    "`print(drc_net.hidden_state.shape) # should be [16, 4, 192, 10, 10]`\n",
    "\n",
    "16 is the batch size; 4 is the four hidden state for the three inner ticks (h_0, h_1, h_2, h_3); 192 is the stacked channel (each RNN-layer has 64 channel, and there are 3 RNN-layers); 10 are the width and height \n",
    "\n",
    "## Relevant Files\n",
    "\n",
    "- `thinker/actor_net.py` contains the DRC network\n",
    "- `thinker/core/rnn.py` contains the DRC-block used for building DRC\n",
    "- `learn_actor.py` contains the code for training the agent; not necessary for this project unless you need to train a new agent\n",
    "\n",
    "In case you want to train a new DRC agent, run (take around a day for a 3090):\n",
    "\n",
    "`python train.py --xpid drc --drc true --actor_unroll_len 20 --reg_cost 1 --actor_learning_rate 4e-4 --entropy_cost 1e-2 --v_trace_lamb 0.97 --actor_adam_eps 1e-4 --has_model false`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
