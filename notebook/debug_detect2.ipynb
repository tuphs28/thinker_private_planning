{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing v5b_sok_drc from ../logs/detect\n",
      "Initializing env 0 with device cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from ../logs/detect/v5b_sok_drc/config_c.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data output directory: /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0\n",
      "Number of file to be generated: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputting to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import time, timeit\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from thinker.actor_net import ActorNet\n",
    "from thinker.main import Env\n",
    "import thinker.util as util\n",
    "from thinker.self_play import init_env_out, create_env_out\n",
    "\n",
    "class DetectBuffer:\n",
    "    def __init__(self, outdir, t, rec_t, logger, delay_n=5):\n",
    "        \"\"\"\n",
    "        Store training data grouped in planning stages and output\n",
    "        whenever the target output is also readydd\n",
    "            Args:\n",
    "                N (int): number of planning stage per training output\n",
    "                delay_n (int): number of planning stage delayed in the output y\n",
    "                rec_t (int): number of step in a planning stage\n",
    "                K (int): number of block to merge into\n",
    "        \"\"\"\n",
    "        self.outdir = outdir\n",
    "        self.t = t # number of time step per file\n",
    "        self.rec_t = rec_t\n",
    "        self.logger = logger        \n",
    "        self.delay_n = delay_n        \n",
    "\n",
    "        self.processed_n, self.xs, self.y, self.done, self.step_status = 0, [], [], [], []\n",
    "        self.file_idx = -1\n",
    "    \n",
    "    def insert(self, xs, y, done, step_status):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xs (dict): dictionary of training input, with each elem having the\n",
    "                shape of (B, *)            \n",
    "            y (tensor): bool tensor of shape (B), being the target output delayed by\n",
    "                delay_n planning stage            \n",
    "            done (tensor): bool tensor of shape (B), being the indicator of episode end\n",
    "            step_status (int): int indicating current step status\n",
    "        Output:\n",
    "            save train_xs in shape (N, rec_t, B, *) and train_y in shape (N, B)\n",
    "        \"\"\"\n",
    "        #print(\"data received! \", y.shape, id, cur_t)\n",
    "        last_step_real = (step_status == 0) | (step_status == 3)\n",
    "        if len(self.step_status) == 0 and not last_step_real: return self.file_idx  # skip until real step\n",
    "                \n",
    "        self.xs.append(util.dict_map(xs, lambda x:x.cpu()))\n",
    "        self.y.append(y.cpu())\n",
    "        self.done.append(done.cpu())\n",
    "        self.step_status.append(step_status)\n",
    "        self.processed_n += int(last_step_real)\n",
    "\n",
    "        if (self.processed_n >= self.t + self.delay_n + 1):               \n",
    "            self.file_idx += 1                     \n",
    "            out = self._extract_data(self.t)\n",
    "            self.processed_n = sum([int(i == 0) + int(i == 3) for i in self.step_status])\n",
    "            assert self.processed_n == self.delay_n+1, f\"should only have {self.delay_n + 1} data left instead of {self.processed_n}\"\n",
    "            path = f'{self.outdir}/data_{self.file_idx}.pt'\n",
    "            torch.save(out, path)\n",
    "            out_shape = out[0]['env_state'].shape\n",
    "            n = self.file_idx * out_shape[0] * out_shape[2]\n",
    "            self.logger.info(f\"{n}: File saved to {path}; env_state shape {out_shape}\")\n",
    "\n",
    "        return self.file_idx   \n",
    "\n",
    "    def _extract_data(self, t):\n",
    "        # obtain the first N planning stage and the corresponding target_y in data\n",
    "        xs, y, done, step_status = self._collect_data(t)\n",
    "        future_y, future_done = self._collect_data(self.delay_n, y_done_only=True)\n",
    "        y = torch.concat([y, future_y], dim=0)\n",
    "        done = torch.concat([done, future_done], dim=0)                \n",
    "        \n",
    "        last_step_real = (step_status == 0) | (step_status == 3)\n",
    "        assert last_step_real[0], \"cur_t should start with 0\"\n",
    "        assert last_step_real.shape[0] == t*self.rec_t, \\\n",
    "            f\" step_status.shape is {last_step_real.shape}, expected {t*self.rec_t} for the first dimension.\"        \n",
    "        assert y.shape[0] == (t + self.delay_n)*self.rec_t, \\\n",
    "            f\" y.shape is {y.shape}, expected {(t + self.delay_n)*self.rec_t} for the first dimension.\"        \n",
    "        \n",
    "        B = y.shape[1]\n",
    "        y = y.view(t + self.delay_n, self.rec_t, B)[:, 0]\n",
    "        done = done.view(t + self.delay_n, self.rec_t, B)[:, 0]\n",
    "        step_status = step_status.view(t, self.rec_t)\n",
    "        # compute target_y\n",
    "        target_y = self._compute_target_y(y, done, self.delay_n)\n",
    "\n",
    "        for k in xs.keys():\n",
    "            xs[k] = xs[k].view((t, self.rec_t) + xs[k].shape[1:])\n",
    "        \n",
    "        xs[\"done\"] = done[:t]\n",
    "        xs[\"step_status\"] = step_status\n",
    "                \n",
    "        return xs, target_y\n",
    "\n",
    "    def _collect_data(self, t, y_done_only=False):\n",
    "        # collect the first t stage from data\n",
    "        step_status = torch.tensor(self.step_status, dtype=torch.long)\n",
    "        next_step_real = (step_status == 2) | (step_status == 3)        \n",
    "        idx = torch.nonzero(next_step_real, as_tuple=False).squeeze()    \n",
    "        last_idx = idx[t-1] + 1\n",
    "        y = torch.stack(self.y[:last_idx], dim=0)\n",
    "        done = torch.stack(self.done[:last_idx], dim=0)\n",
    "        if not y_done_only:\n",
    "            xs = {}\n",
    "            for k in self.xs[0].keys():\n",
    "                xs[k] = torch.stack([v[k] for v in self.xs[:last_idx]], dim=0)                \n",
    "            step_status = step_status[:last_idx]\n",
    "            self.xs = self.xs[last_idx:]\n",
    "            self.y = self.y[last_idx:]\n",
    "            self.done = self.done[last_idx:]\n",
    "            self.step_status = self.step_status[last_idx:]\n",
    "            return xs, y, done, step_status\n",
    "        else:\n",
    "            return y, done\n",
    "        \n",
    "    def _compute_target_y(self, y, done, delay_n):        \n",
    "        # target_y[i] = (y[i] | (~done[i+1] & y[i+1]) | (~done[i+1] & ~done[i+2] & y[i+2]) | ... | (~done[i+1] & ~done[i+2] & ... & ~done[i+M] & y[i+M]))\n",
    "        t, b = y.shape\n",
    "        t = t - delay_n\n",
    "        not_done_cum = torch.ones(delay_n, t, b, dtype=bool)\n",
    "        target_y = y.clone()[:-delay_n]\n",
    "        not_done_cum[0] = ~done[1:1+t]\n",
    "        target_y = target_y | (not_done_cum[0] & y[1:1+t])\n",
    "        for m in range(1, delay_n):\n",
    "            not_done_cum[m] = not_done_cum[m-1] & ~done[m+1:m+1+t]\n",
    "            target_y = target_y | (not_done_cum[m] & y[m+1:m+1+t])\n",
    "        return target_y\n",
    "\n",
    "# ========================================================\n",
    "    \n",
    "total_n = 100000\n",
    "env_n = 128\n",
    "delay_n = 5\n",
    "savedir = \"../logs/detect\"\n",
    "outdir = \"../data/detect\"\n",
    "xpid = \"v5b_sok_drc\"\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "_logger = util.logger()\n",
    "_logger.info(f\"Initializing {xpid} from {savedir}\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "ckpdir = os.path.join(savedir, xpid)     \n",
    "if os.path.islink(ckpdir): ckpdir = os.readlink(ckpdir)  \n",
    "ckpdir =  os.path.abspath(os.path.expanduser(ckpdir))\n",
    "outdir = os.path.abspath(os.path.expanduser(outdir))\n",
    "\n",
    "config_path = os.path.join(ckpdir, 'config_c.yaml')\n",
    "flags = util.create_flags(config_path, save_flags=False)\n",
    "disable_thinker = flags.wrapper_type == 1\n",
    "\n",
    "env = Env(\n",
    "        name=flags.name,\n",
    "        env_n=env_n,\n",
    "        gpu=True,\n",
    "        train_model=False,\n",
    "        parallel=False,\n",
    "        savedir=savedir,        \n",
    "        xpid=xpid,\n",
    "        ckp=True,\n",
    "        return_x=True,\n",
    "        return_h=True,\n",
    "    )\n",
    "\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space \n",
    "\n",
    "actor_param = {\n",
    "    \"obs_space\": obs_space,\n",
    "    \"action_space\": action_space,\n",
    "    \"flags\": flags,\n",
    "    \"tree_rep_meaning\": env.get_tree_rep_meaning() if not disable_thinker else None,\n",
    "}\n",
    "actor_net = ActorNet(**actor_param)\n",
    "\n",
    "path = os.path.join(ckpdir, \"ckp_actor.tar\")\n",
    "checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "actor_net.set_weights(checkpoint[\"actor_net_state_dict\"])\n",
    "actor_net.to(device)\n",
    "actor_net.train(False)\n",
    "\n",
    "state = env.reset()\n",
    "env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "\n",
    "# create dir\n",
    "\n",
    "n = 0\n",
    "while True:\n",
    "    name = \"%s-%d-%d\" % (xpid, checkpoint[\"real_step\"], n)\n",
    "    outdir_ = os.path.join(outdir, name)\n",
    "    if not os.path.exists(outdir_):\n",
    "        os.makedirs(outdir_)\n",
    "        print(f\"Outputting to {outdir_}\")\n",
    "        break\n",
    "    n += 1\n",
    "outdir = outdir_\n",
    "\n",
    "detect_buffer = DetectBuffer(outdir=outdir, t=12800//env_n, rec_t=flags.rec_t, logger=_logger, delay_n=delay_n)\n",
    "file_n = total_n // (env_n * detect_buffer.t) + 1\n",
    "_logger.info(f\"Data output directory: {outdir}\")\n",
    "_logger.info(f\"Number of file to be generated: {file_n}\")\n",
    "\n",
    "rescale = \"Sokoban\" in flags.name\n",
    "\n",
    "# save setting\n",
    "\n",
    "env_state_shape = env.observation_space[\"real_states\"].shape[1:]\n",
    "#if rescale: env_state_shape = (3, 40, 40)\n",
    "tree_rep_shape = env.observation_space[\"tree_reps\"].shape[1:] if not disable_thinker else None\n",
    "\n",
    "flags_detect = {\n",
    "    \"dim_actions\": actor_net.dim_actions,\n",
    "    \"num_actions\": actor_net.num_actions,\n",
    "    \"tuple_actions\": actor_net.tuple_action,\n",
    "    \"name\": flags.name,\n",
    "    \"env_state_shape\": list(env_state_shape),\n",
    "    \"tree_rep_shape\": list(tree_rep_shape) if not disable_thinker else None,\n",
    "    \"rescale\": rescale,\n",
    "    \"rec_t\": flags.rec_t,\n",
    "    \"ckpdir\": ckpdir,\n",
    "    \"net_xpid\": xpid,\n",
    "    \"disable_thinker\": disable_thinker,\n",
    "}\n",
    "\n",
    "yaml_file_path = os.path.join(outdir, 'config_detect.yaml')\n",
    "with open(yaml_file_path, 'w') as file:\n",
    "    yaml.dump(flags_detect, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_0.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 246; Return  13.65089437825893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_1.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 522; Return  12.714808594107172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_2.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 801; Return  12.437977707508798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_3.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1113; Return  12.481985800068655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_4.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1408; Return  12.60919760573994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_5.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1702; Return  12.595252807391097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_6.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1989; Return  12.581000670378623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_7.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2284; Return  12.581444997712318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800: File saved to /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5b_sok_drc-49622080-0/data_8.pt; env_state shape torch.Size([100, 1, 1, 128, 3, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "\n",
    "    rets = []\n",
    "    last_file_idx = None\n",
    "    \n",
    "    while(True):\n",
    "\n",
    "        actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\n",
    "        if not disable_thinker:\n",
    "            primary_action, reset_action = actor_out.action\n",
    "        else:\n",
    "            primary_action, reset_action = actor_out.action, None\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action, \n",
    "            action_prob=actor_out.action_prob[-1])    \n",
    "        env_out = create_env_out(actor_out.action, state, reward, done, info, flags=flags)\n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())\n",
    "        \n",
    "        # write to detect buffer\n",
    "        if not disable_thinker:\n",
    "            env_state = env_out.xs[0] \n",
    "            if rescale:\n",
    "                #env_state = F.interpolate(env_state , size=(40, 40), mode='bilinear', align_corners=False)\n",
    "                env_state = (env_state * 255).to(torch.uint8)\n",
    "        else:\n",
    "            env_state = env_out.real_states\n",
    "        pri_action = primary_action\n",
    "        xs = {\n",
    "            \"env_state\": env_state,\n",
    "            \"pri_action\": pri_action,            \n",
    "            \"cost\": info[\"cost\"],\n",
    "        }\n",
    "        if not disable_thinker:\n",
    "            xs.update({\n",
    "                \"tree_rep\": state[\"tree_reps\"],\n",
    "                \"reset_action\": actor_out.action[1],\n",
    "            })\n",
    "\n",
    "        y = info['cost']\n",
    "        done = done\n",
    "        step_status = info['step_status'][0].item()\n",
    "\n",
    "        file_idx = detect_buffer.insert(xs, y, done, step_status)\n",
    "        \n",
    "        if file_idx >= file_n: \n",
    "            # last file is for validation\n",
    "            os.rename(f'{outdir}/data_{file_idx}.pt', f'{outdir}/val.pt')\n",
    "            break\n",
    "\n",
    "        if last_file_idx is not None and file_idx != last_file_idx:\n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "\n",
    "        last_file_idx = file_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 3, 80, 80])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_out.real_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from thinker.model_net import BaseNet, FrameEncoder\n",
    "from thinker.actor_net import ShallowAFrameEncoder\n",
    "from thinker import util\n",
    "from thinker.core.file_writer import FileWriter\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datadir, transform=None, data_n=None, prefix=\"data\"):\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        self.data = []        \n",
    "        self.samples_per_file = None   \n",
    "        self.data_n = data_n\n",
    "        self.prefix = prefix\n",
    "        self._preload_data(datadir)  # Preload data        \n",
    "\n",
    "    def _preload_data(self, datadir):\n",
    "        # Preload all .pt files\n",
    "        file_list = [f for f in os.listdir(datadir) if f.endswith('.pt') and f.startswith(self.prefix)]\n",
    "        file_list = sorted(file_list, key=lambda x: int(re.search(r'\\d+', x).group()) if re.search(r'\\d+', x) else 0)\n",
    "        for file_name in file_list:\n",
    "            print(f\"Starting to preload {file_name}\")\n",
    "            xs, y = torch.load(os.path.join(datadir, file_name))\n",
    "            if self.samples_per_file is None:  # Set samples_per_file based on the first file\n",
    "                self.t = xs['env_state'].shape[0]\n",
    "                self.b = xs['env_state'].shape[2]\n",
    "                self.samples_per_file = self.t * self.b\n",
    "            xs.pop('step_status')\n",
    "            xs.pop('done')\n",
    "            # Flatten data across t and b dimensions for easier indexing\n",
    "            for t_idx in range(self.t):\n",
    "                for b_idx in range(self.b):\n",
    "                    flattened_xs = {k: v[t_idx, :, b_idx] for k, v in xs.items()}\n",
    "                    flattened_y = y[t_idx, b_idx]\n",
    "                    self.data.append((flattened_xs, flattened_y))\n",
    "                    if self.data_n is not None and len(self.data) >= self.data_n: return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xs, y = self.data[idx]\n",
    "        if self.transform:\n",
    "            # Apply transform if necessary. Note: You might need to adjust this part\n",
    "            # based on what your transform expects and can handle\n",
    "            xs = {k: self.transform(v) for k, v in xs.items()}            \n",
    "        return xs, y\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 500):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "        return x\n",
    "\n",
    "class DetectFrameEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,     \n",
    "        out_size=128,\n",
    "        downscale=True,\n",
    "    ):  \n",
    "        super(DetectFrameEncoder, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.encoder = FrameEncoder(prefix=\"se\",\n",
    "                                    actions_ch=None,\n",
    "                                    input_shape=input_shape,                             \n",
    "                                    size_nn=1,             \n",
    "                                    downscale_c=2,    \n",
    "                                    downscale=downscale,\n",
    "                                    concat_action=False)\n",
    "        \n",
    "        self.conv = []\n",
    "        in_ch =  self.encoder.out_shape[0]\n",
    "        for ch in [64]:\n",
    "            self.conv.append(nn.ReLU())\n",
    "            self.conv.append(nn.Conv2d(in_channels=in_ch,\n",
    "                                       out_channels=ch,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1,))\n",
    "            in_ch = ch\n",
    "        self.conv = nn.Sequential(*self.conv)\n",
    "        conv_out_size = in_ch * self.encoder.out_shape[1] * self.encoder.out_shape[2]\n",
    "        self.fc = nn.Sequential(nn.Linear(conv_out_size, self.out_size))       \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x in shape of (B, C, H, W)\n",
    "        out, _ = self.encoder(x, done=None, actions=None, state={})\n",
    "        out = self.conv(out)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out                                \n",
    "        \n",
    "class DetectNet(BaseNet):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_state_shape,\n",
    "        tree_rep_shape,\n",
    "        hidden_state_shape,\n",
    "        dim_actions,\n",
    "        num_actions,\n",
    "        detect_ab=(0,0),\n",
    "        clone=False,\n",
    "        tran_layer_n=3,\n",
    "        tran_ff_n=512,\n",
    "        shallow_encode=False,\n",
    "        disable_thinker=False,\n",
    "    ):    \n",
    "        super(DetectNet, self).__init__()\n",
    "        \n",
    "        self.env_state_shape = env_state_shape # in (C, H, W) \n",
    "        self.tree_rep_shape = tree_rep_shape # in (C,) \n",
    "        self.hidden_state_shape = hidden_state_shape # in (inner_t, C, H, W)\n",
    "        self.dim_actions = dim_actions\n",
    "        self.num_actions = num_actions\n",
    "        self.dim_rep_actions = self.dim_actions if self.dim_actions > 1 else self.num_actions\n",
    "\n",
    "        self.detect_ab = detect_ab\n",
    "        self.clone = clone\n",
    "        self.disable_thinker = disable_thinker\n",
    "\n",
    "        self.enc_out_size = 128\n",
    "        tran_nhead = 8\n",
    "        if not self.disable_thinker:\n",
    "            reminder = tran_nhead - ((self.enc_out_size + tree_rep_shape[0] + self.dim_rep_actions + 1) % tran_nhead)\n",
    "        else:\n",
    "            reminder = tran_nhead - ((self.enc_out_size + self.dim_rep_actions) % tran_nhead)\n",
    "        self.enc_out_size += reminder\n",
    "\n",
    "        FrameEncoder = ShallowAFrameEncoder if shallow_encode else DetectFrameEncoder\n",
    "        self.true_x_encoder = FrameEncoder(input_shape=env_state_shape, out_size=self.enc_out_size)\n",
    "        if not self.disable_thinker:\n",
    "            self.pred_x_encoder = FrameEncoder(input_shape=env_state_shape, out_size=self.enc_out_size)\n",
    "        if hidden_state_shape is not None:\n",
    "            self.h_encoder = FrameEncoder(input_shape=hidden_state_shape[1:], out_size=self.enc_out_size, downscale=False)   \n",
    "\n",
    "        #self.pred_x_encoder = self.true_x_encoder\n",
    "        if not self.disable_thinker:\n",
    "            self.embed_size = self.enc_out_size + tree_rep_shape[0] + self.dim_rep_actions + 1\n",
    "        else:\n",
    "            self.embed_size = self.enc_out_size + self.dim_rep_actions\n",
    "        self.pos_encoder = PositionalEncoding(self.embed_size)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.embed_size, \n",
    "                                                   nhead=tran_nhead, \n",
    "                                                   dim_feedforward=tran_ff_n,\n",
    "                                                   batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, tran_layer_n)\n",
    "        self.classifier = nn.Linear(self.embed_size, 1)\n",
    "\n",
    "        self.beta = nn.Parameter(torch.tensor(0.5), requires_grad=False) # portion of negative class\n",
    "\n",
    "    def forward(self, env_state, tree_rep, hidden_state, action, reset):\n",
    "        \"\"\"\n",
    "        Forward pass of detection nn\n",
    "        Args:\n",
    "            env_state: float Tensor in shape of (B, rec_t, C, H, W); true and predicted frame\n",
    "            tree_rep: float Tensor in shape of (B, rec_t, C); model output\n",
    "            hidden_state: float Tensor in shape of (B, rec_t, inner_t, C, H, W); model output\n",
    "            action: uint Tensor in shape of (B, rec_t, dim_actions); action (real / imaginary)\n",
    "            reset: bool Tensor in shape of  (B, rec_t); reset action\n",
    "        Return:\n",
    "            logit: float Tensor in shape of (B); logit of classifier output\n",
    "            p: float Tensor in shape of (B); prob of classifier output\n",
    "        \"\"\"\n",
    "        B, rec_t = env_state.shape[:2]\n",
    "        if self.detect_ab[0] in [1, 3] or self.detect_ab[1] in [1, 3]:\n",
    "            if self.clone: env_state = env_state.clone()                \n",
    "            if self.detect_ab[0] in [1, 3]:\n",
    "                env_state[:, 0] = 0.\n",
    "            if self.detect_ab[1] in [1, 3]:\n",
    "                env_state[:, 1:] = 0.\n",
    "        if self.detect_ab[0] in [2, 3] or self.detect_ab[1] in [2, 3]:\n",
    "            if self.clone: tree_rep = tree_rep.clone()\n",
    "            if self.detect_ab[0] in [2, 3]:\n",
    "                tree_rep[:, 0] = 0.\n",
    "            if self.detect_ab[1] in [2, 3]:\n",
    "                tree_rep[:, 1:] = 0.\n",
    "        \n",
    "        action = util.encode_action(action, self.dim_actions, self.num_actions)        \n",
    "        true_proc_x = self.true_x_encoder(env_state[:,0])\n",
    "        true_proc_x = true_proc_x.view(B, self.enc_out_size).unsqueeze(1) # (B, 1, C)\n",
    "        if not self.disable_thinker:\n",
    "            pred_proc_x = self.pred_x_encoder(\n",
    "                torch.flatten(env_state[:,1:], 0, 1),\n",
    "                                            )            \n",
    "            pred_proc_x = pred_proc_x.view(B, rec_t - 1, self.enc_out_size)  # (B, rec_t - 1, C)\n",
    "            proc_x = torch.concat([true_proc_x, pred_proc_x], dim=1) # (B, rec_t, C)            \n",
    "            embed = [proc_x, tree_rep, action, reset.unsqueeze(-1)]\n",
    "        else:\n",
    "            proc_h = self.h_encoder(torch.flatten(hidden_state[:,0], 0, 1))\n",
    "            proc_h = proc_h.view(B, -1, self.enc_out_size)  # (B, inner_t, C)\n",
    "            proc_x = torch.concat([true_proc_x, proc_h], dim=1) # (B, 1 + inner_t, C)\n",
    "            embed = [proc_x, torch.broadcast_to(action, (B, proc_x.shape[1], self.dim_rep_actions))]\n",
    "            \n",
    "        embed = torch.concat(embed, dim=2) # (B, rec_t, embed_size)\n",
    "        embed_pos = self.pos_encoder(embed)\n",
    "        out = self.transformer_encoder(embed_pos)\n",
    "        logit = self.classifier(out[:, -1, :]).view(B)\n",
    "        return logit, torch.sigmoid(logit)\n",
    "\n",
    "def transform_data(xs, device, flags):\n",
    "    xs_ = {}\n",
    "\n",
    "    env_state = xs[\"env_state\"]\n",
    "    if flags.rescale:\n",
    "        env_state = env_state.float() / 255\n",
    "    xs_[\"env_state\"] = env_state.to(device)\n",
    "\n",
    "    xs_[\"tree_rep\"] = xs[\"tree_rep\"].to(device) if \"tree_rep\" in xs else None\n",
    "\n",
    "    action = xs[\"pri_action\"]\n",
    "    if not flags.tuple_actions:\n",
    "        action = action.unsqueeze(-1)\n",
    "    xs_[\"action\"] = action.to(device)\n",
    "\n",
    "    xs_[\"reset\"] = xs[\"reset_action\"].to(device) if \"reset_action\" in xs else None\n",
    "    xs_[\"hidden_state\"] = xs[\"hidden_state\"].to(device) if \"hidden_state\" in xs else None\n",
    "    return xs_\n",
    "\n",
    "def evaluate_detect(target_y, pred_y):\n",
    "    # Binarize the predictions\n",
    "    pred_y_binarized = (pred_y > 0.5).float()\n",
    "    target_y = target_y.float()\n",
    "\n",
    "    # Compute the accuracy\n",
    "    acc = torch.mean((pred_y_binarized == target_y).float()).item()\n",
    "    \n",
    "    # Compute the recall\n",
    "    true_positives = (pred_y_binarized * target_y).sum().float()\n",
    "    possible_positives = target_y.sum().float()\n",
    "    rec = (true_positives / (possible_positives + 1e-6)).item()\n",
    "    \n",
    "    # Compute the precision\n",
    "    predicted_positives = pred_y_binarized.sum().float()\n",
    "    prec = (true_positives / (predicted_positives + 1e-6)).item()\n",
    "    \n",
    "    # Compute the F1 score\n",
    "    f1 = 2 * (prec * rec) / (prec + rec + 1e-6)   \n",
    "\n",
    "    neg_p = 1 - torch.mean(target_y.float()).item()\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"rec\": rec,\n",
    "        \"prec\": prec,\n",
    "        \"f1\": f1,\n",
    "        \"neg_p\": neg_p,\n",
    "        }\n",
    "\n",
    "def train_epoch(detect_net, dataloader, optimizer, device, flags, train=True):\n",
    "    if train:\n",
    "        detect_net.train()\n",
    "    else:\n",
    "        detect_net.eval()     \n",
    "    running_train_eval = {}   \n",
    "    with torch.set_grad_enabled(train):\n",
    "        step = 0\n",
    "        for xs, target_y in dataloader:\n",
    "            xs = transform_data(xs, device, flags)\n",
    "            target_y = target_y.to(device)\n",
    "            \n",
    "            logit, pred_y = detect_net(**xs)\n",
    "            n_mean_y = torch.mean((~target_y).float()).item()\n",
    "            detect_net.beta.data = 0.99 * detect_net.beta.data + (1 - 0.99) * n_mean_y\n",
    "            detect_net.beta.data.clamp_(0.05, 0.95)\n",
    "            weights = torch.where(target_y == 1, detect_net.beta.data, 1-detect_net.beta.data)\n",
    "            loss = F.binary_cross_entropy_with_logits(logit, target_y.float(), weight=weights)\n",
    "            train_eval = evaluate_detect(target_y, pred_y)\n",
    "            train_eval[\"loss\"] = loss.item()\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()  # Zero the gradients\n",
    "                loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.step()  # Perform a single optimization step (parameter update)\n",
    "            \n",
    "            for key in train_eval.keys():\n",
    "                if key not in running_train_eval: \n",
    "                    running_train_eval[key] = train_eval[key]\n",
    "                else:\n",
    "                    running_train_eval[key] += train_eval[key]\n",
    "            step += 1\n",
    "    return {key: val / step for (key, val) in running_train_eval.items()}\n",
    "\n",
    "def save_ckp(path, epoch, flags, optimizer, detect_net):\n",
    "    # save checkpoint\n",
    "    d = {\n",
    "        \"epoch\": epoch,\n",
    "        \"flags\": flags,\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"net_state_dict\": detect_net.state_dict(),\n",
    "    }\n",
    "    torch.save(d, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datadir, transform=None, data_n=None, prefix=\"data\", chunk_n=1):\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        self.data = []  # Current chunk of data\n",
    "        self.data_n = data_n\n",
    "        self.prefix = prefix\n",
    "        self.file_list = [f for f in os.listdir(datadir) if f.endswith('.pt') and f.startswith(self.prefix)]\n",
    "        self.file_list = sorted(self.file_list, key=lambda x: int(re.search(r'\\d+', x).group()) if re.search(r'\\d+', x) else 0)\n",
    "        \n",
    "        xs, y = torch.load(os.path.join(self.datadir, self.file_list[0]))\n",
    "        self.t = xs['env_state'].shape[0]\n",
    "        self.b = xs['env_state'].shape[2]\n",
    "        self.samples_per_file = self.t * self.b\n",
    "\n",
    "        if data_n is not None:\n",
    "            self.len_list = [self.samples_per_file for _ in range(data_n // self.samples_per_file)]\n",
    "            if data_n % self.samples_per_file > 0: self.len_list.append(data_n % self.samples_per_file)\n",
    "            self.file_list = self.file_list[:len(self.len_list)]\n",
    "        else:\n",
    "            self.len_list = [self.samples_per_file for _ in range(len(self.file_list))]\n",
    "        \n",
    "        self.chunk_n = chunk_n\n",
    "        self.current_chunk = 0  # To track which chunk is currently loaded\n",
    "        self.total_files = len(self.file_list)\n",
    "        self.files_per_chunk = max(1, self.total_files // self.chunk_n)\n",
    "        self.samples_per_chunk = self.files_per_chunk * self.samples_per_file\n",
    "\n",
    "    def _load_chunk(self, chunk_index):\n",
    "        # Determine file range for the current chunk\n",
    "        start_file = chunk_index * self.files_per_chunk\n",
    "        end_file = min(start_file + self.files_per_chunk, self.total_files)\n",
    "        self.data = []  # Clear current data\n",
    "        self.current_chunk = chunk_index\n",
    "        for i in range(start_file, end_file):\n",
    "            data_tmp = []\n",
    "            file_name = self.file_list[i]\n",
    "            print(f\"Loading {file_name}\")\n",
    "            xs, y = torch.load(os.path.join(self.datadir, file_name))\n",
    "            xs.pop('step_status', None)\n",
    "            xs.pop('done', None)\n",
    "            \n",
    "            for t_idx in range(self.t):\n",
    "                for b_idx in range(self.b):\n",
    "                    flattened_xs = {k: v[t_idx, :, b_idx] for k, v in xs.items()}\n",
    "                    flattened_y = y[t_idx, b_idx]\n",
    "                    data_tmp.append((flattened_xs, flattened_y))\n",
    "                    if len(data_tmp) >= self.len_list[i]: \n",
    "                        break\n",
    "        \n",
    "            assert len(data_tmp) >= self.len_list[i], f\"data {i} should have at least {self.len_list[i]} samples instead of {len(data_tmp)}\"\n",
    "            self.data.extend(data_tmp)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data_n is not None: return self.data_n\n",
    "        return self.samples_per_file * self.total_files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which chunk the idx falls into        \n",
    "        chunk_index = idx // self.samples_per_chunk\n",
    "        \n",
    "        # If the requested idx is not in the current chunk, load the correct chunk\n",
    "        if chunk_index != self.current_chunk or not self.data:\n",
    "            self._load_chunk(chunk_index)\n",
    "        \n",
    "        # Adjust idx to the current chunk\n",
    "        idx_within_chunk = idx % self.samples_per_chunk\n",
    "        xs, y = self.data[idx_within_chunk]\n",
    "        if self.transform:\n",
    "            xs = {k: self.transform(v) for k, v in xs.items()}\n",
    "        return xs, y   \n",
    "\n",
    "class ChunkSampler(Sampler):\n",
    "    def __init__(self, dataset):\n",
    "        self.chunk_n = dataset.chunk_n\n",
    "        self.data_n = dataset.data_n\n",
    "        self.samples_per_chunk = dataset.samples_per_chunk\n",
    "        if self.samples_per_chunk * self.chunk_n < self.data_n:\n",
    "            self.chunk_n += 1        \n",
    "\n",
    "    def __iter__(self):\n",
    "        # Generate a list of chunk indices\n",
    "        chunk_indices = np.arange(self.chunk_n)\n",
    "        # Shuffle the list of chunk indices to determine the order in which chunks are processed\n",
    "        np.random.shuffle(chunk_indices)\n",
    "        \n",
    "        # For each chunk, generate and shuffle indices within that chunk, then yield them\n",
    "        for chunk_idx in chunk_indices:\n",
    "            start_idx = chunk_idx * self.samples_per_chunk\n",
    "            end_idx = min(start_idx + self.samples_per_chunk, self.data_n)\n",
    "            indices = np.arange(start_idx, end_idx)\n",
    "            np.random.shuffle(indices)\n",
    "            for idx in indices:\n",
    "                yield idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_n    \n",
    "    \n",
    "dataset = CustomDataset(datadir=\"../data/detect/v5b_sok_drc-49622080-1/\", transform=None, data_n=100000, chunk_n=3)\n",
    "sampler = ChunkSampler(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data_0.pt\n",
      "Loading data_1.pt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "Loading data_2.pt\n",
      "Loading data_3.pt\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n",
      "44900\n",
      "45000\n",
      "45100\n",
      "45200\n",
      "45300\n",
      "45400\n",
      "45500\n",
      "45600\n",
      "45700\n",
      "45800\n",
      "45900\n",
      "46000\n",
      "46100\n",
      "46200\n",
      "46300\n",
      "46400\n",
      "46500\n",
      "46600\n",
      "46700\n",
      "46800\n",
      "46900\n",
      "47000\n",
      "47100\n",
      "47200\n",
      "47300\n",
      "47400\n",
      "47500\n",
      "47600\n",
      "47700\n",
      "47800\n",
      "47900\n",
      "48000\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n",
      "48800\n",
      "48900\n",
      "49000\n",
      "49100\n",
      "49200\n",
      "49300\n",
      "49400\n",
      "49500\n",
      "49600\n",
      "49700\n",
      "49800\n",
      "49900\n",
      "50000\n",
      "50100\n",
      "50200\n",
      "50300\n",
      "50400\n",
      "50500\n",
      "50600\n",
      "50700\n",
      "50800\n",
      "50900\n",
      "51000\n",
      "51100\n",
      "Loading data_4.pt\n",
      "Loading data_5.pt\n",
      "51200\n",
      "51300\n",
      "51400\n",
      "51500\n",
      "51600\n",
      "51700\n",
      "51800\n",
      "51900\n",
      "52000\n",
      "52100\n",
      "52200\n",
      "52300\n",
      "52400\n",
      "52500\n",
      "52600\n",
      "52700\n",
      "52800\n",
      "52900\n",
      "53000\n",
      "53100\n",
      "53200\n",
      "53300\n",
      "53400\n",
      "53500\n",
      "53600\n",
      "53700\n",
      "53800\n",
      "53900\n",
      "54000\n",
      "54100\n",
      "54200\n",
      "54300\n",
      "54400\n",
      "54500\n",
      "54600\n",
      "54700\n",
      "54800\n",
      "54900\n",
      "55000\n",
      "55100\n",
      "55200\n",
      "55300\n",
      "55400\n",
      "55500\n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n",
      "69500\n",
      "69600\n",
      "69700\n",
      "69800\n",
      "69900\n",
      "70000\n",
      "70100\n",
      "70200\n",
      "70300\n",
      "70400\n",
      "70500\n",
      "70600\n",
      "70700\n",
      "70800\n",
      "70900\n",
      "71000\n",
      "71100\n",
      "71200\n",
      "71300\n",
      "71400\n",
      "71500\n",
      "71600\n",
      "71700\n",
      "71800\n",
      "71900\n",
      "72000\n",
      "72100\n",
      "72200\n",
      "72300\n",
      "72400\n",
      "72500\n",
      "72600\n",
      "72700\n",
      "72800\n",
      "72900\n",
      "73000\n",
      "73100\n",
      "73200\n",
      "73300\n",
      "73400\n",
      "73500\n",
      "73600\n",
      "73700\n",
      "73800\n",
      "73900\n",
      "74000\n",
      "74100\n",
      "74200\n",
      "74300\n",
      "74400\n",
      "74500\n",
      "74600\n",
      "74700\n",
      "74800\n",
      "74900\n",
      "75000\n",
      "75100\n",
      "75200\n",
      "75300\n",
      "75400\n",
      "75500\n",
      "75600\n",
      "75700\n",
      "75800\n",
      "75900\n",
      "76000\n",
      "76100\n",
      "76200\n",
      "76300\n",
      "76400\n",
      "76500\n",
      "76600\n",
      "76700\n",
      "Loading data_6.pt\n",
      "Loading data_7.pt\n",
      "76800\n",
      "76900\n",
      "77000\n",
      "77100\n",
      "77200\n",
      "77300\n",
      "77400\n",
      "77500\n",
      "77600\n",
      "77700\n",
      "77800\n",
      "77900\n",
      "78000\n",
      "78100\n",
      "78200\n",
      "78300\n",
      "78400\n",
      "78500\n",
      "78600\n",
      "78700\n",
      "78800\n",
      "78900\n",
      "79000\n",
      "79100\n",
      "79200\n",
      "79300\n",
      "79400\n",
      "79500\n",
      "79600\n",
      "79700\n",
      "79800\n",
      "79900\n",
      "80000\n",
      "80100\n",
      "80200\n",
      "80300\n",
      "80400\n",
      "80500\n",
      "80600\n",
      "80700\n",
      "80800\n",
      "80900\n",
      "81000\n",
      "81100\n",
      "81200\n",
      "81300\n",
      "81400\n",
      "81500\n",
      "81600\n",
      "81700\n",
      "81800\n",
      "81900\n",
      "82000\n",
      "82100\n",
      "82200\n",
      "82300\n",
      "82400\n",
      "82500\n",
      "82600\n",
      "82700\n",
      "82800\n",
      "82900\n",
      "83000\n",
      "83100\n",
      "83200\n",
      "83300\n",
      "83400\n",
      "83500\n",
      "83600\n",
      "83700\n",
      "83800\n",
      "83900\n",
      "84000\n",
      "84100\n",
      "84200\n",
      "84300\n",
      "84400\n",
      "84500\n",
      "84600\n",
      "84700\n",
      "84800\n",
      "84900\n",
      "85000\n",
      "85100\n",
      "85200\n",
      "85300\n",
      "85400\n",
      "85500\n",
      "85600\n",
      "85700\n",
      "85800\n",
      "85900\n",
      "86000\n",
      "86100\n",
      "86200\n",
      "86300\n",
      "86400\n",
      "86500\n",
      "86600\n",
      "86700\n",
      "86800\n",
      "86900\n",
      "87000\n",
      "87100\n",
      "87200\n",
      "87300\n",
      "87400\n",
      "87500\n",
      "87600\n",
      "87700\n",
      "87800\n",
      "87900\n",
      "88000\n",
      "88100\n",
      "88200\n",
      "88300\n",
      "88400\n",
      "88500\n",
      "88600\n",
      "88700\n",
      "88800\n",
      "88900\n",
      "89000\n",
      "89100\n",
      "89200\n",
      "89300\n",
      "89400\n",
      "89500\n",
      "89600\n",
      "89700\n",
      "89800\n",
      "89900\n",
      "90000\n",
      "90100\n",
      "90200\n",
      "90300\n",
      "90400\n",
      "90500\n",
      "90600\n",
      "90700\n",
      "90800\n",
      "90900\n",
      "91000\n",
      "91100\n",
      "91200\n",
      "91300\n",
      "91400\n",
      "91500\n",
      "91600\n",
      "91700\n",
      "91800\n",
      "91900\n",
      "92000\n",
      "92100\n",
      "92200\n",
      "92300\n",
      "92400\n",
      "92500\n",
      "92600\n",
      "92700\n",
      "92800\n",
      "92900\n",
      "93000\n",
      "93100\n",
      "93200\n",
      "93300\n",
      "93400\n",
      "93500\n",
      "93600\n",
      "93700\n",
      "93800\n",
      "93900\n",
      "94000\n",
      "94100\n",
      "94200\n",
      "94300\n",
      "94400\n",
      "94500\n",
      "94600\n",
      "94700\n",
      "94800\n",
      "94900\n",
      "95000\n",
      "95100\n",
      "95200\n",
      "95300\n",
      "95400\n",
      "95500\n",
      "95600\n",
      "95700\n",
      "95800\n",
      "95900\n",
      "96000\n",
      "96100\n",
      "96200\n",
      "96300\n",
      "96400\n",
      "96500\n",
      "96600\n",
      "96700\n",
      "96800\n",
      "96900\n",
      "97000\n",
      "97100\n",
      "97200\n",
      "97300\n",
      "97400\n",
      "97500\n",
      "97600\n",
      "97700\n",
      "97800\n",
      "97900\n",
      "98000\n",
      "98100\n",
      "98200\n",
      "98300\n",
      "98400\n",
      "98500\n",
      "98600\n",
      "98700\n",
      "98800\n",
      "98900\n",
      "99000\n",
      "99100\n",
      "99200\n",
      "99300\n",
      "99400\n",
      "99500\n",
      "99600\n",
      "99700\n",
      "99800\n",
      "99900\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "for n, i in enumerate(dataset):\n",
    "    if n % 100 == 0: print(n)\n",
    "    m = dataset[n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset.len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12800, 12800, 12800, 12800, 12800, 12800, 12800, 10400]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_index 1\n",
      "start_file:  4\n",
      "end_file:  8\n",
      "Loading data_4.pt\n",
      "12800 12800 4\n",
      "Loading data_5.pt\n",
      "25600 12800 5\n",
      "Loading data_6.pt\n",
      "38400 12800 6\n",
      "Loading data_7.pt\n",
      "48818 10418 7\n",
      "idx_within_chunk 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'env_state': tensor([[[[0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904],\n",
       "            [0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904],\n",
       "            [0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904],\n",
       "            ...,\n",
       "            [0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904],\n",
       "            [0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904],\n",
       "            [0.6904, 0.6904, 0.6904,  ..., 0.6904, 0.6904, 0.6904]],\n",
       "  \n",
       "           [[0.2393, 0.2393, 0.4236,  ..., 0.2393, 0.4236, 0.2393],\n",
       "            [0.2393, 0.2393, 0.4236,  ..., 0.2393, 0.4236, 0.2393],\n",
       "            [0.6040, 0.6040, 0.6040,  ..., 0.6040, 0.6040, 0.6040],\n",
       "            ...,\n",
       "            [0.6040, 0.6040, 0.6040,  ..., 0.6040, 0.6040, 0.6040],\n",
       "            [0.2393, 0.2393, 0.4236,  ..., 0.2393, 0.4236, 0.2393],\n",
       "            [0.2393, 0.2393, 0.4236,  ..., 0.2393, 0.4236, 0.2393]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.2783,  ..., 0.0000, 0.2783, 0.0000],\n",
       "            [0.0000, 0.0000, 0.2783,  ..., 0.0000, 0.2783, 0.0000],\n",
       "            [0.5566, 0.5566, 0.5566,  ..., 0.5566, 0.5566, 0.5566],\n",
       "            ...,\n",
       "            [0.5566, 0.5566, 0.5566,  ..., 0.5566, 0.5566, 0.5566],\n",
       "            [0.0000, 0.0000, 0.2783,  ..., 0.0000, 0.2783, 0.0000],\n",
       "            [0.0000, 0.0000, 0.2783,  ..., 0.0000, 0.2783, 0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  'pri_action': tensor([3]),\n",
       "  'cost': tensor([False]),\n",
       "  'hidden_state': tensor([[[[[-3.0817e-02, -3.5917e-02, -2.7581e-02,  ..., -2.4187e-02,\n",
       "              -6.8777e-02, -5.1954e-02],\n",
       "             [-1.0930e-02,  2.6403e-03,  1.5583e-02,  ...,  1.3928e-03,\n",
       "              -2.5230e-02, -1.2132e-01],\n",
       "             [-1.0430e-01,  2.2105e-04, -6.6318e-02,  ..., -2.0928e-05,\n",
       "              -1.2884e-02, -6.1839e-02],\n",
       "             ...,\n",
       "             [-1.1250e-02, -1.7038e-02, -1.0205e-02,  ..., -1.4778e-02,\n",
       "              -2.7817e-03, -6.6555e-02],\n",
       "             [-1.0007e-02, -1.3051e-02, -1.0583e-02,  ..., -3.9812e-02,\n",
       "              -5.9640e-03, -3.2691e-02],\n",
       "             [-8.8298e-03, -1.1884e-02, -8.9565e-03,  ..., -3.8617e-02,\n",
       "              -1.3731e-02, -5.5117e-02]],\n",
       "  \n",
       "            [[-1.9425e-01, -1.7914e-01, -2.8871e-01,  ..., -1.7643e-01,\n",
       "              -1.9026e-01, -1.7124e-01],\n",
       "             [-2.7439e-01, -3.1207e-01, -2.1786e-01,  ..., -4.6129e-01,\n",
       "              -2.3923e-01, -2.0983e-01],\n",
       "             [-1.5494e-01, -2.9658e-01, -1.8230e-01,  ..., -2.0226e-01,\n",
       "              -1.3201e-01, -2.1769e-01],\n",
       "             ...,\n",
       "             [-2.0540e-01, -1.9014e-01, -2.1162e-01,  ..., -5.1270e-01,\n",
       "              -4.8483e-01, -2.0592e-01],\n",
       "             [-2.1822e-01, -1.9111e-01, -1.7883e-01,  ..., -2.0873e-01,\n",
       "              -3.7725e-01, -1.3958e-01],\n",
       "             [-2.8237e-01, -4.2467e-01, -4.4625e-01,  ..., -3.9247e-01,\n",
       "              -4.8971e-01, -2.6587e-01]],\n",
       "  \n",
       "            [[-5.1727e-02, -6.8404e-02, -5.7976e-02,  ..., -5.0227e-02,\n",
       "              -6.5826e-02, -1.1564e-01],\n",
       "             [ 1.0091e-01,  9.7185e-02,  3.9595e-02,  ...,  3.2060e-03,\n",
       "               1.7433e-02, -2.3844e-02],\n",
       "             [-5.5970e-02, -3.9411e-03, -1.7272e-02,  ...,  1.7803e-03,\n",
       "               7.1191e-03,  1.2515e-02],\n",
       "             ...,\n",
       "             [ 1.5783e-02,  1.8220e-02,  1.4931e-02,  ..., -5.9954e-02,\n",
       "               3.0254e-03,  4.6086e-02],\n",
       "             [ 1.0745e-02,  8.7890e-03,  6.5582e-03,  ..., -6.0858e-02,\n",
       "               6.2544e-03,  2.3636e-02],\n",
       "             [ 1.6282e-02,  1.3683e-02,  1.1688e-02,  ..., -6.8353e-03,\n",
       "               2.8547e-02,  5.7825e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.5110e-01, -7.8300e-02, -7.2268e-02,  ..., -6.5743e-02,\n",
       "              -9.8409e-02, -1.6813e-01],\n",
       "             [-7.8370e-02, -2.6667e-02, -4.6119e-02,  ..., -1.5718e-02,\n",
       "              -1.6464e-02, -9.6575e-02],\n",
       "             [-8.5293e-02, -3.2838e-02, -6.1431e-02,  ..., -1.1847e-02,\n",
       "              -1.5389e-02, -9.8444e-02],\n",
       "             ...,\n",
       "             [-4.5259e-02, -1.7239e-02, -1.7853e-02,  ..., -4.3722e-02,\n",
       "              -1.8586e-02, -7.3560e-02],\n",
       "             [-3.9275e-02, -1.3446e-02, -1.4595e-02,  ..., -2.5711e-02,\n",
       "              -1.9653e-02, -8.2339e-02],\n",
       "             [-8.0213e-02, -3.3905e-02, -3.4853e-02,  ..., -4.4085e-02,\n",
       "              -3.6343e-02, -7.2778e-02]],\n",
       "  \n",
       "            [[-2.2999e-01, -4.6182e-01, -3.7823e-01,  ..., -3.6707e-01,\n",
       "              -3.6531e-01, -3.3453e-01],\n",
       "             [-2.9531e-01, -8.6966e-01, -7.3486e-01,  ..., -8.1983e-01,\n",
       "              -5.4562e-01, -6.5105e-01],\n",
       "             [-5.4259e-01, -8.6788e-01, -5.9535e-01,  ..., -4.4407e-01,\n",
       "              -2.0680e-01, -6.2354e-01],\n",
       "             ...,\n",
       "             [-3.5574e-01, -6.7178e-01, -6.9919e-01,  ..., -7.3372e-01,\n",
       "              -4.9054e-01, -2.5020e-01],\n",
       "             [-4.4036e-01, -7.7161e-01, -7.9830e-01,  ..., -8.0259e-01,\n",
       "              -5.6151e-01, -3.2129e-01],\n",
       "             [-3.9968e-01, -7.8556e-01, -8.2087e-01,  ..., -7.3631e-01,\n",
       "              -6.5736e-01, -3.3142e-01]],\n",
       "  \n",
       "            [[ 7.9274e-02, -7.4804e-03, -9.5363e-03,  ..., -3.2601e-02,\n",
       "              -4.8626e-02, -1.3928e-02],\n",
       "             [ 6.2386e-02, -6.7020e-02, -5.0702e-03,  ..., -1.1997e-01,\n",
       "              -1.6191e-01, -1.4539e-01],\n",
       "             [-1.5303e-02, -2.3874e-01, -2.5114e-01,  ..., -8.8375e-02,\n",
       "              -1.1938e-01, -1.5884e-01],\n",
       "             ...,\n",
       "             [-1.8777e-02, -6.3944e-02, -6.1191e-02,  ..., -5.3447e-02,\n",
       "              -1.8450e-01, -2.5467e-01],\n",
       "             [-1.4371e-02, -8.4896e-02, -1.0038e-01,  ..., -9.5582e-02,\n",
       "              -1.8486e-01, -2.7341e-01],\n",
       "             [-6.7774e-02, -1.2595e-01, -1.4078e-01,  ..., -1.7150e-01,\n",
       "              -2.3892e-01, -2.3955e-01]]],\n",
       "  \n",
       "  \n",
       "           [[[-3.2985e-02, -3.6998e-02, -3.0512e-02,  ..., -2.6066e-02,\n",
       "              -7.2362e-02, -5.3785e-02],\n",
       "             [-1.1938e-02,  2.7982e-03,  1.6057e-02,  ...,  2.0744e-03,\n",
       "              -2.8705e-02, -1.1555e-01],\n",
       "             [-1.0706e-01,  3.3958e-04, -6.8151e-02,  ..., -3.4114e-04,\n",
       "              -1.3694e-02, -6.3207e-02],\n",
       "             ...,\n",
       "             [-1.1621e-02, -1.7182e-02, -1.0374e-02,  ..., -1.5685e-02,\n",
       "              -3.3009e-03, -6.9086e-02],\n",
       "             [-1.0150e-02, -1.2887e-02, -1.0538e-02,  ..., -3.9738e-02,\n",
       "              -6.0996e-03, -3.2228e-02],\n",
       "             [-8.7919e-03, -1.1474e-02, -8.4961e-03,  ..., -3.7934e-02,\n",
       "              -1.3595e-02, -5.3209e-02]],\n",
       "  \n",
       "            [[-1.8901e-01, -1.7023e-01, -2.7626e-01,  ..., -1.6776e-01,\n",
       "              -1.8030e-01, -1.6458e-01],\n",
       "             [-2.6594e-01, -2.8890e-01, -2.0030e-01,  ..., -4.3557e-01,\n",
       "              -2.2229e-01, -1.9011e-01],\n",
       "             [-1.4917e-01, -2.7748e-01, -1.6785e-01,  ..., -2.2684e-01,\n",
       "              -1.2197e-01, -2.0267e-01],\n",
       "             ...,\n",
       "             [-1.9639e-01, -1.7459e-01, -1.9457e-01,  ..., -5.0698e-01,\n",
       "              -4.6093e-01, -1.9307e-01],\n",
       "             [-2.0835e-01, -1.7485e-01, -1.6195e-01,  ..., -1.9130e-01,\n",
       "              -3.5529e-01, -1.3100e-01],\n",
       "             [-2.7809e-01, -4.1205e-01, -4.3272e-01,  ..., -3.8012e-01,\n",
       "              -4.7683e-01, -2.5751e-01]],\n",
       "  \n",
       "            [[-5.2925e-02, -7.0843e-02, -5.9557e-02,  ..., -5.2296e-02,\n",
       "              -6.7684e-02, -1.1468e-01],\n",
       "             [ 1.0920e-01,  1.0824e-01,  4.5285e-02,  ...,  3.9047e-03,\n",
       "               1.9690e-02, -2.2306e-02],\n",
       "             [-6.0040e-02, -4.4443e-03, -1.9288e-02,  ...,  2.6567e-03,\n",
       "               1.0152e-02,  1.3398e-02],\n",
       "             ...,\n",
       "             [ 1.7531e-02,  2.0956e-02,  1.7234e-02,  ..., -5.8541e-02,\n",
       "               3.8934e-03,  5.5544e-02],\n",
       "             [ 1.2055e-02,  1.0317e-02,  7.7139e-03,  ..., -6.4539e-02,\n",
       "               7.3424e-03,  2.8813e-02],\n",
       "             [ 1.7717e-02,  1.5510e-02,  1.3300e-02,  ..., -7.4396e-03,\n",
       "               3.2128e-02,  6.4736e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.5195e-01, -7.8815e-02, -7.3627e-02,  ..., -6.7165e-02,\n",
       "              -1.0030e-01, -1.7496e-01],\n",
       "             [-7.9019e-02, -2.6778e-02, -4.6271e-02,  ..., -1.4951e-02,\n",
       "              -1.6257e-02, -9.9134e-02],\n",
       "             [-8.6145e-02, -3.2612e-02, -6.1833e-02,  ..., -1.1372e-02,\n",
       "              -1.3750e-02, -1.0509e-01],\n",
       "             ...,\n",
       "             [-4.5103e-02, -1.7006e-02, -1.7749e-02,  ..., -4.2865e-02,\n",
       "              -1.8965e-02, -7.5436e-02],\n",
       "             [-3.9118e-02, -1.3223e-02, -1.4197e-02,  ..., -2.5169e-02,\n",
       "              -1.9622e-02, -8.3932e-02],\n",
       "             [-8.0495e-02, -3.3779e-02, -3.4616e-02,  ..., -4.3558e-02,\n",
       "              -3.6159e-02, -7.5883e-02]],\n",
       "  \n",
       "            [[-2.4131e-01, -4.7511e-01, -3.8913e-01,  ..., -3.7987e-01,\n",
       "              -3.7586e-01, -3.3786e-01],\n",
       "             [-3.2732e-01, -8.8908e-01, -7.4183e-01,  ..., -8.0616e-01,\n",
       "              -5.4067e-01, -6.4763e-01],\n",
       "             [-5.6247e-01, -8.6491e-01, -5.8224e-01,  ..., -4.6277e-01,\n",
       "              -2.2280e-01, -6.4187e-01],\n",
       "             ...,\n",
       "             [-3.8283e-01, -6.8173e-01, -7.0972e-01,  ..., -7.2815e-01,\n",
       "              -5.1528e-01, -2.6089e-01],\n",
       "             [-4.6715e-01, -7.7443e-01, -7.9921e-01,  ..., -7.9761e-01,\n",
       "              -5.6333e-01, -3.2136e-01],\n",
       "             [-4.2486e-01, -7.8653e-01, -8.1930e-01,  ..., -7.3061e-01,\n",
       "              -6.4601e-01, -3.3401e-01]],\n",
       "  \n",
       "            [[ 8.8740e-02, -1.0291e-03, -2.3554e-03,  ..., -2.7996e-02,\n",
       "              -4.4519e-02, -1.3094e-02],\n",
       "             [ 6.8878e-02, -6.1354e-02, -3.5463e-03,  ..., -1.1105e-01,\n",
       "              -1.5882e-01, -1.4232e-01],\n",
       "             [-1.0865e-02, -2.3529e-01, -2.5007e-01,  ..., -1.2993e-01,\n",
       "              -1.4208e-01, -1.7493e-01],\n",
       "             ...,\n",
       "             [-1.0390e-02, -5.8276e-02, -5.7535e-02,  ..., -5.9598e-02,\n",
       "              -1.7758e-01, -2.5752e-01],\n",
       "             [-8.4041e-03, -8.1562e-02, -9.8567e-02,  ..., -9.5527e-02,\n",
       "              -1.8390e-01, -2.7867e-01],\n",
       "             [-6.5836e-02, -1.2519e-01, -1.4189e-01,  ..., -1.7336e-01,\n",
       "              -2.4265e-01, -2.4623e-01]]],\n",
       "  \n",
       "  \n",
       "           [[[-2.7867e-02, -2.9979e-02, -2.0400e-02,  ..., -2.2063e-02,\n",
       "              -6.4335e-02, -4.8620e-02],\n",
       "             [-9.8087e-03,  4.0896e-03,  1.8209e-02,  ...,  2.5285e-03,\n",
       "              -2.5846e-02, -1.1024e-01],\n",
       "             [-1.0164e-01,  3.6599e-04, -6.2974e-02,  ...,  3.2366e-04,\n",
       "              -1.5349e-02, -6.5908e-02],\n",
       "             ...,\n",
       "             [-1.0573e-02, -1.5512e-02, -9.1519e-03,  ..., -1.3387e-02,\n",
       "              -2.7248e-03, -6.1598e-02],\n",
       "             [-9.3817e-03, -1.1794e-02, -9.3835e-03,  ..., -3.6936e-02,\n",
       "              -5.4166e-03, -2.7989e-02],\n",
       "             [-8.1390e-03, -1.0551e-02, -7.6090e-03,  ..., -3.4947e-02,\n",
       "              -1.2053e-02, -4.9721e-02]],\n",
       "  \n",
       "            [[-1.9201e-01, -1.7360e-01, -2.7949e-01,  ..., -1.6862e-01,\n",
       "              -1.8075e-01, -1.6501e-01],\n",
       "             [-2.7210e-01, -3.0019e-01, -2.0837e-01,  ..., -4.4852e-01,\n",
       "              -2.2958e-01, -1.9257e-01],\n",
       "             [-1.5788e-01, -2.8554e-01, -1.7524e-01,  ..., -2.8018e-01,\n",
       "              -1.3930e-01, -2.1119e-01],\n",
       "             ...,\n",
       "             [-2.0456e-01, -1.8506e-01, -2.0881e-01,  ..., -5.2819e-01,\n",
       "              -4.7413e-01, -1.9689e-01],\n",
       "             [-2.1712e-01, -1.8481e-01, -1.7298e-01,  ..., -2.0400e-01,\n",
       "              -3.7366e-01, -1.3675e-01],\n",
       "             [-2.8300e-01, -4.2153e-01, -4.4299e-01,  ..., -3.9095e-01,\n",
       "              -4.8896e-01, -2.6507e-01]],\n",
       "  \n",
       "            [[-5.4610e-02, -7.3895e-02, -6.3102e-02,  ..., -5.5030e-02,\n",
       "              -7.0842e-02, -1.1877e-01],\n",
       "             [ 1.0969e-01,  1.1094e-01,  4.7474e-02,  ...,  3.9733e-03,\n",
       "               1.9915e-02, -2.3346e-02],\n",
       "             [-6.1433e-02, -4.7204e-03, -1.9282e-02,  ...,  2.9098e-03,\n",
       "               1.0371e-02,  1.1268e-02],\n",
       "             ...,\n",
       "             [ 1.7316e-02,  2.1578e-02,  1.7833e-02,  ..., -5.8918e-02,\n",
       "               4.1228e-03,  6.0728e-02],\n",
       "             [ 1.1801e-02,  1.0376e-02,  7.7506e-03,  ..., -6.5098e-02,\n",
       "               7.4155e-03,  3.0024e-02],\n",
       "             [ 1.7049e-02,  1.4951e-02,  1.2766e-02,  ..., -7.2116e-03,\n",
       "               3.0913e-02,  6.5201e-02]],\n",
       "  \n",
       "            ...,\n",
       "  \n",
       "            [[-1.5029e-01, -7.8015e-02, -7.2932e-02,  ..., -6.5602e-02,\n",
       "              -9.9381e-02, -1.7359e-01],\n",
       "             [-7.7953e-02, -2.6304e-02, -4.5041e-02,  ..., -1.4371e-02,\n",
       "              -1.6221e-02, -9.9589e-02],\n",
       "             [-8.5390e-02, -3.2827e-02, -6.0434e-02,  ..., -1.1459e-02,\n",
       "              -1.4545e-02, -1.0609e-01],\n",
       "             ...,\n",
       "             [-4.4745e-02, -1.6855e-02, -1.7325e-02,  ..., -4.1111e-02,\n",
       "              -1.8418e-02, -7.4518e-02],\n",
       "             [-3.8831e-02, -1.3173e-02, -1.4100e-02,  ..., -2.4489e-02,\n",
       "              -1.9410e-02, -8.3122e-02],\n",
       "             [-8.0347e-02, -3.3878e-02, -3.4631e-02,  ..., -4.3364e-02,\n",
       "              -3.5998e-02, -7.2401e-02]],\n",
       "  \n",
       "            [[-2.2404e-01, -4.5304e-01, -3.6838e-01,  ..., -3.6037e-01,\n",
       "              -3.5771e-01, -3.2440e-01],\n",
       "             [-2.8454e-01, -8.4113e-01, -6.9840e-01,  ..., -7.6347e-01,\n",
       "              -5.0733e-01, -6.2125e-01],\n",
       "             [-5.2602e-01, -8.3179e-01, -5.5081e-01,  ..., -4.3160e-01,\n",
       "              -2.1011e-01, -6.3144e-01],\n",
       "             ...,\n",
       "             [-3.4118e-01, -6.4183e-01, -6.6987e-01,  ..., -7.1531e-01,\n",
       "              -5.0844e-01, -2.5679e-01],\n",
       "             [-4.2405e-01, -7.3742e-01, -7.6169e-01,  ..., -7.6958e-01,\n",
       "              -5.4036e-01, -3.1090e-01],\n",
       "             [-3.9111e-01, -7.5914e-01, -7.9127e-01,  ..., -7.0935e-01,\n",
       "              -6.3396e-01, -3.2220e-01]],\n",
       "  \n",
       "            [[ 7.5556e-02, -7.3277e-03, -7.9757e-03,  ..., -3.2538e-02,\n",
       "              -4.9399e-02, -1.2457e-02],\n",
       "             [ 6.2970e-02, -5.7823e-02,  2.0450e-03,  ..., -1.0456e-01,\n",
       "              -1.5033e-01, -1.3167e-01],\n",
       "             [-1.8233e-02, -2.3111e-01, -2.3626e-01,  ..., -1.1685e-01,\n",
       "              -1.3562e-01, -1.7385e-01],\n",
       "             ...,\n",
       "             [-1.7900e-02, -5.3316e-02, -5.0358e-02,  ..., -5.5887e-02,\n",
       "              -1.7510e-01, -2.4336e-01],\n",
       "             [-1.5601e-02, -7.7947e-02, -9.3914e-02,  ..., -8.8130e-02,\n",
       "              -1.7820e-01, -2.6662e-01],\n",
       "             [-6.5736e-02, -1.1735e-01, -1.3313e-01,  ..., -1.6249e-01,\n",
       "              -2.2976e-01, -2.3150e-01]]]]])},\n",
       " tensor(False))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[12800*4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /mnt/c/Users/chung/Personal/RS/thinker/data/detect/v5_sok-23691168-0/test/ckp_detect.tar\n"
     ]
    }
   ],
   "source": [
    "flags = argparse.Namespace()\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "flags.dxpid = \"v5_sok-23691168-0\"\n",
    "flags.dproject = \"detect\"\n",
    "flags.datadir = \"../data/__dproject__/__dxpid__/\"\n",
    "flags.txpid = \"test\"\n",
    "flags.project = \"detect_post\"\n",
    "flags.batch_size = 128\n",
    "flags.learning_rate = 0.0001\n",
    "flags.num_epochs = 50\n",
    "flags.early_stop_n = -1\n",
    "flags.data_n = 50000\n",
    "flags.ckp = False\n",
    "flags.use_wandb = False\n",
    "flags.tran_layer_n = 3\n",
    "flags.tran_ff_n = 512\n",
    "flags.shallow_encode = False\n",
    "\n",
    "flags.datadir = flags.datadir.replace(\"__dproject__\", flags.dproject)\n",
    "flags.datadir = flags.datadir.replace(\"__dxpid__\", flags.dxpid)\n",
    "# ========================================================\n",
    "if not flags.ckp:\n",
    "    flags.datadir = os.path.abspath(os.path.expanduser(flags.datadir))\n",
    "    # create ckp dir\n",
    "    xpid_n = 0\n",
    "    while (True):\n",
    "        xpid_ = flags.txpid if xpid_n == 0 else flags.txpid + f\"_{xpid_n}\"\n",
    "        ckpdir = os.path.join(flags.datadir, xpid_)\n",
    "        xpid_n += 1\n",
    "        if not os.path.exists(ckpdir):\n",
    "            os.mkdir(ckpdir) \n",
    "            flags.txpid = xpid_\n",
    "            break    \n",
    "else:\n",
    "    ckpdir = os.path.join(flags.datadir, flags.txpid)\n",
    "flags.tckpdir = ckpdir\n",
    "flags.tckp_path = os.path.join(ckpdir, \"ckp_detect.tar\")\n",
    "flags.tckp_path_b = os.path.join(ckpdir, \"ckp_detect_best.tar\")\n",
    "print(f\"Checkpoint path: {flags.tckp_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to preload data_0.pt\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(datadir=flags.datadir, transform=None, data_n=10000)\n",
    "dataloader = DataLoader(dataset, batch_size=flags.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 80, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[\"env_state\"][1,0].float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(20):\n",
    "    util.plot_raw_state((xs[\"env_state\"][100,s].float()*255).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "dataset = CustomDataset(datadir=flags.datadir, transform=None, data_n=flags.data_n)\n",
    "dataloader = DataLoader(dataset, batch_size=flags.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(datadir=flags.datadir, transform=None, data_n=5000, prefix=\"val\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=flags.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load setting\n",
    "yaml_file_path = os.path.join(flags.datadir, 'config_detect.yaml')\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    flags_data = yaml.safe_load(file)\n",
    "flags_data = argparse.Namespace(**flags_data)\n",
    "flags = argparse.Namespace(**{**vars(flags), **vars(flags_data)}) # merge the two flags\n",
    "\n",
    "plogger = FileWriter(\n",
    "    xpid=flags.txpid,\n",
    "    xp_args=flags.__dict__,\n",
    "    rootdir=flags.datadir,\n",
    "    overwrite=not flags.ckp,\n",
    ")\n",
    "flags.full_xpid = flags.dxpid + \"_\" + flags.txpid\n",
    "\n",
    "if flags.use_wandb: wlogger = util.Wandb(flags)\n",
    "\n",
    "# initalize net\n",
    "device = torch.device(\"cuda\")\n",
    "detect_net = DetectNet(\n",
    "    env_state_shape = flags_data.env_state_shape,\n",
    "    tree_rep_shape = getattr(flags_data, \"tree_rep_shape\", None),\n",
    "    hidden_state_shape = getattr(flags_data, \"hidden_state_shape\", None),\n",
    "    dim_actions = flags_data.dim_actions,\n",
    "    num_actions = flags_data.num_actions,\n",
    "    disable_thinker = flags.disable_thinker,\n",
    "    tran_layer_n = flags.tran_layer_n,\n",
    "    tran_ff_n = flags.tran_ff_n,\n",
    "    shallow_encode= flags.shallow_encode,\n",
    ")\n",
    "\n",
    "# load optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    detect_net.parameters(), lr=flags.learning_rate, \n",
    ")\n",
    "\n",
    "if flags.ckp:\n",
    "    checkpoint = torch.load(flags.tckp_path, torch.device(\"cpu\"))\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    detect_net.load_state_dict(checkpoint[\"net_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    del checkpoint\n",
    "else:\n",
    "    epoch = 0\n",
    "\n",
    "detect_net = detect_net.to(device)\n",
    "util.optimizer_to(optimizer, device)\n",
    "\n",
    "print(\"Detect network size: %d\"\n",
    "        % sum(p.numel() for p in detect_net.parameters())\n",
    "    )\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epoch_since_improve = 0\n",
    "\n",
    "while (epoch < flags.num_epochs):\n",
    "    train_stat = train_epoch(detect_net, dataloader, optimizer, device, flags, train=True)\n",
    "    val_stat = train_epoch(detect_net, val_dataloader, None, device, flags, train=False)\n",
    "    stat = {**train_stat, **{'val/' + key: value for key, value in val_stat.items()}}\n",
    "    stat[\"epoch\"] = epoch\n",
    "    plogger.log(stat)\n",
    "    if flags.use_wandb: wlogger.wandb.log(stat, step=stat['epoch'])\n",
    "    \n",
    "    epoch += 1    \n",
    "    print_str = f'Epoch {epoch}/{flags.num_epochs},'\n",
    "    for key in stat.keys(): \n",
    "        if 'val/' + key in stat.keys():\n",
    "            print_str += f\" {key}:{stat[key]:.4f} ({stat['val/'+key]:.4f})\"\n",
    "    print(print_str)   \n",
    "            \n",
    "    # Early stopping and best model saving logic\n",
    "    if flags.early_stop_n >= 0:  # Check if early stopping is enabled\n",
    "        current_val_loss = val_stat['loss']  # Assuming val_stat contains the validation loss\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            epoch_since_improve = 0\n",
    "            save_ckp(flags.tckp_path_b, epoch, flags, optimizer, detect_net)\n",
    "            print(f\"New best model saved to {flags.tckp_path_b}\")\n",
    "        else:\n",
    "            epoch_since_improve += 1\n",
    "        \n",
    "        if epoch_since_improve > flags.early_stop_n:\n",
    "            print(f\"Stopping early at epoch {epoch} due to no improvement in validation loss for {flags.early_stop_n} consecutive epochs.\")\n",
    "            break  # Stop the training loop\n",
    "\n",
    "    if epoch % 5 == 0 or epoch >= flags.num_epochs:\n",
    "        save_ckp(flags.tckp_path, epoch, flags, optimizer, detect_net)\n",
    "        print(f\"Checkpoint saved to {flags.tckp_path}\")\n",
    "\n",
    "    if flags.use_wandb and (epoch % 10 == 0 or epoch >= flags.num_epochs):\n",
    "        wlogger.wandb.save(\n",
    "            os.path.join(flags.tckpdir, \"*\"), flags.tckpdir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2288818359375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deprecated\n",
    "\n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from thinker import util\n",
    "\n",
    "datadir = \"../data/detect/v5_sok-5993808-1/\"\n",
    "datadir = os.path.abspath(os.path.expanduser(datadir))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datadir, transform=None):\n",
    "        self.datadir = datadir\n",
    "        self.file_list = [f for f in os.listdir(datadir) if f.endswith('.pt')]\n",
    "        self.transform = transform\n",
    "        xs, y = torch.load(os.path.join(datadir, self.file_list[0]))        \n",
    "        self.t = xs['env_state'].shape[0]\n",
    "        self.b = xs['env_state'].shape[2]\n",
    "        self.samples_per_file = self.t * self.b\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) * self.samples_per_file  # Adjust based on your data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx = idx // self.samples_per_file\n",
    "        within_file_idx = idx % self.samples_per_file\n",
    "        t_idx = within_file_idx // self.b\n",
    "        b_idx = within_file_idx % self.b\n",
    "        xs, y = torch.load(os.path.join(self.datadir, self.file_list[file_idx]))\n",
    "        xs.pop('step_status')\n",
    "        xs.pop('done')\n",
    "        xs = util.dict_map(xs, lambda x: x[t_idx, :, b_idx])\n",
    "        y = y[t_idx, b_idx]\n",
    "        return xs, y\n",
    "\n",
    "# To load data and train\n",
    "dataset = CustomDataset(datadir)\n",
    "# print(dataset[100])\n",
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing env 0 with device cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlinked log directory: /mnt/c/Users/chung/Personal/RS/thinker/notebook/logs/latest\n",
      "Wrote config file to /mnt/c/Users/chung/Personal/RS/thinker/notebook/logs/detect-20240204-023020/config_c.yaml\n"
     ]
    }
   ],
   "source": [
    "from thinker.actor_net import DRCNet\n",
    "from thinker.main import Env\n",
    "from thinker.self_play import init_env_out, create_env_out\n",
    "from thinker import util\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "env_n = 16\n",
    "flags = util.create_setting(args=[], drc=True, save_flags=False, wrapper_type=1)\n",
    "env = Env(\n",
    "        name=\"Sokoban-v0\",\n",
    "        env_n=env_n,\n",
    "        gpu=True,\n",
    "        train_model=False,\n",
    "        parallel=False,\n",
    "        return_x=True,\n",
    "        return_h=True,\n",
    "        flags=flags,\n",
    "        wrapper_type=1,\n",
    "    )\n",
    "\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space \n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "actor_net = DRCNet(obs_space=obs_space, action_space=action_space, flags=flags, tree_rep_meaning=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"../logs/detect/v1a_drc/ckp_actor.tar\")\n",
    "actor_net.load_state_dict(checkpoint[\"actor_net_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ = torch.load(\"../logs/detect/v5b_sok_drc/ckp_actor.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = actor_net.to(device)\n",
    "state = env.reset()\n",
    "env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "rets = []\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    while(True):\n",
    "        actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\n",
    "        primary_action, reset_action = actor_out.action, None\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action)    \n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())            \n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "        env_out = create_env_out(primary_action, state, reward, done, info, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ['step', 'real_step', 'actor_net_optimizer_state_dict', 'actor_net_scheduler_state_dict', 'actor_net_state_dict']\n",
    "for c in cs: checkpoint_[c] = checkpoint[c]\n",
    "torch.save(checkpoint_, \"../logs/detect/v5b_sok_drc/ckp_actor.tar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1; Return  13.789999961853027\n",
      "Episode 2; Return  13.78000020980835\n",
      "Episode 3; Return  13.773333549499512\n",
      "Episode 4; Return  13.760000228881836\n",
      "Episode 5; Return  13.744000244140626\n",
      "Episode 6; Return  13.730000178019205\n",
      "Episode 8; Return  13.710000038146973\n",
      "Episode 9; Return  13.700000021192762\n",
      "Episode 11; Return  13.683636491948908\n",
      "Episode 12; Return  13.674166758855185\n",
      "Episode 13; Return  13.680000085097094\n",
      "Episode 15; Return  13.670000076293945\n",
      "Episode 16; Return  13.658750057220459\n",
      "Episode 17; Return  13.662353010738597\n",
      "Episode 18; Return  13.651666747199165\n",
      "Episode 19; Return  13.654210592571058\n",
      "Episode 20; Return  13.655500078201294\n",
      "Episode 21; Return  13.652857235499791\n",
      "Episode 23; Return  13.656087046084197\n",
      "Episode 24; Return  13.651250084241232\n",
      "Episode 25; Return  13.649200096130372\n",
      "Episode 26; Return  13.650769343742958\n",
      "Episode 27; Return  13.653703795539009\n",
      "Episode 28; Return  13.652857235499791\n",
      "Episode 30; Return  13.649000072479248\n",
      "Episode 32; Return  13.656562596559525\n",
      "Episode 33; Return  13.659090995788574\n",
      "Episode 34; Return  13.651764785542207\n",
      "Episode 35; Return  13.286000108718872\n",
      "Episode 36; Return  13.28666678402159\n",
      "Episode 37; Return  13.294594706715765\n",
      "Episode 38; Return  13.30078960092444\n",
      "Episode 39; Return  13.313333456332867\n",
      "Episode 40; Return  13.319000118970871\n",
      "Episode 42; Return  13.33547630196526\n",
      "Episode 43; Return  13.344651261041331\n",
      "Episode 44; Return  13.349772816354578\n",
      "Episode 45; Return  13.35822229915195\n",
      "Episode 46; Return  13.34826095726179\n",
      "Episode 47; Return  13.350000092323791\n",
      "Episode 48; Return  13.352708434065184\n",
      "Episode 49; Return  13.358367447950402\n",
      "Episode 51; Return  13.099411870626842\n",
      "Episode 52; Return  13.110961638677578\n",
      "Episode 53; Return  13.120566133901757\n",
      "Episode 55; Return  13.142181916399435\n",
      "Episode 56; Return  12.921964398186121\n",
      "Episode 57; Return  12.9357895848521\n",
      "Episode 58; Return  12.951034586748172\n",
      "Episode 59; Return  12.964745868818234\n",
      "Episode 60; Return  12.97716677164038\n",
      "Episode 61; Return  12.985573869992475\n",
      "Episode 63; Return  13.005238207323211\n",
      "Episode 65; Return  13.022923197883825\n",
      "Episode 66; Return  13.03060619013779\n",
      "Episode 68; Return  13.04661778119557\n",
      "Episode 69; Return  12.854927674583767\n",
      "Episode 70; Return  12.867428701264517\n",
      "Episode 71; Return  12.87859167515392\n",
      "Episode 72; Return  12.888472348451614\n",
      "Episode 74; Return  12.909864995930645\n",
      "Episode 75; Return  12.919200137456258\n",
      "Episode 76; Return  12.929210665978884\n",
      "Episode 77; Return  12.940389747743483\n",
      "Episode 78; Return  12.94833347430596\n",
      "Episode 79; Return  12.95734190940857\n",
      "Episode 80; Return  12.965125134587288\n",
      "Episode 81; Return  12.96679026109201\n",
      "Episode 82; Return  12.974634289741516\n",
      "Episode 83; Return  12.978674845523145\n",
      "Episode 84; Return  12.986904907794226\n",
      "Episode 85; Return  12.992941320643705\n",
      "Episode 86; Return  12.99790712012801\n",
      "Episode 88; Return  12.863750154321844\n",
      "Episode 90; Return  12.882555707295735\n",
      "Episode 91; Return  12.888901249393003\n",
      "Episode 92; Return  12.89728275589321\n",
      "Episode 93; Return  12.904301222934517\n",
      "Episode 94; Return  12.913829935357926\n",
      "Episode 95; Return  12.923789616634972\n",
      "Episode 96; Return  12.92927098274231\n",
      "Episode 97; Return  12.936288813954777\n",
      "Episode 98; Return  12.822959347647064\n",
      "Episode 99; Return  12.830808246978606\n",
      "Episode 101; Return  12.847524919132194\n",
      "Episode 102; Return  12.854902129547268\n",
      "Episode 103; Return  12.738252603891985\n",
      "Episode 104; Return  12.746538640214848\n",
      "Episode 106; Return  12.763019041070399\n",
      "Episode 109; Return  12.787156132383084\n",
      "Episode 111; Return  12.801261430388099\n",
      "Episode 112; Return  12.809375167957374\n",
      "Episode 113; Return  12.816283353662069\n",
      "Episode 114; Return  12.82526332558247\n",
      "Episode 115; Return  12.83173929401066\n",
      "Episode 116; Return  12.83663809813302\n",
      "Episode 117; Return  12.844786490130629\n",
      "Episode 118; Return  12.85025439929154\n",
      "Episode 119; Return  12.85739511702241\n",
      "Episode 121; Return  12.868429917934513\n",
      "Episode 123; Return  12.786585537398734\n",
      "Episode 125; Return  12.799680176734924\n",
      "Episode 126; Return  12.805635097480955\n",
      "Episode 127; Return  12.812519862895876\n",
      "Episode 128; Return  12.819609553553164\n",
      "Episode 131; Return  12.739542171245313\n",
      "Episode 132; Return  12.747803214824561\n",
      "Episode 133; Return  12.754812215503893\n",
      "Episode 134; Return  12.673433028050322\n",
      "Episode 135; Return  12.68170389422664\n",
      "Episode 136; Return  12.687279604813632\n",
      "Episode 137; Return  12.694452746941225\n",
      "Episode 139; Return  12.70913688227427\n",
      "Episode 140; Return  12.715285902363913\n",
      "Episode 141; Return  12.722766147437671\n",
      "Episode 143; Return  12.651958240495695\n",
      "Episode 144; Return  12.65944463842445\n",
      "Episode 145; Return  12.58455192467262\n",
      "Episode 147; Return  12.597415160159676\n",
      "Episode 148; Return  12.605067757335869\n",
      "Episode 149; Return  12.612349185367558\n",
      "Episode 150; Return  12.617533526420594\n",
      "Episode 151; Return  12.62576177893885\n",
      "Episode 152; Return  12.632500185778266\n",
      "Episode 153; Return  12.639804106132656\n",
      "Episode 154; Return  12.646363817252121\n",
      "Episode 155; Return  12.653225986419185\n",
      "Episode 156; Return  12.659743769046587\n",
      "Episode 157; Return  12.665923745768845\n",
      "Episode 158; Return  12.672658402708512\n",
      "Episode 159; Return  12.680000174720332\n",
      "Episode 160; Return  12.6868751719594\n",
      "Episode 161; Return  12.69248464388877\n",
      "Episode 162; Return  12.69839523015199\n",
      "Episode 164; Return  12.638719686647741\n",
      "Episode 166; Return  12.646385721413486\n",
      "Episode 167; Return  12.65251514868822\n",
      "Episode 168; Return  12.587916851043701\n",
      "Episode 170; Return  12.60117665459128\n",
      "Episode 171; Return  12.60649141233567\n",
      "Episode 172; Return  12.613023436346719\n",
      "Episode 173; Return  12.616531972940258\n",
      "Episode 174; Return  12.623218569262274\n",
      "Episode 175; Return  12.62977160862514\n",
      "Episode 176; Return  12.636136542667042\n",
      "Episode 177; Return  12.575141427207129\n",
      "Episode 178; Return  12.580730518598235\n",
      "Episode 180; Return  12.593500179714626\n",
      "Episode 181; Return  12.52834272582228\n",
      "Episode 182; Return  12.534176008386927\n",
      "Episode 184; Return  12.546956704362579\n",
      "Episode 185; Return  12.553459641095754\n",
      "Episode 186; Return  12.558709861770753\n",
      "Episode 187; Return  12.565401250028355\n",
      "Episode 190; Return  12.583263336357318\n",
      "Episode 191; Return  12.58858656696\n",
      "Episode 192; Return  12.593802262718478\n",
      "Episode 193; Return  12.600414685634751\n",
      "Episode 194; Return  12.605515641649975\n",
      "Episode 195; Return  12.61097453618661\n",
      "Episode 196; Return  12.615612423541595\n",
      "Episode 197; Return  12.620913882546013\n",
      "Episode 198; Return  12.62661633768467\n",
      "Episode 199; Return  12.632412234143397\n",
      "Episode 200; Return  12.578350178599358\n",
      "Episode 201; Return  12.58343301542956\n",
      "Episode 202; Return  12.587425922993386\n",
      "Episode 203; Return  12.534532204637387\n",
      "Episode 204; Return  12.539657046397528\n",
      "Episode 205; Return  12.545317254996881\n",
      "Episode 206; Return  12.493398244519836\n",
      "Episode 207; Return  12.499662020932073\n",
      "Episode 209; Return  12.510526501390922\n",
      "Episode 211; Return  12.52000018601169\n",
      "Episode 212; Return  12.524905842992494\n",
      "Episode 213; Return  12.530141028440054\n",
      "Episode 214; Return  12.535327286920815\n",
      "Episode 215; Return  12.48548856058786\n",
      "Episode 216; Return  12.490833522544968\n",
      "Episode 217; Return  12.495484059307433\n",
      "Episode 218; Return  12.50073413400475\n",
      "Episode 219; Return  12.5063015592697\n",
      "Episode 220; Return  12.511136550794948\n",
      "Episode 221; Return  12.51619928185217\n",
      "Episode 222; Return  12.521621808812425\n",
      "Episode 223; Return  12.526906015092482\n",
      "Episode 224; Return  12.531785898442779\n",
      "Episode 225; Return  12.535644630326166\n",
      "Episode 226; Return  12.540309920247678\n",
      "Episode 227; Return  12.544185207278717\n",
      "Episode 228; Return  12.549868606161652\n",
      "Episode 229; Return  12.554235992993851\n",
      "Episode 231; Return  12.562857328039227\n",
      "Episode 232; Return  12.567629495057567\n",
      "Episode 233; Return  12.572918639674207\n",
      "Episode 234; Return  12.577051465837364\n",
      "Episode 235; Return  12.581021460573725\n",
      "Episode 237; Return  12.589620434785191\n",
      "Episode 239; Return  12.598535746710072\n",
      "Episode 240; Return  12.601583514114221\n",
      "Episode 241; Return  12.606224247528804\n",
      "Episode 242; Return  12.611198525290844\n",
      "Episode 243; Return  12.615926104317968\n",
      "Episode 246; Return  12.626422937807998\n",
      "Episode 247; Return  12.631012319553236\n",
      "Episode 248; Return  12.634798558969651\n",
      "Episode 249; Return  12.63911663719928\n",
      "Episode 250; Return  12.642520169734954\n",
      "Episode 252; Return  12.651349375645319\n",
      "Episode 253; Return  12.655652341635331\n",
      "Episode 255; Return  12.663137422355952\n",
      "Episode 256; Return  12.667500165756792\n",
      "Episode 257; Return  12.669688882994745\n",
      "Episode 259; Return  12.677451904676136\n",
      "Episode 260; Return  12.681615552076927\n",
      "Episode 261; Return  12.68574729413365\n",
      "Episode 262; Return  12.689809327362148\n",
      "Episode 264; Return  12.69814410489617\n",
      "Episode 266; Return  12.706015200991379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m#actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m#primary_action, reset_action = actor_out.action, None\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         primary_action, actor_state \u001b[38;5;241m=\u001b[39m \u001b[43mactor_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactor_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         primary_action \u001b[38;5;241m=\u001b[39m primary_action[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m         reset_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/chung/Personal/RS/thinker/thinker/thinker/actor_net.py:974\u001b[0m, in \u001b[0;36mDRCNet_.forward\u001b[0;34m(self, obs, core_state, greedy)\u001b[0m\n\u001b[1;32m    972\u001b[0m             nd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(nd)\n\u001b[1;32m    973\u001b[0m         nd \u001b[38;5;241m=\u001b[39m nd\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 974\u001b[0m         output, core_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     core_output_list\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    976\u001b[0m core_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(core_output_list)\n",
      "File \u001b[0;32m/mnt/c/Users/chung/Personal/RS/thinker/thinker/thinker/core/rnn.py:339\u001b[0m, in \u001b[0;36mConvAttnLSTM.forward_single\u001b[0;34m(self, x, core_state, reset, reset_attn)\u001b[0m\n\u001b[1;32m    336\u001b[0m concat_k_cur \u001b[38;5;241m=\u001b[39m core_state[n \u001b[38;5;241m*\u001b[39m layer_n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    337\u001b[0m concat_v_cur \u001b[38;5;241m=\u001b[39m core_state[n \u001b[38;5;241m*\u001b[39m layer_n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m h_next, c_next, concat_k, concat_v \u001b[38;5;241m=\u001b[39m \u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcell_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_k_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_v_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask_reshape\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_scale \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m h_next\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    343\u001b[0m     h_next\u001b[38;5;241m.\u001b[39mregister_hook(\u001b[38;5;28;01mlambda\u001b[39;00m grad: grad \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_scale)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/chung/Personal/RS/thinker/thinker/thinker/core/rnn.py:108\u001b[0m, in \u001b[0;36mConvAttnLSTMCell.forward\u001b[0;34m(self, input, h_cur, c_cur, concat_k, concat_v, attn_mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28minput\u001b[39m, h_cur], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# concatenate along channel axis\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_inject:\n\u001b[0;32m--> 108\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_max_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_cur\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# concatenate along channel axis\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear:\n\u001b[1;32m    113\u001b[0m     combined_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain(combined[:, :, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "actor_net = actor_net.to(device)\n",
    "state = env.reset()\n",
    "#env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "env_out = init_env_out(state, flags=flags, dim_actions=1, tuple_action=False)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "rets = []\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    while(True):\n",
    "        #actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\n",
    "        #primary_action, reset_action = actor_out.action, None\n",
    "        primary_action, actor_state = actor_net(obs=env_out, core_state=actor_state, greedy=False)\n",
    "        primary_action = primary_action[0]\n",
    "        reset_action = None\n",
    "\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action)    \n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())            \n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "        env_out = create_env_out(primary_action, state, reward, done, info, flags=flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
