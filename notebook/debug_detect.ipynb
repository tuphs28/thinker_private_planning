{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from thinker.util import __project__\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "from thinker.actor_net import ActorNet\n",
    "from thinker.main import Env\n",
    "import thinker.util as util\n",
    "from thinker.self_play import init_env_out, create_env_out\n",
    "\n",
    "class DetectBuffer:\n",
    "    def __init__(self, outdir, t, rec_t, logger, delay_n=5):\n",
    "        \"\"\"\n",
    "        Store training data grouped in planning stages and output\n",
    "        whenever the target output is also readydd\n",
    "            Args:\n",
    "                N (int): number of planning stage per training output\n",
    "                delay_n (int): number of planning stage delayed in the output y\n",
    "                rec_t (int): number of step in a planning stage\n",
    "                K (int): number of block to merge into\n",
    "        \"\"\"\n",
    "        self.outdir = outdir\n",
    "        self.t = t # number of time step per file\n",
    "        self.rec_t = rec_t\n",
    "        self.logger = logger        \n",
    "        self.delay_n = delay_n        \n",
    "\n",
    "        self.processed_n, self.xs, self.y, self.done, self.step_status = 0, [], [], [], []\n",
    "        self.file_idx = -1\n",
    "    \n",
    "    def insert(self, xs, y, done, step_status):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xs (dict): dictionary of training input, with each elem having the\n",
    "                shape of (B, *)            \n",
    "            y (tensor): bool tensor of shape (B), being the target output delayed by\n",
    "                delay_n planning stage            \n",
    "            done (tensor): bool tensor of shape (B), being the indicator of episode end\n",
    "            step_status (int): int indicating current step status\n",
    "        Output:\n",
    "            save train_xs in shape (N, rec_t, B, *) and train_y in shape (N, B)\n",
    "        \"\"\"\n",
    "        #print(\"data received! \", y.shape, id, cur_t)\n",
    "        last_step_real = (step_status == 0) | (step_status == 3)\n",
    "        if len(self.step_status) == 0 and not last_step_real: return self.file_idx  # skip until real step\n",
    "                \n",
    "        self.xs.append(util.dict_map(xs, lambda x:x.cpu()))\n",
    "        self.y.append(y.cpu())\n",
    "        self.done.append(done.cpu())\n",
    "        self.step_status.append(step_status)\n",
    "        self.processed_n += int(last_step_real)\n",
    "\n",
    "        if (self.processed_n >= self.t + self.delay_n + 1):               \n",
    "            self.file_idx += 1                     \n",
    "            out = self._extract_data(self.t)\n",
    "            self.processed_n = sum([int(i == 0) + int(i == 3) for i in self.step_status])\n",
    "            assert self.processed_n == self.delay_n+1, f\"should only have {self.delay_n + 1} data left instead of {self.processed_n}\"\n",
    "            path = f'{self.outdir}/data_{self.file_idx}.pt'\n",
    "            torch.save(out, path)\n",
    "            out_shape = out[0]['env_state'].shape\n",
    "            n = self.file_idx * out_shape[0] * out_shape[2]\n",
    "            self.logger.info(f\"{n}: File saved to {path}; env_state shape {out_shape}\")\n",
    "\n",
    "        return self.file_idx   \n",
    "\n",
    "    def _extract_data(self, t):\n",
    "        # obtain the first N planning stage and the corresponding target_y in data\n",
    "        xs, y, done, step_status = self._collect_data(t)\n",
    "        future_y, future_done = self._collect_data(self.delay_n, y_done_only=True)\n",
    "        y = torch.concat([y, future_y], dim=0)        \n",
    "        done = torch.concat([done, future_done], dim=0)                \n",
    "        \n",
    "        last_step_real = (step_status == 0) | (step_status == 3)\n",
    "        assert last_step_real[0], \"cur_t should start with 0\"\n",
    "        assert last_step_real.shape[0] == t*self.rec_t, \\\n",
    "            f\" last_step_real.shape is {last_step_real.shape}, expected {t*self.rec_t} for the first dimension.\"        \n",
    "        assert y.shape[0] == (t + self.delay_n)*self.rec_t, \\\n",
    "            f\" y.shape is {y.shape}, expected {(t + self.delay_n)*self.rec_t} for the first dimension.\"        \n",
    "        \n",
    "        B = y.shape[1]\n",
    "        y = y.view(t + self.delay_n, self.rec_t, B)[:, 0]\n",
    "        done = done.view(t + self.delay_n, self.rec_t, B)[:, 0]\n",
    "        step_status = step_status.view(t, self.rec_t)\n",
    "        # compute target_y\n",
    "        target_y = self._compute_target_y(y, done, self.delay_n)\n",
    "\n",
    "        for k in xs.keys():\n",
    "            xs[k] = xs[k].view((t, self.rec_t) + xs[k].shape[1:])\n",
    "        \n",
    "        xs[\"done\"] = done[:t]\n",
    "        xs[\"step_status\"] = step_status\n",
    "                \n",
    "        return xs, target_y\n",
    "\n",
    "    def _collect_data(self, t, y_done_only=False):\n",
    "        # collect the first t stage from data\n",
    "        step_status = torch.tensor(self.step_status, dtype=torch.long)\n",
    "        next_step_real = (step_status == 2) | (step_status == 3)        \n",
    "        idx = torch.nonzero(next_step_real, as_tuple=False).squeeze()    \n",
    "        last_idx = idx[t-1] + 1\n",
    "        y = torch.stack(self.y[:last_idx], dim=0)\n",
    "        done = torch.stack(self.done[:last_idx], dim=0)\n",
    "        if not y_done_only:\n",
    "            xs = {}\n",
    "            for k in self.xs[0].keys():\n",
    "                xs[k] = torch.stack([v[k] for v in self.xs[:last_idx]], dim=0)                \n",
    "            step_status = step_status[:last_idx]\n",
    "            self.xs = self.xs[last_idx:]\n",
    "            self.y = self.y[last_idx:]\n",
    "            self.done = self.done[last_idx:]\n",
    "            self.step_status = self.step_status[last_idx:]\n",
    "            return xs, y, done, step_status\n",
    "        else:\n",
    "            return y, done\n",
    "        \n",
    "    def _compute_target_y(self, y, done, delay_n):        \n",
    "        # target_y[i] = (y[i] | (~done[i+1] & y[i+1]) | (~done[i+1] & ~done[i+2] & y[i+2]) | ... | (~done[i+1] & ~done[i+2] & ... & ~done[i+M] & y[i+M]))\n",
    "        t, b = y.shape\n",
    "        t = t - delay_n\n",
    "        not_done_cum = torch.ones(delay_n, t, b, dtype=bool)\n",
    "        target_y = y.clone()[:-delay_n]\n",
    "        not_done_cum[0] = ~done[1:1+t]\n",
    "        target_y = target_y | (not_done_cum[0] & y[1:1+t])\n",
    "        for m in range(1, delay_n):\n",
    "            not_done_cum[m] = not_done_cum[m-1] & ~done[m+1:m+1+t]\n",
    "            target_y = target_y | (not_done_cum[m] & y[m+1:m+1+t])\n",
    "        return target_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n = 200000\n",
    "env_n = 16\n",
    "delay_n = 5\n",
    "greedy = True\n",
    "savedir = \"../logs/thinker\"\n",
    "outdir = \"../data/detect\"\n",
    "xpid = \"v18_mcts\"\n",
    "\n",
    "_logger = util.logger()\n",
    "_logger.info(f\"Initializing {xpid} from {savedir}\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "ckpdir = os.path.join(savedir, xpid)     \n",
    "if os.path.islink(ckpdir): ckpdir = os.readlink(ckpdir)  \n",
    "ckpdir =  os.path.abspath(os.path.expanduser(ckpdir))\n",
    "outdir = os.path.abspath(os.path.expanduser(outdir))\n",
    "\n",
    "config_path = os.path.join(ckpdir, 'config_c.yaml')\n",
    "flags = util.create_flags(config_path, save_flags=False)\n",
    "flags.shallow_enc = False\n",
    "\n",
    "env = Env(\n",
    "        name=flags.name,\n",
    "        env_n=env_n,\n",
    "        gpu=True,\n",
    "        train_model=False,\n",
    "        parallel=False,\n",
    "        savedir=savedir,        \n",
    "        xpid=xpid,\n",
    "        ckp=True,\n",
    "        return_x=True,\n",
    "        return_h=True,\n",
    "    )\n",
    "\n",
    "disable_thinker = flags.wrapper_type == 1   \n",
    "im_rollout = disable_thinker and env.has_model\n",
    "mcts = flags.mcts\n",
    "\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space \n",
    "\n",
    "actor_param = {\n",
    "    \"obs_space\": obs_space,\n",
    "    \"action_space\": action_space,\n",
    "    \"flags\": flags,\n",
    "    \"tree_rep_meaning\": env.get_tree_rep_meaning() if not disable_thinker else None,\n",
    "    \"record_state\": True,\n",
    "}\n",
    "actor_net = ActorNet(**actor_param)\n",
    "\n",
    "if not mcts:\n",
    "    path = os.path.join(ckpdir, \"ckp_actor.tar\")\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    actor_net.set_weights(checkpoint[\"actor_net_state_dict\"])\n",
    "    actor_net.to(device)\n",
    "    actor_net.train(False)\n",
    "\n",
    "state = env.reset()\n",
    "env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "\n",
    "file_idx = 0\n",
    "\n",
    "# create dir\n",
    "\n",
    "n = 0\n",
    "while True:\n",
    "    name = \"%s-%d\" % (xpid, n)\n",
    "    outdir_ = os.path.join(outdir, name)\n",
    "    if not os.path.exists(outdir_):\n",
    "        os.makedirs(outdir_)\n",
    "        print(f\"Outputting to {outdir_}\")\n",
    "        break\n",
    "    n += 1\n",
    "outdir = outdir_\n",
    "\n",
    "rec_t=flags.rec_t if not im_rollout and not mcts else delay_n + 1\n",
    "detect_buffer = DetectBuffer(outdir=outdir, t=3200//env_n, rec_t=rec_t, logger=_logger, delay_n=delay_n)\n",
    "file_n = total_n // (env_n * detect_buffer.t) + 1\n",
    "_logger.info(f\"Data output directory: {outdir}\")\n",
    "_logger.info(f\"Number of file to be generated: {file_n}\")\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=greedy)            \n",
    "    if not disable_thinker:\n",
    "        primary_action, reset_action = actor_out.action\n",
    "    else:\n",
    "        primary_action, reset_action = actor_out.action, None\n",
    "\n",
    "    # save setting\n",
    "    env_state_shape = env.observation_space[\"real_states\"].shape[1:]\n",
    "    #if rescale: env_state_shape = (3, 40, 40)\n",
    "    tree_rep_shape = env.observation_space[\"tree_reps\"].shape[1:] if not disable_thinker else None\n",
    "    hidden_state_shape = actor_net.hidden_state.shape[1:] if disable_thinker else None\n",
    "\n",
    "    flags_detect = {\n",
    "        \"dim_actions\": actor_net.dim_actions,\n",
    "        \"num_actions\": actor_net.num_actions,\n",
    "        \"tuple_actions\": actor_net.tuple_action,\n",
    "        \"name\": flags.name,\n",
    "        \"env_state_shape\": list(env_state_shape),\n",
    "        \"tree_rep_shape\": list(tree_rep_shape) if not disable_thinker else None,\n",
    "        \"hidden_state_shape\": list(hidden_state_shape) if disable_thinker else None,\n",
    "        \"rec_t\": flags.rec_t,\n",
    "        \"delay_n\": delay_n,\n",
    "        \"ckpdir\": ckpdir,\n",
    "        \"xpid\": xpid,        \n",
    "        \"dxpid\": name,\n",
    "        \"disable_thinker\": disable_thinker,\n",
    "        \"im_rollout\": im_rollout,      \n",
    "        \"mcts\": mcts,\n",
    "    }\n",
    "\n",
    "    yaml_file_path = os.path.join(outdir, 'config_detect.yaml')\n",
    "    with open(yaml_file_path, 'w') as file:\n",
    "        yaml.dump(flags_detect, file)\n",
    "\n",
    "\n",
    "    rets = []\n",
    "    last_file_idx = None\n",
    "    \n",
    "    while(True):\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action, \n",
    "            action_prob=actor_out.action_prob[-1])    \n",
    "        \n",
    "        env_out = create_env_out(actor_out.action, state, reward, done, info, flags=flags)        \n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())\n",
    "\n",
    "        step_status = info['step_status'][0].item() if not im_rollout else 0        \n",
    "\n",
    "        if im_rollout or (mcts and step_status in [2, 3]):\n",
    "            # generate imaginary rollout or most visited rollout (mcts)\n",
    "            if im_rollout: \n",
    "                action = actor_out.action.unsqueeze(0)\n",
    "            else:\n",
    "                action = actor_out.action[0].unsqueeze(0)\n",
    "            model_net_out = env.model_net(\n",
    "                x=env_out.real_states[0],\n",
    "                done=env_out.done[0],\n",
    "                actions=action,\n",
    "                state=None,\n",
    "                one_hot=False,\n",
    "                ret_xs=True\n",
    "            )\n",
    "            new_env_out = env_out\n",
    "            if mcts:\n",
    "                most_visited_actions = torch.tensor(env.most_visited_path(delay_n), dtype=torch.long, device=device)\n",
    "            for m in range(delay_n):\n",
    "                if not mcts:\n",
    "                    actor_out, actor_state = actor_net(env_out=new_env_out, core_state=actor_state, greedy=greedy)   \n",
    "                    action = actor_out.action\n",
    "                else:\n",
    "                    action = most_visited_actions[m]\n",
    "                model_net_out = env.model_net.forward_single(\n",
    "                    state=model_net_out.state,\n",
    "                    action=action,\n",
    "                    one_hot=False,\n",
    "                    ret_xs=True,\n",
    "                )\n",
    "                new_state = {\"real_states\": (torch.clamp(model_net_out.xs,0,1)*255).to(torch.uint8)[0]}\n",
    "                new_env_out = create_env_out(action, new_state, reward, done, info, flags=flags)\n",
    "                xs = {\n",
    "                    \"env_state\": model_net_out.xs[0].half(),\n",
    "                    \"pri_action\": action,            \n",
    "                    \"cost\": torch.zeros_like(info[\"cost\"]),\n",
    "                }\n",
    "                if im_rollout: xs[\"hidden_state\"] = actor_net.hidden_state\n",
    "                if mcts: xs[\"reset_action\"] = torch.zeros_like(actor_out.action[1])\n",
    "                file_idx = detect_buffer.insert(\n",
    "                    xs, \n",
    "                    torch.zeros_like(y), \n",
    "                    torch.zeros_like(done), \n",
    "                    1 if m < delay_n - 1 else 2\n",
    "                )\n",
    "\n",
    "        actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=greedy)            \n",
    "        if not disable_thinker:\n",
    "            primary_action, reset_action = actor_out.action\n",
    "        else:\n",
    "            primary_action, reset_action = actor_out.action, None\n",
    "        \n",
    "        # write to detect buffer\n",
    "        if not disable_thinker:\n",
    "            env_state = env_out.xs[0] \n",
    "        else:\n",
    "            env_state = env_out.real_states[0]\n",
    "            env_state = env.normalize(env_state)\n",
    "        \n",
    "        env_state = env_state.half()\n",
    "        xs = {\n",
    "            \"env_state\": env_state,\n",
    "            \"pri_action\": primary_action,            \n",
    "            \"cost\": info[\"cost\"],\n",
    "        }\n",
    "        if not disable_thinker:\n",
    "            if not mcts: xs.update({\"tree_rep\": state[\"tree_reps\"]})\n",
    "            xs.update({\"reset_action\": actor_out.action[1]})\n",
    "        else:\n",
    "            if disable_thinker:\n",
    "                xs.update({\n",
    "                    \"hidden_state\": actor_net.hidden_state\n",
    "                })       \n",
    "        y = info['cost']\n",
    "        done = done        \n",
    "\n",
    "        if not (mcts and step_status != 0): # no recording for non-real mcts\n",
    "            file_idx = detect_buffer.insert(xs, y, done, step_status)\n",
    "        \n",
    "        if file_idx >= file_n: \n",
    "            # last file is for validation\n",
    "            os.rename(f'{outdir}/data_{file_idx}.pt', f'{outdir}/val.pt')\n",
    "            break\n",
    "\n",
    "        if last_file_idx is not None and file_idx != last_file_idx:\n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "\n",
    "        last_file_idx = file_idx\n",
    "    \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect_train import *\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "#datadir = \"/home/scuk/RS/thinker/data/detect/v5_sok-32052928-0\"\n",
    "datadir = \"/home/scuk/RS/thinker/data/detect/v5c_sp0-49956736-0\"\n",
    "dataset = CustomDataset(datadir=datadir, transform=None, chunk_n=1, data_n=10000)\n",
    "sampler = ChunkSampler(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=2048, sampler=ChunkSampler(dataset))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# load setting\n",
    "yaml_file_path = os.path.join(datadir, 'config_detect.yaml')\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    flags_data = yaml.safe_load(file)\n",
    "flags_data = argparse.Namespace(**flags_data)\n",
    "num_actions = flags_data.num_actions\n",
    "rec_t = flags_data.rec_t\n",
    "\n",
    "# Path to your BMP file\n",
    "image_path = '/home/scuk/RS/thinker/data/player_on_dan_small.bmp'\n",
    "# Load the image\n",
    "image = Image.open(image_path)\n",
    "# Convert the image to a tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to Tensor, scales to [0, 1] range\n",
    "])\n",
    "search_image = transform(image).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.870221757888794, 'rec': 0.6387614607810974, 'prec': 0.6094553828239441, 'f1': 0.6229297759159571, 'neg_p': 0.8314314842224121}\n"
     ]
    }
   ],
   "source": [
    "def find_max_similarity_single_function(x, search_image):\n",
    "    B, C, H, W = x.shape  # Batch size, Channels, Height, Width\n",
    "    block_size = 8\n",
    "    num_blocks_h = H // block_size  # Number of horizontal blocks\n",
    "    num_blocks_w = W // block_size  # Number of vertical blocks\n",
    "\n",
    "    x_reshaped = x.view(B, C, num_blocks_h, block_size, num_blocks_w, block_size)\n",
    "    # Permute to group blocks together while keeping the batch and channel dimensions intact\n",
    "    x_permuted = x_reshaped.permute(0, 2, 4, 1, 3, 5)\n",
    "    # Flatten the block grid dimensions to list all blocks sequentially\n",
    "    x_blocks = x_permuted.reshape(B, num_blocks_h * num_blocks_w, C * block_size * block_size)\n",
    "    # Normalize the blocks and the search_image\n",
    "    x_blocks_norm = F.normalize(x_blocks+1e-6, p=2, dim=-1)  # Normalize over channel dimension\n",
    "    search_image_norm = F.normalize(torch.flatten(search_image), p=2, dim=-1)\n",
    "\n",
    "    similarity = torch.sum(x_blocks_norm * search_image_norm, dim=-1)\n",
    "\n",
    "    # Find the maximum similarity for each image in the batch\n",
    "    max_similarity, _ = similarity.view(B, -1).max(dim=1)\n",
    "    return max_similarity\n",
    "\n",
    "def mask_top_rank(x, rank):\n",
    "    # args: x (tensor) of shape (B, N); rank (int)\n",
    "    # return a mask that equals 1 if the element of each row is the rank largest element\n",
    "    B, N = x.shape\n",
    "    sorted_values, _ = x.sort(dim=1, descending=True)\n",
    "    ties = (sorted_values[:, 1:] - sorted_values[:, :-1]) != 0\n",
    "    cum_ties = torch.cumsum(ties, dim=-1)\n",
    "    cum_ties = torch.concat([torch.zeros(B, 1, device=x.device), cum_ties], dim=-1)\n",
    "    idx = torch.argmax((cum_ties == rank).float(), dim=1)\n",
    "    not_found = torch.all(~(cum_ties == rank), dim=-1)\n",
    "    rank_values = sorted_values[torch.arange(B, device=x.device), idx]\n",
    "    mask = x == rank_values.unsqueeze(-1)\n",
    "    mask[not_found] = False\n",
    "    return mask\n",
    "\n",
    "#B = 2048\n",
    "#env_state = torch.stack([dataset[idx][0][\"env_state\"] for idx in range(B)]).to(device)\n",
    "#tree_rep = torch.stack([dataset[idx][0][\"tree_rep\"] for idx in range(B)]).to(device)\n",
    "#target_y = torch.stack([dataset[idx][1] for idx in range(B)]).to(device)\n",
    "\n",
    "eval_results = {}\n",
    "search_rank = 0\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "\n",
    "    for xs, target_y in dataloader:\n",
    "\n",
    "        env_state = xs[\"env_state\"].to(device)\n",
    "        tree_rep = xs[\"tree_rep\"].to(device)\n",
    "        target_y = target_y.to(device)\n",
    "\n",
    "        B, rec_t = env_state.shape[:2]\n",
    "\n",
    "        # for sokoban\n",
    "        # max_sim = find_max_similarity_single_function(torch.flatten(env_state, 0, 1), search_image)\n",
    "        # max_sim = max_sim.view(B, rec_t)\n",
    "\n",
    "        # for point goal\n",
    "        mask = torch.zeros(240, dtype=torch.bool)\n",
    "        for i in range(3, 4):\n",
    "            mask[60*i+22:60*i+22+16] = 1\n",
    "            #mask[60*i+41:60*i+41+16] = 1\n",
    "        #max_sim = torch.sum((env_state[:, :, mask] > 0.95).float(), dim=-1) >= 0.5\n",
    "        max_sim = torch.sum((env_state[:, :, mask] > 0.9).float(), dim=-1) >= 1\n",
    "\n",
    "        # compute last rollout return\n",
    "\n",
    "        idx_reset = num_actions * 4 + 6\n",
    "        idx_rr = idx_reset + flags_data.rec_t + 1\n",
    "        reset = tree_rep[:, :, idx_reset].bool()\n",
    "        rollout_return = tree_rep[:, :, idx_rr]\n",
    "\n",
    "        last_rollout_return = rollout_return.clone()\n",
    "        r = last_rollout_return[:, -1].clone()\n",
    "        for n in range(flags_data.rec_t-1, -1, -1):\n",
    "            r[reset[:, n]] = last_rollout_return[reset[:, n], n]\n",
    "            last_rollout_return[:, n] = r  \n",
    "\n",
    "        search_mask = torch.zeros(B, rec_t, dtype=torch.bool, device=device)\n",
    "        search_mask[:, 0] = 1\n",
    "\n",
    "        for m in range(search_rank+1):\n",
    "            search_mask = search_mask | mask_top_rank(last_rollout_return, m)\n",
    "\n",
    "        max_sim[~search_mask] = 0\n",
    "        max_sim = torch.max(max_sim, dim=-1)[0]\n",
    "        pred_y = max_sim > 0.95\n",
    "        \n",
    "        result = evaluate_detect(target_y, pred_y)\n",
    "        for k, v in result.items():\n",
    "            if k not in eval_results: \n",
    "                eval_results[k] = [v]\n",
    "            else:\n",
    "                eval_results[k].append(v)\n",
    "\n",
    "\n",
    "for k in eval_results:\n",
    "    eval_results[k] = np.mean(np.array(eval_results[k]))\n",
    "\n",
    "print(eval_results)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sim = find_max_similarity_single_function(torch.flatten(env_state, 0, 1), search_image)\n",
    "env_state_ = env_state.flatten(0, 1)\n",
    "\n",
    "midx = torch.nonzero(max_sim > 0.95).squeeze(-1)\n",
    "idx = torch.randperm(midx.shape[0])\n",
    "midx = midx[idx][:20]\n",
    "d_env_state = env_state_[midx]\n",
    "\n",
    "midx = torch.nonzero(max_sim < 0.95).squeeze(-1)\n",
    "idx = torch.randperm(midx.shape[0])\n",
    "midx = midx[idx][:20]\n",
    "s_env_state = env_state_[midx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "border_size = 0  # Size of the black border\n",
    "scale_factor = 6\n",
    "\n",
    "# Calculate the new size including the border\n",
    "if border_size > 0:\n",
    "    new_height = d_env_state.size(2) + 2*border_size\n",
    "    new_width = d_env_state.size(3) + 2*border_size\n",
    "\n",
    "    d_env_state_ = torch.zeros((d_env_state.size(0), 3, new_height, new_width), device=d_env_state.device)\n",
    "    d_env_state_[:, :, border_size:-border_size, border_size:-border_size] = d_env_state\n",
    "\n",
    "    s_env_state_ = torch.zeros((s_env_state.size(0), 3, new_height, new_width), device=s_env_state.device)\n",
    "    s_env_state_[:, :, border_size:-border_size, border_size:-border_size] = s_env_state\n",
    "else:\n",
    "    d_env_state_ = d_env_state\n",
    "    s_env_state_ = s_env_state\n",
    "\n",
    "d_env_state_ = F.interpolate(d_env_state_, scale_factor=scale_factor, mode='nearest')\n",
    "s_env_state_ = F.interpolate(s_env_state_, scale_factor=scale_factor, mode='nearest')\n",
    "\n",
    "for i in range(d_env_state.shape[0]):\n",
    "    image_filename = f\"../data/sample/d_{i}.png\"\n",
    "    img = d_env_state_[i]\n",
    "    save_image(img, image_filename)\n",
    "for i in range(s_env_state.shape[0]):\n",
    "    image_filename = f\"../data/sample/s_{i}.png\"\n",
    "    img = s_env_state_[i]\n",
    "    save_image(img, image_filename)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2288818359375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deprecated\n",
    "\n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from thinker import util\n",
    "\n",
    "datadir = \"../data/detect/v5_sok-5993808-1/\"\n",
    "datadir = os.path.abspath(os.path.expanduser(datadir))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datadir, transform=None):\n",
    "        self.datadir = datadir\n",
    "        self.file_list = [f for f in os.listdir(datadir) if f.endswith('.pt')]\n",
    "        self.transform = transform\n",
    "        xs, y = torch.load(os.path.join(datadir, self.file_list[0]))        \n",
    "        self.t = xs['env_state'].shape[0]\n",
    "        self.b = xs['env_state'].shape[2]\n",
    "        self.samples_per_file = self.t * self.b\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) * self.samples_per_file  # Adjust based on your data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx = idx // self.samples_per_file\n",
    "        within_file_idx = idx % self.samples_per_file\n",
    "        t_idx = within_file_idx // self.b\n",
    "        b_idx = within_file_idx % self.b\n",
    "        xs, y = torch.load(os.path.join(self.datadir, self.file_list[file_idx]))\n",
    "        xs.pop('step_status')\n",
    "        xs.pop('done')\n",
    "        xs = util.dict_map(xs, lambda x: x[t_idx, :, b_idx])\n",
    "        y = y[t_idx, b_idx]\n",
    "        return xs, y\n",
    "\n",
    "# To load data and train\n",
    "dataset = CustomDataset(datadir)\n",
    "# print(dataset[100])\n",
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing env 0 with device cuda\n",
      "Model network size: 6637133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlinked log directory: /home/stephen/RS/thinker/notebook/logs/latest\n",
      "Wrote config file to /home/stephen/RS/thinker/notebook/logs/detect-20240205-143653/config_c.yaml\n"
     ]
    }
   ],
   "source": [
    "from thinker.actor_net import DRCNet, ActorNetBase\n",
    "from thinker.main import Env\n",
    "from thinker.self_play import init_env_out, create_env_out\n",
    "from thinker import util\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "env_n = 16\n",
    "flags = util.create_setting(args=[], drc=False, save_flags=False, see_h=True, legacy=True, wrapper_type=0, has_action_seq=False)\n",
    "env = Env(\n",
    "        name=\"Sokoban-v0\",\n",
    "        env_n=env_n,\n",
    "        gpu=True,\n",
    "        train_model=False,\n",
    "        parallel=False,\n",
    "        return_x=True,\n",
    "        return_h=True,\n",
    "        flags=flags,\n",
    "    )\n",
    "\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space \n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "# actor_net = DRCNet(obs_space=obs_space, action_space=action_space, flags=flags, tree_rep_meaning=None)\n",
    "actor_net = ActorNetBase(obs_space=obs_space, action_space=action_space, flags=flags, tree_rep_meaning=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (16, 111), float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_space[\"tree_reps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"../logs/detect/v1a_base_dirloss/ckp_actor.tar\")[\"actor_net_state_dict\"]\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    key = key.replace(\"actor_encoder\", \"h_encoder\")\n",
    "    key = key.replace(\"core\", \"tree_rep_encoder.rnn\")    \n",
    "    key = key.replace(\"initial_enc\", \"tree_rep_encoder.rnn_in_fc\")    \n",
    "    key = key.replace(\"model_stat_fc\", \"tree_rep_encoder.rnn_out_fc\")    \n",
    "    new_state_dict[key] = value\n",
    "actor_net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in actor_net.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in new_state_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../logs/detect/v1a_base_dirloss/ckp_actor.tar\")[\"actor_net_state_dict\"]\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = actor_net.to(device)\n",
    "state = env.reset()\n",
    "env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "rets = []\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    while(True):\n",
    "        actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\n",
    "        primary_action, reset_action = actor_out.action, None\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action)    \n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())            \n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "        env_out = create_env_out(primary_action, state, reward, done, info, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ['step', 'real_step', 'actor_net_optimizer_state_dict', 'actor_net_scheduler_state_dict', 'actor_net_state_dict']\n",
    "for c in cs: checkpoint_[c] = checkpoint[c]\n",
    "torch.save(checkpoint_, \"../logs/detect/v5b_sok_drc/ckp_actor.tar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actor_net = actor_net.to(device)\n",
    "state = env.reset()\n",
    "#env_out = init_env_out(state, flags=flags, dim_actions=actor_net.dim_actions, tuple_action=actor_net.tuple_action)  \n",
    "env_out = init_env_out(state, flags=flags, dim_actions=1, tuple_action=False)  \n",
    "actor_state = actor_net.initial_state(batch_size=env_n, device=device)\n",
    "rets = []\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    \n",
    "    while(True):\n",
    "        #actor_out, actor_state = actor_net(env_out=env_out, core_state=actor_state, greedy=False)\n",
    "        #primary_action, reset_action = actor_out.action, None\n",
    "        primary_action, actor_state = actor_net(obs=env_out, core_state=actor_state, greedy=False)\n",
    "        primary_action = primary_action[0]\n",
    "        reset_action = None\n",
    "\n",
    "        state, reward, done, info = env.step(\n",
    "            primary_action=primary_action, \n",
    "            reset_action=reset_action)    \n",
    "        if torch.any(done):\n",
    "            rets.extend(info[\"episode_return\"][done].cpu().tolist())            \n",
    "            print(f\"Episode {len(rets)}; Return  {np.mean(np.array(rets))}\")\n",
    "        env_out = create_env_out(primary_action, state, reward, done, info, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinker.wrapper import DMSuiteEnv\n",
    "# Example usage\n",
    "env = DMSuiteEnv(domain_name=\"acrobot\", task_name=\"swingup\", rgb=False)\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    print(obs, reward, done)\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
